{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_theme()\n",
    "import os\n",
    "from itertools import cycle\n",
    "\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout, Activation, LeakyReLU\n",
    "LeakyReLU = LeakyReLU(0.1)\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop, Adadelta, Adagrad, Adamax, Nadam, Ftrl\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "# from scikeras.wrappers import KerasClassifier\n",
    "from tensorflow.keras.utils import to_categorical, set_random_seed\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, classification_report, RocCurveDisplay, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.preprocessing import RobustScaler, LabelEncoder\n",
    "\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\abdul\\\\Desktop\\\\HEA_2'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd = os.getcwd()\n",
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Dataframe:  (1167, 44)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Alloy</th>\n",
       "      <th>avg_dev_AtomicWeight</th>\n",
       "      <th>maximum_MeltingT</th>\n",
       "      <th>avg_dev_MeltingT</th>\n",
       "      <th>mode_MeltingT</th>\n",
       "      <th>avg_dev_Column</th>\n",
       "      <th>mean_Row</th>\n",
       "      <th>mode_Row</th>\n",
       "      <th>minimum_CovalentRadius</th>\n",
       "      <th>maximum_CovalentRadius</th>\n",
       "      <th>range_CovalentRadius</th>\n",
       "      <th>avg_dev_CovalentRadius</th>\n",
       "      <th>mode_CovalentRadius</th>\n",
       "      <th>maximum_Electronegativity</th>\n",
       "      <th>mean_Electronegativity</th>\n",
       "      <th>mode_Electronegativity</th>\n",
       "      <th>mean_NsValence</th>\n",
       "      <th>maximum_NpValence</th>\n",
       "      <th>mean_NpValence</th>\n",
       "      <th>avg_dev_NpValence</th>\n",
       "      <th>range_NdValence</th>\n",
       "      <th>mean_NdValence</th>\n",
       "      <th>avg_dev_NdValence</th>\n",
       "      <th>avg_dev_NValence</th>\n",
       "      <th>mode_NValence</th>\n",
       "      <th>maximum_NdUnfilled</th>\n",
       "      <th>range_NdUnfilled</th>\n",
       "      <th>avg_dev_NdUnfilled</th>\n",
       "      <th>mode_NUnfilled</th>\n",
       "      <th>minimum_GSvolume_pa</th>\n",
       "      <th>range_GSvolume_pa</th>\n",
       "      <th>mode_GSvolume_pa</th>\n",
       "      <th>maximum_GSbandgap</th>\n",
       "      <th>avg_dev_GSbandgap</th>\n",
       "      <th>range_GSmagmom</th>\n",
       "      <th>minimum_SpaceGroupNumber</th>\n",
       "      <th>maximum_SpaceGroupNumber</th>\n",
       "      <th>mean_SpaceGroupNumber</th>\n",
       "      <th>range_Column</th>\n",
       "      <th>maximum_NpUnfilled</th>\n",
       "      <th>maximum_NdValence</th>\n",
       "      <th>mode_MendeleevNumber</th>\n",
       "      <th>range_NUnfilled</th>\n",
       "      <th>Phase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Al0.5NbTaTiV</td>\n",
       "      <td>3.838070</td>\n",
       "      <td>3290.0</td>\n",
       "      <td>584.546173</td>\n",
       "      <td>7.571474</td>\n",
       "      <td>0.966843</td>\n",
       "      <td>4.555556</td>\n",
       "      <td>4</td>\n",
       "      <td>121</td>\n",
       "      <td>170</td>\n",
       "      <td>3.912023</td>\n",
       "      <td>2.391138</td>\n",
       "      <td>153</td>\n",
       "      <td>1.63</td>\n",
       "      <td>1.572222</td>\n",
       "      <td>0.916291</td>\n",
       "      <td>1.777778</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.180262</td>\n",
       "      <td>4</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>0.635989</td>\n",
       "      <td>1.797913</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0.908856</td>\n",
       "      <td>7</td>\n",
       "      <td>2.639771</td>\n",
       "      <td>1.819699</td>\n",
       "      <td>2.639771</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>194</td>\n",
       "      <td>229</td>\n",
       "      <td>220.777778</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>43</td>\n",
       "      <td>3</td>\n",
       "      <td>BCC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Al0.75MoNbTiV</td>\n",
       "      <td>3.255577</td>\n",
       "      <td>2896.0</td>\n",
       "      <td>521.067701</td>\n",
       "      <td>7.571474</td>\n",
       "      <td>1.140210</td>\n",
       "      <td>4.263158</td>\n",
       "      <td>4</td>\n",
       "      <td>121</td>\n",
       "      <td>164</td>\n",
       "      <td>3.784190</td>\n",
       "      <td>2.377029</td>\n",
       "      <td>153</td>\n",
       "      <td>2.16</td>\n",
       "      <td>1.713158</td>\n",
       "      <td>0.932164</td>\n",
       "      <td>1.578947</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.235805</td>\n",
       "      <td>5</td>\n",
       "      <td>2.947368</td>\n",
       "      <td>0.845714</td>\n",
       "      <td>0.598806</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1.074312</td>\n",
       "      <td>6</td>\n",
       "      <td>2.639771</td>\n",
       "      <td>1.819699</td>\n",
       "      <td>2.639771</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>194</td>\n",
       "      <td>229</td>\n",
       "      <td>221.000000</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>43</td>\n",
       "      <td>3</td>\n",
       "      <td>BCC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Al0.25MoNbTiV</td>\n",
       "      <td>3.205911</td>\n",
       "      <td>2896.0</td>\n",
       "      <td>441.662561</td>\n",
       "      <td>7.571474</td>\n",
       "      <td>0.758442</td>\n",
       "      <td>4.411765</td>\n",
       "      <td>4</td>\n",
       "      <td>121</td>\n",
       "      <td>164</td>\n",
       "      <td>3.784190</td>\n",
       "      <td>1.950841</td>\n",
       "      <td>153</td>\n",
       "      <td>2.16</td>\n",
       "      <td>1.725294</td>\n",
       "      <td>0.932164</td>\n",
       "      <td>1.529412</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.105014</td>\n",
       "      <td>5</td>\n",
       "      <td>3.294118</td>\n",
       "      <td>0.758442</td>\n",
       "      <td>0.492669</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0.833360</td>\n",
       "      <td>6</td>\n",
       "      <td>2.639771</td>\n",
       "      <td>1.819699</td>\n",
       "      <td>2.639771</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>194</td>\n",
       "      <td>229</td>\n",
       "      <td>220.529412</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>43</td>\n",
       "      <td>3</td>\n",
       "      <td>BCC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Al0.25NbTaTiV</td>\n",
       "      <td>3.825406</td>\n",
       "      <td>3290.0</td>\n",
       "      <td>539.821730</td>\n",
       "      <td>7.571474</td>\n",
       "      <td>0.648931</td>\n",
       "      <td>4.647059</td>\n",
       "      <td>4</td>\n",
       "      <td>121</td>\n",
       "      <td>170</td>\n",
       "      <td>3.912023</td>\n",
       "      <td>2.140270</td>\n",
       "      <td>153</td>\n",
       "      <td>1.63</td>\n",
       "      <td>1.570000</td>\n",
       "      <td>0.916291</td>\n",
       "      <td>1.764706</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.105014</td>\n",
       "      <td>4</td>\n",
       "      <td>2.823529</td>\n",
       "      <td>0.542163</td>\n",
       "      <td>1.825219</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0.718768</td>\n",
       "      <td>7</td>\n",
       "      <td>2.639771</td>\n",
       "      <td>1.819699</td>\n",
       "      <td>2.639771</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>194</td>\n",
       "      <td>229</td>\n",
       "      <td>220.529412</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>43</td>\n",
       "      <td>3</td>\n",
       "      <td>BCC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Al0.2MoTaTiV</td>\n",
       "      <td>3.838178</td>\n",
       "      <td>3290.0</td>\n",
       "      <td>565.511565</td>\n",
       "      <td>7.571474</td>\n",
       "      <td>0.703300</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>4</td>\n",
       "      <td>121</td>\n",
       "      <td>170</td>\n",
       "      <td>3.912023</td>\n",
       "      <td>2.105461</td>\n",
       "      <td>153</td>\n",
       "      <td>2.16</td>\n",
       "      <td>1.702857</td>\n",
       "      <td>0.916291</td>\n",
       "      <td>1.761905</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.086822</td>\n",
       "      <td>5</td>\n",
       "      <td>3.095238</td>\n",
       "      <td>0.645547</td>\n",
       "      <td>1.812332</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0.829650</td>\n",
       "      <td>6</td>\n",
       "      <td>2.639771</td>\n",
       "      <td>1.809927</td>\n",
       "      <td>2.639771</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>194</td>\n",
       "      <td>229</td>\n",
       "      <td>220.476191</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>43</td>\n",
       "      <td>3</td>\n",
       "      <td>BCC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Alloy  avg_dev_AtomicWeight  maximum_MeltingT  avg_dev_MeltingT  \\\n",
       "0   Al0.5NbTaTiV              3.838070            3290.0        584.546173   \n",
       "1  Al0.75MoNbTiV              3.255577            2896.0        521.067701   \n",
       "2  Al0.25MoNbTiV              3.205911            2896.0        441.662561   \n",
       "3  Al0.25NbTaTiV              3.825406            3290.0        539.821730   \n",
       "4   Al0.2MoTaTiV              3.838178            3290.0        565.511565   \n",
       "\n",
       "   mode_MeltingT  avg_dev_Column  mean_Row  mode_Row  minimum_CovalentRadius  \\\n",
       "0       7.571474        0.966843  4.555556         4                     121   \n",
       "1       7.571474        1.140210  4.263158         4                     121   \n",
       "2       7.571474        0.758442  4.411765         4                     121   \n",
       "3       7.571474        0.648931  4.647059         4                     121   \n",
       "4       7.571474        0.703300  4.666667         4                     121   \n",
       "\n",
       "   maximum_CovalentRadius  range_CovalentRadius  avg_dev_CovalentRadius  \\\n",
       "0                     170              3.912023                2.391138   \n",
       "1                     164              3.784190                2.377029   \n",
       "2                     164              3.784190                1.950841   \n",
       "3                     170              3.912023                2.140270   \n",
       "4                     170              3.912023                2.105461   \n",
       "\n",
       "   mode_CovalentRadius  maximum_Electronegativity  mean_Electronegativity  \\\n",
       "0                  153                       1.63                1.572222   \n",
       "1                  153                       2.16                1.713158   \n",
       "2                  153                       2.16                1.725294   \n",
       "3                  153                       1.63                1.570000   \n",
       "4                  153                       2.16                1.702857   \n",
       "\n",
       "   mode_Electronegativity  mean_NsValence  maximum_NpValence  mean_NpValence  \\\n",
       "0                0.916291        1.777778           0.693147        0.111111   \n",
       "1                0.932164        1.578947           0.693147        0.157895   \n",
       "2                0.932164        1.529412           0.693147        0.058824   \n",
       "3                0.916291        1.764706           0.693147        0.058824   \n",
       "4                0.916291        1.761905           0.693147        0.047619   \n",
       "\n",
       "   avg_dev_NpValence  range_NdValence  mean_NdValence  avg_dev_NdValence  \\\n",
       "0           0.180262                4        2.666667           0.635989   \n",
       "1           0.235805                5        2.947368           0.845714   \n",
       "2           0.105014                5        3.294118           0.758442   \n",
       "3           0.105014                4        2.823529           0.542163   \n",
       "4           0.086822                5        3.095238           0.645547   \n",
       "\n",
       "   avg_dev_NValence  mode_NValence  maximum_NdUnfilled  range_NdUnfilled  \\\n",
       "0          1.797913       1.609438                   8                 8   \n",
       "1          0.598806       1.609438                   8                 8   \n",
       "2          0.492669       1.609438                   8                 8   \n",
       "3          1.825219       1.609438                   8                 8   \n",
       "4          1.812332       1.609438                   8                 8   \n",
       "\n",
       "   avg_dev_NdUnfilled  mode_NUnfilled  minimum_GSvolume_pa  range_GSvolume_pa  \\\n",
       "0            0.908856               7             2.639771           1.819699   \n",
       "1            1.074312               6             2.639771           1.819699   \n",
       "2            0.833360               6             2.639771           1.819699   \n",
       "3            0.718768               7             2.639771           1.819699   \n",
       "4            0.829650               6             2.639771           1.809927   \n",
       "\n",
       "   mode_GSvolume_pa  maximum_GSbandgap  avg_dev_GSbandgap  range_GSmagmom  \\\n",
       "0          2.639771                0.0                0.0        0.000023   \n",
       "1          2.639771                0.0                0.0        0.000023   \n",
       "2          2.639771                0.0                0.0        0.000023   \n",
       "3          2.639771                0.0                0.0        0.000023   \n",
       "4          2.639771                0.0                0.0        0.000023   \n",
       "\n",
       "   minimum_SpaceGroupNumber  maximum_SpaceGroupNumber  mean_SpaceGroupNumber  \\\n",
       "0                       194                       229             220.777778   \n",
       "1                       194                       229             221.000000   \n",
       "2                       194                       229             220.529412   \n",
       "3                       194                       229             220.529412   \n",
       "4                       194                       229             220.476191   \n",
       "\n",
       "   range_Column  maximum_NpUnfilled  maximum_NdValence  mode_MendeleevNumber  \\\n",
       "0             9                   5                  4                    43   \n",
       "1             9                   5                  5                    43   \n",
       "2             9                   5                  5                    43   \n",
       "3             9                   5                  4                    43   \n",
       "4             9                   5                  5                    43   \n",
       "\n",
       "   range_NUnfilled Phase  \n",
       "0                3   BCC  \n",
       "1                3   BCC  \n",
       "2                3   BCC  \n",
       "3                3   BCC  \n",
       "4                3   BCC  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(pwd+\"/raw_dataset/HEA_tr_NETCORE.csv\")\n",
    "print(\"Shape of Dataframe: \", df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of feature: (1167, 42)\n",
      "Shape of labels: (1167,)\n"
     ]
    }
   ],
   "source": [
    "# SHUFFLE THE DATASET\n",
    "df = df.sample(frac=1, random_state=42)\n",
    "X = df.copy().drop(columns=[\"Alloy\", \"Phase\"])\n",
    "y = df[\"Phase\"].astype(\"category\")\n",
    "print(f\"Shape of feature: {X.shape}\\nShape of labels: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phase\n",
      "MIP        428\n",
      "BCC        363\n",
      "FCC        211\n",
      "FCC_BCC    165\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# check class imbalance\n",
    "print(y.value_counts(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of feature: (1712, 42)\n",
      "Shape of labels: (1712,)\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "X, y = SMOTE(random_state=42).fit_resample(X, y)\n",
    "print(f\"Shape of feature: {X.shape}\\nShape of labels: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phase\n",
      "BCC        428\n",
      "FCC        428\n",
      "FCC_BCC    428\n",
      "MIP        428\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# check for class imbalance\n",
    "print(y.value_counts(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_dev_AtomicWeight</th>\n",
       "      <th>maximum_MeltingT</th>\n",
       "      <th>avg_dev_MeltingT</th>\n",
       "      <th>mode_MeltingT</th>\n",
       "      <th>avg_dev_Column</th>\n",
       "      <th>mean_Row</th>\n",
       "      <th>mode_Row</th>\n",
       "      <th>minimum_CovalentRadius</th>\n",
       "      <th>maximum_CovalentRadius</th>\n",
       "      <th>range_CovalentRadius</th>\n",
       "      <th>avg_dev_CovalentRadius</th>\n",
       "      <th>mode_CovalentRadius</th>\n",
       "      <th>maximum_Electronegativity</th>\n",
       "      <th>mean_Electronegativity</th>\n",
       "      <th>mode_Electronegativity</th>\n",
       "      <th>mean_NsValence</th>\n",
       "      <th>maximum_NpValence</th>\n",
       "      <th>mean_NpValence</th>\n",
       "      <th>avg_dev_NpValence</th>\n",
       "      <th>range_NdValence</th>\n",
       "      <th>mean_NdValence</th>\n",
       "      <th>avg_dev_NdValence</th>\n",
       "      <th>avg_dev_NValence</th>\n",
       "      <th>mode_NValence</th>\n",
       "      <th>maximum_NdUnfilled</th>\n",
       "      <th>range_NdUnfilled</th>\n",
       "      <th>avg_dev_NdUnfilled</th>\n",
       "      <th>mode_NUnfilled</th>\n",
       "      <th>minimum_GSvolume_pa</th>\n",
       "      <th>range_GSvolume_pa</th>\n",
       "      <th>mode_GSvolume_pa</th>\n",
       "      <th>maximum_GSbandgap</th>\n",
       "      <th>avg_dev_GSbandgap</th>\n",
       "      <th>range_GSmagmom</th>\n",
       "      <th>minimum_SpaceGroupNumber</th>\n",
       "      <th>maximum_SpaceGroupNumber</th>\n",
       "      <th>mean_SpaceGroupNumber</th>\n",
       "      <th>range_Column</th>\n",
       "      <th>maximum_NpUnfilled</th>\n",
       "      <th>maximum_NdValence</th>\n",
       "      <th>mode_MendeleevNumber</th>\n",
       "      <th>range_NUnfilled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.161097</td>\n",
       "      <td>1.256140</td>\n",
       "      <td>0.606754</td>\n",
       "      <td>0.532601</td>\n",
       "      <td>0.521256</td>\n",
       "      <td>-0.216360</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.584759</td>\n",
       "      <td>0.717467</td>\n",
       "      <td>1.363636</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.232362</td>\n",
       "      <td>0.449317</td>\n",
       "      <td>-1.196825</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.477222</td>\n",
       "      <td>0.422557</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.304043</td>\n",
       "      <td>0.175303</td>\n",
       "      <td>-0.008391</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.190333</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.336801</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.640823</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.709468</td>\n",
       "      <td>-0.647368</td>\n",
       "      <td>-0.538152</td>\n",
       "      <td>-0.471801</td>\n",
       "      <td>-0.863198</td>\n",
       "      <td>0.220453</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.42</td>\n",
       "      <td>-0.427776</td>\n",
       "      <td>-1.279471</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1.471545</td>\n",
       "      <td>1.916202</td>\n",
       "      <td>-0.110975</td>\n",
       "      <td>0.584963</td>\n",
       "      <td>-0.223215</td>\n",
       "      <td>-0.254527</td>\n",
       "      <td>-0.666667</td>\n",
       "      <td>1.487024</td>\n",
       "      <td>-0.236945</td>\n",
       "      <td>-0.963679</td>\n",
       "      <td>0.560099</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.196263</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.948033</td>\n",
       "      <td>-0.030237</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-53.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.640578</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.551801</td>\n",
       "      <td>-0.647368</td>\n",
       "      <td>-0.934202</td>\n",
       "      <td>0.039657</td>\n",
       "      <td>-0.977210</td>\n",
       "      <td>-0.216360</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.70</td>\n",
       "      <td>-0.814217</td>\n",
       "      <td>-1.599888</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.090976</td>\n",
       "      <td>1.916202</td>\n",
       "      <td>1.809577</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.026149</td>\n",
       "      <td>0.020301</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.584874</td>\n",
       "      <td>-0.225051</td>\n",
       "      <td>-0.802636</td>\n",
       "      <td>0.560099</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.853525</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.030237</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.694305</td>\n",
       "      <td>-0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.428073</td>\n",
       "      <td>2.882456</td>\n",
       "      <td>0.969928</td>\n",
       "      <td>-1.266392</td>\n",
       "      <td>0.594814</td>\n",
       "      <td>-1.406341</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-15.0</td>\n",
       "      <td>-0.42</td>\n",
       "      <td>1.434420</td>\n",
       "      <td>1.058207</td>\n",
       "      <td>-0.272727</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.850365</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.362050</td>\n",
       "      <td>0.584963</td>\n",
       "      <td>1.529725</td>\n",
       "      <td>1.115875</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.534503</td>\n",
       "      <td>0.775456</td>\n",
       "      <td>0.299071</td>\n",
       "      <td>-1.247204</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.262099</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-79.249736</td>\n",
       "      <td>4.490789</td>\n",
       "      <td>-0.030237</td>\n",
       "      <td>4.496</td>\n",
       "      <td>0.616735</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.283342</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.071655</td>\n",
       "      <td>1.256140</td>\n",
       "      <td>0.363886</td>\n",
       "      <td>0.039657</td>\n",
       "      <td>0.103571</td>\n",
       "      <td>0.140634</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.584759</td>\n",
       "      <td>0.646848</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.820978</td>\n",
       "      <td>0.449317</td>\n",
       "      <td>-0.535416</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.161471</td>\n",
       "      <td>0.153797</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.067211</td>\n",
       "      <td>0.047385</td>\n",
       "      <td>-0.120768</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.141745</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.030237</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.269152</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   avg_dev_AtomicWeight  maximum_MeltingT  avg_dev_MeltingT  mode_MeltingT  \\\n",
       "0              0.161097          1.256140          0.606754       0.532601   \n",
       "1             -0.709468         -0.647368         -0.538152      -0.471801   \n",
       "2             -0.551801         -0.647368         -0.934202       0.039657   \n",
       "3              0.428073          2.882456          0.969928      -1.266392   \n",
       "4              0.071655          1.256140          0.363886       0.039657   \n",
       "\n",
       "   avg_dev_Column  mean_Row  mode_Row  minimum_CovalentRadius  \\\n",
       "0        0.521256 -0.216360       0.0                     0.0   \n",
       "1       -0.863198  0.220453       0.0                     1.0   \n",
       "2       -0.977210 -0.216360       0.0                     0.0   \n",
       "3        0.594814 -1.406341      -1.0                   -15.0   \n",
       "4        0.103571  0.140634       0.0                     0.0   \n",
       "\n",
       "   maximum_CovalentRadius  range_CovalentRadius  avg_dev_CovalentRadius  \\\n",
       "0                    0.18              0.584759                0.717467   \n",
       "1                   -0.42             -0.427776               -1.279471   \n",
       "2                   -0.70             -0.814217               -1.599888   \n",
       "3                   -0.42              1.434420                1.058207   \n",
       "4                    0.18              0.584759                0.646848   \n",
       "\n",
       "   mode_CovalentRadius  maximum_Electronegativity  mean_Electronegativity  \\\n",
       "0             1.363636                       0.25                0.232362   \n",
       "1             0.000000                       0.05                1.471545   \n",
       "2             0.000000                       0.00                1.090976   \n",
       "3            -0.272727                       0.64                0.850365   \n",
       "4             0.000000                       0.25                0.820978   \n",
       "\n",
       "   mode_Electronegativity  mean_NsValence  maximum_NpValence  mean_NpValence  \\\n",
       "0                0.449317       -1.196825           0.000000        0.477222   \n",
       "1                1.916202       -0.110975           0.584963       -0.223215   \n",
       "2                1.916202        1.809577           0.000000        0.026149   \n",
       "3                0.000000        0.362050           0.584963        1.529725   \n",
       "4                0.449317       -0.535416           0.000000        0.161471   \n",
       "\n",
       "   avg_dev_NpValence  range_NdValence  mean_NdValence  avg_dev_NdValence  \\\n",
       "0           0.422557         0.000000       -0.304043           0.175303   \n",
       "1          -0.254527        -0.666667        1.487024          -0.236945   \n",
       "2           0.020301         0.000000        0.584874          -0.225051   \n",
       "3           1.115875         0.000000       -0.534503           0.775456   \n",
       "4           0.153797         0.000000        0.067211           0.047385   \n",
       "\n",
       "   avg_dev_NValence  mode_NValence  maximum_NdUnfilled  range_NdUnfilled  \\\n",
       "0         -0.008391       0.000000            0.000000               0.0   \n",
       "1         -0.963679       0.560099           -0.333333              -0.5   \n",
       "2         -0.802636       0.560099           -0.333333              -0.5   \n",
       "3          0.299071      -1.247204            0.000000               0.0   \n",
       "4         -0.120768       0.000000            0.000000               0.0   \n",
       "\n",
       "   avg_dev_NdUnfilled  mode_NUnfilled  minimum_GSvolume_pa  range_GSvolume_pa  \\\n",
       "0            0.190333        1.333333             0.000000           0.000000   \n",
       "1           -0.196263       -0.333333             0.000000          10.948033   \n",
       "2           -0.853525        0.000000             0.000000           0.000000   \n",
       "3            0.262099        0.000000           -79.249736           4.490789   \n",
       "4           -0.141745        0.000000             0.000000           0.000000   \n",
       "\n",
       "   mode_GSvolume_pa  maximum_GSbandgap  avg_dev_GSbandgap  range_GSmagmom  \\\n",
       "0          0.336801              0.000           0.000000             0.0   \n",
       "1         -0.030237              0.000           0.000000             0.0   \n",
       "2         -0.030237              0.000           0.000000             0.0   \n",
       "3         -0.030237              4.496           0.616735             0.0   \n",
       "4         -0.030237              0.000           0.000000             0.0   \n",
       "\n",
       "   minimum_SpaceGroupNumber  maximum_SpaceGroupNumber  mean_SpaceGroupNumber  \\\n",
       "0                       0.0                       0.0               0.640823   \n",
       "1                     -53.0                       0.0              -0.640578   \n",
       "2                       0.0                       0.0              -0.694305   \n",
       "3                       0.0                       0.0              -0.283342   \n",
       "4                       0.0                       0.0               0.269152   \n",
       "\n",
       "   range_Column  maximum_NpUnfilled  maximum_NdValence  mode_MendeleevNumber  \\\n",
       "0      0.000000                 0.0                0.0              0.000000   \n",
       "1     -0.333333                -0.2                1.0              0.666667   \n",
       "2     -0.666667                 0.0                0.0              0.666667   \n",
       "3      0.333333                 0.0                0.0              0.000000   \n",
       "4      0.000000                 0.0                0.0              0.000000   \n",
       "\n",
       "   range_NUnfilled  \n",
       "0              0.0  \n",
       "1             -1.0  \n",
       "2             -1.0  \n",
       "3              0.0  \n",
       "4              0.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SCALE FEATURES\n",
    "X = pd.DataFrame(RobustScaler().fit_transform(X), columns=X.columns)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label encode y and then to_categorical\n",
    "lb_enc = LabelEncoder()\n",
    "y = lb_enc.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BCC', 'FCC', 'FCC_BCC', 'MIP']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = list(lb_enc.classes_)\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'BCC': 0, 'FCC': 1, 'FCC_BCC': 2, 'MIP': 3}\n"
     ]
    }
   ],
   "source": [
    "print(dict(zip(lb_enc.inverse_transform([0, 1, 2, 3]), [0, 1, 2, 3])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1369, 42) (343, 42) (1369,) (343,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINE MODEL BUILD FUNCTION\n",
    "def model_builder(hidden_layers, neurons, drop_rate, learning_rate, act_fn='relu'):\n",
    "    set_random_seed(42)\n",
    "    # Add input layer\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(X.shape[1], )))\n",
    "    model.add(Activation(act_fn))\n",
    "    model.add(Dropout(drop_rate))\n",
    "\n",
    "    # add hidden layers\n",
    "    for i in range(hidden_layers):\n",
    "        model.add(Dense(neurons))\n",
    "        model.add(Activation(act_fn))\n",
    "        model.add(Dropout(drop_rate))\n",
    "    \n",
    "    # add final layer\n",
    "    model.add(Dense(4))\n",
    "    model.add(Activation('softmax'))\n",
    "    opt_fn = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=opt_fn, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "# DEFINE OBJECTIVE FUNCTION\n",
    "def obj_fn(trial):\n",
    "    # PARAMETER SPACE\n",
    "    # ACTIVATION = ['relu', 'sigmoid', 'softplus', 'softsign', 'tanh', 'selu', 'elu', 'exponential']\n",
    "    param_space = {\n",
    "        'build_params': {\n",
    "            'hidden_layers': trial.suggest_int(\"hidden_layers\", 1, 10, step=1),\n",
    "            'neurons': trial.suggest_int(\"neurons\", 32, 1024, step=32),\n",
    "            #'act_fn': trial.suggest_categorical(\"act_fn\", ACTIVATION),\n",
    "            'drop_rate': trial.suggest_float(\"drop_rate\", 0.001, 0.1, log=True),\n",
    "            'learning_rate': trial.suggest_float(\"learning_rate\", 1e-7, 1e-3, log=True)\n",
    "        },\n",
    "        'fit_params': {\n",
    "            'batch_size': trial.suggest_int(\"batch_size\", 32, 128, step=16),\n",
    "            'epochs': trial.suggest_int(\"epochs\", 500, 3000, step=500)\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # BUILD MODEL\n",
    "    model = model_builder(**param_space['build_params'])\n",
    "    model.fit(X_train, y_train, **param_space['fit_params'], verbose=0)\n",
    "    _, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "    \n",
    "    return test_acc\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-04 11:53:39,428] A new study created in memory with name: no-name-1f4964fd-9ae3-4209-8ed5-e93e0c2d8b65\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae9c9bd776ea4588811b802e0fe38dba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2024-08-04 11:58:53,272] Trial 0 finished with value: 0.8163265585899353 and parameters: {'hidden_layers': 1, 'neurons': 192, 'drop_rate': 0.08680323206893041, 'learning_rate': 3.0725162942328367e-05, 'batch_size': 32, 'epochs': 500}. Best is trial 0 with value: 0.8163265585899353.\n",
      "[I 2024-08-04 12:02:45,803] Trial 1 finished with value: 0.82798832654953 and parameters: {'hidden_layers': 7, 'neurons': 32, 'drop_rate': 0.09300008330117172, 'learning_rate': 0.00030477112493731246, 'batch_size': 112, 'epochs': 1000}. Best is trial 1 with value: 0.82798832654953.\n",
      "[I 2024-08-04 13:38:48,256] Trial 2 finished with value: 0.8600583076477051 and parameters: {'hidden_layers': 10, 'neurons': 992, 'drop_rate': 0.06927576632874567, 'learning_rate': 2.6056908405603766e-05, 'batch_size': 32, 'epochs': 3000}. Best is trial 2 with value: 0.8600583076477051.\n",
      "[I 2024-08-04 13:44:12,285] Trial 3 finished with value: 0.8338192701339722 and parameters: {'hidden_layers': 1, 'neurons': 448, 'drop_rate': 0.03290165294129646, 'learning_rate': 3.3791172150474745e-05, 'batch_size': 128, 'epochs': 2000}. Best is trial 2 with value: 0.8600583076477051.\n",
      "[I 2024-08-04 13:47:40,679] Trial 4 finished with value: 0.851311981678009 and parameters: {'hidden_layers': 4, 'neurons': 384, 'drop_rate': 0.007993409939112793, 'learning_rate': 0.00011375216343913266, 'batch_size': 48, 'epochs': 500}. Best is trial 2 with value: 0.8600583076477051.\n",
      "[I 2024-08-04 13:51:15,873] Trial 5 finished with value: 0.6734693646430969 and parameters: {'hidden_layers': 7, 'neurons': 768, 'drop_rate': 0.06249367054880629, 'learning_rate': 4.4499377515750424e-07, 'batch_size': 96, 'epochs': 500}. Best is trial 2 with value: 0.8600583076477051.\n",
      "[I 2024-08-04 13:57:51,088] Trial 6 finished with value: 0.82798832654953 and parameters: {'hidden_layers': 9, 'neurons': 160, 'drop_rate': 0.0015949582204576509, 'learning_rate': 6.8657051363797115e-06, 'batch_size': 64, 'epochs': 1000}. Best is trial 2 with value: 0.8600583076477051.\n",
      "[I 2024-08-04 14:14:02,599] Trial 7 finished with value: 0.4664722979068756 and parameters: {'hidden_layers': 7, 'neurons': 96, 'drop_rate': 0.01529769657291029, 'learning_rate': 1.0648541055078186e-07, 'batch_size': 32, 'epochs': 1500}. Best is trial 2 with value: 0.8600583076477051.\n",
      "[I 2024-08-04 14:18:31,661] Trial 8 finished with value: 0.8688046932220459 and parameters: {'hidden_layers': 3, 'neurons': 896, 'drop_rate': 0.029751265973292758, 'learning_rate': 0.0004491826558671797, 'batch_size': 96, 'epochs': 1000}. Best is trial 8 with value: 0.8688046932220459.\n",
      "[I 2024-08-04 15:05:04,265] Trial 9 finished with value: 0.8483964800834656 and parameters: {'hidden_layers': 7, 'neurons': 960, 'drop_rate': 0.023520233713389464, 'learning_rate': 7.33402031540349e-05, 'batch_size': 48, 'epochs': 3000}. Best is trial 8 with value: 0.8688046932220459.\n",
      "[I 2024-08-04 15:16:13,045] Trial 10 finished with value: 0.8483964800834656 and parameters: {'hidden_layers': 4, 'neurons': 704, 'drop_rate': 0.006182732358435303, 'learning_rate': 2.4736389624058707e-06, 'batch_size': 80, 'epochs': 2000}. Best is trial 8 with value: 0.8688046932220459.\n",
      "[I 2024-08-04 15:30:37,682] Trial 11 finished with value: 0.8629737496376038 and parameters: {'hidden_layers': 3, 'neurons': 1024, 'drop_rate': 0.03794930045857273, 'learning_rate': 0.000795268017029209, 'batch_size': 96, 'epochs': 3000}. Best is trial 8 with value: 0.8688046932220459.\n",
      "[I 2024-08-04 15:41:52,836] Trial 12 finished with value: 0.8600583076477051 and parameters: {'hidden_layers': 3, 'neurons': 800, 'drop_rate': 0.031370201668416954, 'learning_rate': 0.0009141084802620839, 'batch_size': 96, 'epochs': 2500}. Best is trial 8 with value: 0.8688046932220459.\n",
      "[I 2024-08-04 15:49:08,241] Trial 13 finished with value: 0.8658891916275024 and parameters: {'hidden_layers': 3, 'neurons': 1024, 'drop_rate': 0.015772020217296383, 'learning_rate': 0.0009755140807213231, 'batch_size': 96, 'epochs': 1500}. Best is trial 8 with value: 0.8688046932220459.\n",
      "[I 2024-08-04 15:52:32,389] Trial 14 finished with value: 0.8600583076477051 and parameters: {'hidden_layers': 2, 'neurons': 608, 'drop_rate': 0.00370928494201726, 'learning_rate': 0.0002075535914929469, 'batch_size': 128, 'epochs': 1500}. Best is trial 8 with value: 0.8688046932220459.\n",
      "[I 2024-08-04 16:00:14,044] Trial 15 finished with value: 0.8571428656578064 and parameters: {'hidden_layers': 5, 'neurons': 896, 'drop_rate': 0.01450514803061223, 'learning_rate': 0.00040140505290012257, 'batch_size': 80, 'epochs': 1000}. Best is trial 8 with value: 0.8688046932220459.\n",
      "[I 2024-08-04 16:08:40,912] Trial 16 finished with value: 0.8600583076477051 and parameters: {'hidden_layers': 5, 'neurons': 864, 'drop_rate': 0.0038707538134167075, 'learning_rate': 0.000986834321401422, 'batch_size': 112, 'epochs': 1500}. Best is trial 8 with value: 0.8688046932220459.\n",
      "[I 2024-08-04 16:12:16,996] Trial 17 finished with value: 0.8163265585899353 and parameters: {'hidden_layers': 3, 'neurons': 672, 'drop_rate': 0.015015836467931492, 'learning_rate': 2.097719714467032e-06, 'batch_size': 112, 'epochs': 1000}. Best is trial 8 with value: 0.8688046932220459.\n",
      "[I 2024-08-04 16:20:19,235] Trial 18 finished with value: 0.8396501541137695 and parameters: {'hidden_layers': 2, 'neurons': 544, 'drop_rate': 0.001201207242857878, 'learning_rate': 0.00010924921436869341, 'batch_size': 64, 'epochs': 2000}. Best is trial 8 with value: 0.8688046932220459.\n",
      "[I 2024-08-04 16:33:53,203] Trial 19 finished with value: 0.8454810380935669 and parameters: {'hidden_layers': 4, 'neurons': 896, 'drop_rate': 0.0447413481704662, 'learning_rate': 1.2378758332349065e-05, 'batch_size': 96, 'epochs': 2500}. Best is trial 8 with value: 0.8688046932220459.\n",
      "[I 2024-08-04 16:42:35,141] Trial 20 finished with value: 0.851311981678009 and parameters: {'hidden_layers': 6, 'neurons': 352, 'drop_rate': 0.01893722775401079, 'learning_rate': 0.0003537350119571494, 'batch_size': 64, 'epochs': 1500}. Best is trial 8 with value: 0.8688046932220459.\n",
      "[I 2024-08-04 16:47:23,447] Trial 21 finished with value: 0.8629737496376038 and parameters: {'hidden_layers': 3, 'neurons': 1024, 'drop_rate': 0.043509601665737085, 'learning_rate': 0.000974752637762039, 'batch_size': 96, 'epochs': 1000}. Best is trial 8 with value: 0.8688046932220459.\n",
      "[I 2024-08-04 16:58:48,798] Trial 22 finished with value: 0.8775510191917419 and parameters: {'hidden_layers': 2, 'neurons': 992, 'drop_rate': 0.026069316453991312, 'learning_rate': 0.00048178791904500857, 'batch_size': 80, 'epochs': 2500}. Best is trial 22 with value: 0.8775510191917419.\n",
      "[I 2024-08-04 17:09:19,952] Trial 23 finished with value: 0.8571428656578064 and parameters: {'hidden_layers': 2, 'neurons': 832, 'drop_rate': 0.011434803301047443, 'learning_rate': 0.00015988740489326504, 'batch_size': 80, 'epochs': 2500}. Best is trial 22 with value: 0.8775510191917419.\n",
      "[I 2024-08-04 17:15:09,818] Trial 24 finished with value: 0.8571428656578064 and parameters: {'hidden_layers': 1, 'neurons': 960, 'drop_rate': 0.023778118244984103, 'learning_rate': 0.0004132477941865196, 'batch_size': 80, 'epochs': 2000}. Best is trial 22 with value: 0.8775510191917419.\n",
      "[I 2024-08-04 17:22:13,469] Trial 25 finished with value: 0.8425655961036682 and parameters: {'hidden_layers': 2, 'neurons': 736, 'drop_rate': 0.008647182076900772, 'learning_rate': 6.483975718942728e-05, 'batch_size': 112, 'epochs': 2500}. Best is trial 22 with value: 0.8775510191917419.\n",
      "[I 2024-08-04 17:31:57,979] Trial 26 finished with value: 0.8658891916275024 and parameters: {'hidden_layers': 4, 'neurons': 896, 'drop_rate': 0.024513577717516267, 'learning_rate': 0.00041905308873513454, 'batch_size': 80, 'epochs': 1500}. Best is trial 22 with value: 0.8775510191917419.\n",
      "[I 2024-08-04 17:45:36,007] Trial 27 finished with value: 0.8600583076477051 and parameters: {'hidden_layers': 5, 'neurons': 960, 'drop_rate': 0.004983230238743342, 'learning_rate': 0.00021396839791375626, 'batch_size': 96, 'epochs': 2000}. Best is trial 22 with value: 0.8775510191917419.\n",
      "[I 2024-08-04 17:50:14,578] Trial 28 finished with value: 0.8396501541137695 and parameters: {'hidden_layers': 2, 'neurons': 832, 'drop_rate': 0.05160143208370784, 'learning_rate': 5.946615316005171e-05, 'batch_size': 64, 'epochs': 1000}. Best is trial 22 with value: 0.8775510191917419.\n",
      "[I 2024-08-04 17:51:40,529] Trial 29 finished with value: 0.737609326839447 and parameters: {'hidden_layers': 1, 'neurons': 256, 'drop_rate': 0.012343604872963376, 'learning_rate': 1.6238987448223943e-05, 'batch_size': 112, 'epochs': 500}. Best is trial 22 with value: 0.8775510191917419.\n",
      "[I 2024-08-04 17:55:50,313] Trial 30 finished with value: 0.8600583076477051 and parameters: {'hidden_layers': 3, 'neurons': 608, 'drop_rate': 0.021473901505802397, 'learning_rate': 0.0005500001026003257, 'batch_size': 128, 'epochs': 1500}. Best is trial 22 with value: 0.8775510191917419.\n",
      "[I 2024-08-04 18:05:20,636] Trial 31 finished with value: 0.8571428656578064 and parameters: {'hidden_layers': 4, 'neurons': 928, 'drop_rate': 0.028875696549294887, 'learning_rate': 0.0005434458199440913, 'batch_size': 80, 'epochs': 1500}. Best is trial 22 with value: 0.8775510191917419.\n",
      "[I 2024-08-04 18:15:48,623] Trial 32 finished with value: 0.8454810380935669 and parameters: {'hidden_layers': 4, 'neurons': 1024, 'drop_rate': 0.01822766734419389, 'learning_rate': 0.0002438126286860685, 'batch_size': 80, 'epochs': 1500}. Best is trial 22 with value: 0.8775510191917419.\n",
      "[I 2024-08-04 18:20:09,654] Trial 33 finished with value: 0.8658891916275024 and parameters: {'hidden_layers': 3, 'neurons': 896, 'drop_rate': 0.07821789315591827, 'learning_rate': 0.0001270308071330939, 'batch_size': 96, 'epochs': 1000}. Best is trial 22 with value: 0.8775510191917419.\n",
      "[I 2024-08-04 18:32:49,209] Trial 34 finished with value: 0.8454810380935669 and parameters: {'hidden_layers': 6, 'neurons': 800, 'drop_rate': 0.09939633692248641, 'learning_rate': 0.0005274466507379557, 'batch_size': 80, 'epochs': 1500}. Best is trial 22 with value: 0.8775510191917419.\n",
      "[I 2024-08-04 18:43:55,109] Trial 35 finished with value: 0.8396501541137695 and parameters: {'hidden_layers': 1, 'neurons': 960, 'drop_rate': 0.02817979934884724, 'learning_rate': 3.490346058165587e-05, 'batch_size': 64, 'epochs': 2000}. Best is trial 22 with value: 0.8775510191917419.\n",
      "[I 2024-08-04 18:45:59,645] Trial 36 finished with value: 0.8483964800834656 and parameters: {'hidden_layers': 2, 'neurons': 1024, 'drop_rate': 0.05443986525467628, 'learning_rate': 0.0002877661852188798, 'batch_size': 96, 'epochs': 500}. Best is trial 22 with value: 0.8775510191917419.\n",
      "[I 2024-08-04 18:50:48,048] Trial 37 finished with value: 0.8688046932220459 and parameters: {'hidden_layers': 4, 'neurons': 864, 'drop_rate': 0.009327642047677966, 'learning_rate': 0.0005958500571902267, 'batch_size': 112, 'epochs': 1000}. Best is trial 22 with value: 0.8775510191917419.\n",
      "[I 2024-08-04 18:55:10,391] Trial 38 finished with value: 0.8425655961036682 and parameters: {'hidden_layers': 10, 'neurons': 768, 'drop_rate': 0.0068059497549031464, 'learning_rate': 0.0006465289004884164, 'batch_size': 112, 'epochs': 500}. Best is trial 22 with value: 0.8775510191917419.\n",
      "[I 2024-08-04 18:59:29,817] Trial 39 finished with value: 0.8396501541137695 and parameters: {'hidden_layers': 5, 'neurons': 672, 'drop_rate': 0.009862686449854476, 'learning_rate': 3.9094377369002375e-06, 'batch_size': 128, 'epochs': 1000}. Best is trial 22 with value: 0.8775510191917419.\n",
      "[I 2024-08-04 19:07:41,337] Trial 40 finished with value: 0.7725947499275208 and parameters: {'hidden_layers': 8, 'neurons': 832, 'drop_rate': 0.0031018412373745186, 'learning_rate': 3.901267725159909e-07, 'batch_size': 112, 'epochs': 1000}. Best is trial 22 with value: 0.8775510191917419.\n",
      "[I 2024-08-04 19:13:17,325] Trial 41 finished with value: 0.8658891916275024 and parameters: {'hidden_layers': 4, 'neurons': 928, 'drop_rate': 0.017094661185434342, 'learning_rate': 0.0003091769908266877, 'batch_size': 96, 'epochs': 1000}. Best is trial 22 with value: 0.8775510191917419.\n",
      "[I 2024-08-04 19:22:34,994] Trial 42 finished with value: 0.8717201352119446 and parameters: {'hidden_layers': 3, 'neurons': 992, 'drop_rate': 0.02507067932441517, 'learning_rate': 0.00016395688691546193, 'batch_size': 80, 'epochs': 1500}. Best is trial 22 with value: 0.8775510191917419.\n",
      "[I 2024-08-04 19:37:16,168] Trial 43 finished with value: 0.8600583076477051 and parameters: {'hidden_layers': 3, 'neurons': 960, 'drop_rate': 0.011646597271193056, 'learning_rate': 9.524745766465566e-05, 'batch_size': 96, 'epochs': 3000}. Best is trial 22 with value: 0.8775510191917419.\n",
      "[I 2024-08-04 19:42:10,371] Trial 44 finished with value: 0.8571428656578064 and parameters: {'hidden_layers': 3, 'neurons': 992, 'drop_rate': 0.03649881474168386, 'learning_rate': 0.00018947680675016008, 'batch_size': 48, 'epochs': 500}. Best is trial 22 with value: 0.8775510191917419.\n",
      "[I 2024-08-04 19:49:22,637] Trial 45 finished with value: 0.8600583076477051 and parameters: {'hidden_layers': 2, 'neurons': 1024, 'drop_rate': 0.02072381868561913, 'learning_rate': 0.0006508558510418885, 'batch_size': 112, 'epochs': 2000}. Best is trial 22 with value: 0.8775510191917419.\n",
      "[I 2024-08-04 19:54:59,085] Trial 46 finished with value: 0.8571428656578064 and parameters: {'hidden_layers': 4, 'neurons': 864, 'drop_rate': 0.013665691466152605, 'learning_rate': 4.846485547449615e-05, 'batch_size': 96, 'epochs': 1000}. Best is trial 22 with value: 0.8775510191917419.\n",
      "[I 2024-08-04 20:05:35,972] Trial 47 finished with value: 0.8775510191917419 and parameters: {'hidden_layers': 3, 'neurons': 928, 'drop_rate': 0.00869049008467767, 'learning_rate': 0.0009683066741064406, 'batch_size': 64, 'epochs': 1500}. Best is trial 22 with value: 0.8775510191917419.\n",
      "[I 2024-08-04 20:16:24,863] Trial 48 finished with value: 0.8454810380935669 and parameters: {'hidden_layers': 2, 'neurons': 32, 'drop_rate': 0.006028019620272138, 'learning_rate': 0.0001298206327475195, 'batch_size': 48, 'epochs': 1500}. Best is trial 22 with value: 0.8775510191917419.\n",
      "[I 2024-08-04 20:21:26,627] Trial 49 finished with value: 0.8629737496376038 and parameters: {'hidden_layers': 3, 'neurons': 480, 'drop_rate': 0.007773569598615977, 'learning_rate': 0.0007036389964454558, 'batch_size': 64, 'epochs': 1000}. Best is trial 22 with value: 0.8775510191917419.\n"
     ]
    }
   ],
   "source": [
    "# PERFORM BAYESIAN OPTIMIZATION\n",
    "tpe = optuna.samplers.TPESampler()\n",
    "study = optuna.create_study(direction=\"maximize\", sampler=tpe)\n",
    "study.optimize(obj_fn, n_trials=50, show_progress_bar=True)                                                                                                                                               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters\n",
      "--------------------------------------------------\n",
      "{'build_params': {'hidden_layers': 2, 'drop_rate': 0.026069316453991312, 'neurons': 992, 'learning_rate': 0.00048178791904500857}, 'fit_params': {'batch_size': 80, 'epochs': 2500}}\n"
     ]
    }
   ],
   "source": [
    "# BEST PARAMETERS\n",
    "best_params_dict = study.best_params\n",
    "best_model_params = {\n",
    "    'build_params': {\n",
    "        'hidden_layers': best_params_dict['hidden_layers'],\n",
    "        'drop_rate': best_params_dict['drop_rate'],\n",
    "        'neurons': best_params_dict['neurons'],\n",
    "        'learning_rate': best_params_dict['learning_rate']\n",
    "    },\n",
    "    'fit_params': {\n",
    "        'batch_size': best_params_dict['batch_size'],\n",
    "        'epochs': best_params_dict['epochs']\n",
    "    }\n",
    "}\n",
    "print(\"Best Parameters\")\n",
    "print(\"-\"*50)\n",
    "print(best_model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2500\n",
      "18/18 [==============================] - 2s 54ms/step - loss: 1.1937 - accuracy: 0.5296 - val_loss: 0.9321 - val_accuracy: 0.6589\n",
      "Epoch 2/2500\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.8707 - accuracy: 0.6844 - val_loss: 0.8733 - val_accuracy: 0.6706\n",
      "Epoch 3/2500\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.7773 - accuracy: 0.7012 - val_loss: 0.7180 - val_accuracy: 0.7493\n",
      "Epoch 4/2500\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.7452 - accuracy: 0.7173 - val_loss: 0.7194 - val_accuracy: 0.7230\n",
      "Epoch 5/2500\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.7141 - accuracy: 0.7348 - val_loss: 0.6631 - val_accuracy: 0.7580\n",
      "Epoch 6/2500\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.6537 - accuracy: 0.7589 - val_loss: 0.6416 - val_accuracy: 0.7784\n",
      "Epoch 7/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.6556 - accuracy: 0.7619 - val_loss: 0.6869 - val_accuracy: 0.7493\n",
      "Epoch 8/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.6982 - accuracy: 0.7589 - val_loss: 0.6985 - val_accuracy: 0.7522\n",
      "Epoch 9/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.6344 - accuracy: 0.7757 - val_loss: 0.6303 - val_accuracy: 0.7609\n",
      "Epoch 10/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.5809 - accuracy: 0.7984 - val_loss: 0.6273 - val_accuracy: 0.7872\n",
      "Epoch 11/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.5451 - accuracy: 0.8050 - val_loss: 0.6252 - val_accuracy: 0.7843\n",
      "Epoch 12/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.5628 - accuracy: 0.8020 - val_loss: 0.6096 - val_accuracy: 0.7784\n",
      "Epoch 13/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.5470 - accuracy: 0.8064 - val_loss: 0.5544 - val_accuracy: 0.8017\n",
      "Epoch 14/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.5300 - accuracy: 0.8152 - val_loss: 0.5630 - val_accuracy: 0.7988\n",
      "Epoch 15/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.5159 - accuracy: 0.8188 - val_loss: 0.6026 - val_accuracy: 0.7901\n",
      "Epoch 16/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.5067 - accuracy: 0.8320 - val_loss: 0.6137 - val_accuracy: 0.7755\n",
      "Epoch 17/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.5339 - accuracy: 0.8108 - val_loss: 0.5598 - val_accuracy: 0.8047\n",
      "Epoch 18/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.5546 - accuracy: 0.8130 - val_loss: 0.5713 - val_accuracy: 0.7930\n",
      "Epoch 19/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.4948 - accuracy: 0.8269 - val_loss: 0.5233 - val_accuracy: 0.8280\n",
      "Epoch 20/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.4797 - accuracy: 0.8342 - val_loss: 0.5221 - val_accuracy: 0.8076\n",
      "Epoch 21/2500\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.4786 - accuracy: 0.8269 - val_loss: 0.5424 - val_accuracy: 0.8192\n",
      "Epoch 22/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.5755 - accuracy: 0.8188 - val_loss: 0.5383 - val_accuracy: 0.8192\n",
      "Epoch 23/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.4684 - accuracy: 0.8283 - val_loss: 0.5054 - val_accuracy: 0.8105\n",
      "Epoch 24/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.4443 - accuracy: 0.8444 - val_loss: 0.5435 - val_accuracy: 0.8222\n",
      "Epoch 25/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.4693 - accuracy: 0.8342 - val_loss: 0.5682 - val_accuracy: 0.7930\n",
      "Epoch 26/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.4610 - accuracy: 0.8400 - val_loss: 0.5563 - val_accuracy: 0.7988\n",
      "Epoch 27/2500\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 0.4699 - accuracy: 0.8276 - val_loss: 0.5371 - val_accuracy: 0.8163\n",
      "Epoch 28/2500\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.4622 - accuracy: 0.8386 - val_loss: 0.5528 - val_accuracy: 0.7959\n",
      "Epoch 29/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.4265 - accuracy: 0.8495 - val_loss: 0.5253 - val_accuracy: 0.8134\n",
      "Epoch 30/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.4451 - accuracy: 0.8415 - val_loss: 0.5158 - val_accuracy: 0.8192\n",
      "Epoch 31/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.4299 - accuracy: 0.8430 - val_loss: 0.5094 - val_accuracy: 0.8309\n",
      "Epoch 32/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.4285 - accuracy: 0.8495 - val_loss: 0.5339 - val_accuracy: 0.8280\n",
      "Epoch 33/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.4136 - accuracy: 0.8517 - val_loss: 0.5332 - val_accuracy: 0.8338\n",
      "Epoch 34/2500\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.4386 - accuracy: 0.8510 - val_loss: 0.5347 - val_accuracy: 0.8047\n",
      "Epoch 35/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.4426 - accuracy: 0.8437 - val_loss: 0.4773 - val_accuracy: 0.8426\n",
      "Epoch 36/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.4182 - accuracy: 0.8510 - val_loss: 0.4971 - val_accuracy: 0.8338\n",
      "Epoch 37/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.4541 - accuracy: 0.8371 - val_loss: 0.5305 - val_accuracy: 0.8222\n",
      "Epoch 38/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.4120 - accuracy: 0.8546 - val_loss: 0.4787 - val_accuracy: 0.8542\n",
      "Epoch 39/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.4012 - accuracy: 0.8590 - val_loss: 0.5435 - val_accuracy: 0.8251\n",
      "Epoch 40/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.3926 - accuracy: 0.8590 - val_loss: 0.5157 - val_accuracy: 0.8105\n",
      "Epoch 41/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.4003 - accuracy: 0.8634 - val_loss: 0.5076 - val_accuracy: 0.8251\n",
      "Epoch 42/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.4315 - accuracy: 0.8481 - val_loss: 0.5072 - val_accuracy: 0.8309\n",
      "Epoch 43/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.4015 - accuracy: 0.8649 - val_loss: 0.5017 - val_accuracy: 0.8163\n",
      "Epoch 44/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.3894 - accuracy: 0.8568 - val_loss: 0.5063 - val_accuracy: 0.8338\n",
      "Epoch 45/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.3800 - accuracy: 0.8605 - val_loss: 0.4772 - val_accuracy: 0.8309\n",
      "Epoch 46/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.4024 - accuracy: 0.8517 - val_loss: 0.5203 - val_accuracy: 0.8367\n",
      "Epoch 47/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.4075 - accuracy: 0.8641 - val_loss: 0.5543 - val_accuracy: 0.7930\n",
      "Epoch 48/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.4153 - accuracy: 0.8481 - val_loss: 0.5744 - val_accuracy: 0.8513\n",
      "Epoch 49/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.3922 - accuracy: 0.8598 - val_loss: 0.5117 - val_accuracy: 0.8251\n",
      "Epoch 50/2500\n",
      "18/18 [==============================] - 0s 28ms/step - loss: 0.3742 - accuracy: 0.8707 - val_loss: 0.5246 - val_accuracy: 0.8251\n",
      "Epoch 51/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.3719 - accuracy: 0.8692 - val_loss: 0.5216 - val_accuracy: 0.7988\n",
      "Epoch 52/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.3749 - accuracy: 0.8671 - val_loss: 0.4819 - val_accuracy: 0.8397\n",
      "Epoch 53/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.3618 - accuracy: 0.8663 - val_loss: 0.4792 - val_accuracy: 0.8659\n",
      "Epoch 54/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.3920 - accuracy: 0.8576 - val_loss: 0.4981 - val_accuracy: 0.8367\n",
      "Epoch 55/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.3977 - accuracy: 0.8641 - val_loss: 0.4933 - val_accuracy: 0.8017\n",
      "Epoch 56/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.3666 - accuracy: 0.8678 - val_loss: 0.5199 - val_accuracy: 0.8251\n",
      "Epoch 57/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.3788 - accuracy: 0.8634 - val_loss: 0.5179 - val_accuracy: 0.8280\n",
      "Epoch 58/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.3576 - accuracy: 0.8744 - val_loss: 0.4955 - val_accuracy: 0.8309\n",
      "Epoch 59/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.3439 - accuracy: 0.8758 - val_loss: 0.4805 - val_accuracy: 0.8484\n",
      "Epoch 60/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.3448 - accuracy: 0.8780 - val_loss: 0.5409 - val_accuracy: 0.8367\n",
      "Epoch 61/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.3582 - accuracy: 0.8722 - val_loss: 0.4690 - val_accuracy: 0.8309\n",
      "Epoch 62/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.3665 - accuracy: 0.8714 - val_loss: 0.5047 - val_accuracy: 0.8367\n",
      "Epoch 63/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.3722 - accuracy: 0.8590 - val_loss: 0.5222 - val_accuracy: 0.8134\n",
      "Epoch 64/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.3477 - accuracy: 0.8692 - val_loss: 0.4806 - val_accuracy: 0.8484\n",
      "Epoch 65/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.3733 - accuracy: 0.8656 - val_loss: 0.4787 - val_accuracy: 0.8484\n",
      "Epoch 66/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.3629 - accuracy: 0.8634 - val_loss: 0.4845 - val_accuracy: 0.8397\n",
      "Epoch 67/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.3463 - accuracy: 0.8751 - val_loss: 0.5318 - val_accuracy: 0.8338\n",
      "Epoch 68/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.3312 - accuracy: 0.8795 - val_loss: 0.4833 - val_accuracy: 0.8455\n",
      "Epoch 69/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.3167 - accuracy: 0.8912 - val_loss: 0.5327 - val_accuracy: 0.8134\n",
      "Epoch 70/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.3403 - accuracy: 0.8729 - val_loss: 0.4926 - val_accuracy: 0.8309\n",
      "Epoch 71/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.3328 - accuracy: 0.8860 - val_loss: 0.4662 - val_accuracy: 0.8542\n",
      "Epoch 72/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.3466 - accuracy: 0.8787 - val_loss: 0.5213 - val_accuracy: 0.8222\n",
      "Epoch 73/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.3283 - accuracy: 0.8795 - val_loss: 0.5305 - val_accuracy: 0.8251\n",
      "Epoch 74/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.3191 - accuracy: 0.8890 - val_loss: 0.4881 - val_accuracy: 0.8367\n",
      "Epoch 75/2500\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.3249 - accuracy: 0.8744 - val_loss: 0.4858 - val_accuracy: 0.8309\n",
      "Epoch 76/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.3378 - accuracy: 0.8824 - val_loss: 0.5010 - val_accuracy: 0.8455\n",
      "Epoch 77/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.3240 - accuracy: 0.8853 - val_loss: 0.4679 - val_accuracy: 0.8542\n",
      "Epoch 78/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.3401 - accuracy: 0.8722 - val_loss: 0.5228 - val_accuracy: 0.8309\n",
      "Epoch 79/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.3628 - accuracy: 0.8663 - val_loss: 0.5139 - val_accuracy: 0.8251\n",
      "Epoch 80/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.3351 - accuracy: 0.8736 - val_loss: 0.5222 - val_accuracy: 0.8309\n",
      "Epoch 81/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.3158 - accuracy: 0.8839 - val_loss: 0.5016 - val_accuracy: 0.8338\n",
      "Epoch 82/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.3172 - accuracy: 0.8853 - val_loss: 0.4848 - val_accuracy: 0.8338\n",
      "Epoch 83/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.3042 - accuracy: 0.8707 - val_loss: 0.4969 - val_accuracy: 0.8426\n",
      "Epoch 84/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.2865 - accuracy: 0.8955 - val_loss: 0.4860 - val_accuracy: 0.8367\n",
      "Epoch 85/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.3156 - accuracy: 0.8926 - val_loss: 0.4970 - val_accuracy: 0.8513\n",
      "Epoch 86/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.3188 - accuracy: 0.8758 - val_loss: 0.5577 - val_accuracy: 0.8047\n",
      "Epoch 87/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.3270 - accuracy: 0.8802 - val_loss: 0.5082 - val_accuracy: 0.8426\n",
      "Epoch 88/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.3201 - accuracy: 0.8809 - val_loss: 0.5001 - val_accuracy: 0.8513\n",
      "Epoch 89/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.3144 - accuracy: 0.8860 - val_loss: 0.5115 - val_accuracy: 0.8309\n",
      "Epoch 90/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.3229 - accuracy: 0.8780 - val_loss: 0.4888 - val_accuracy: 0.8455\n",
      "Epoch 91/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.3115 - accuracy: 0.8890 - val_loss: 0.4868 - val_accuracy: 0.8513\n",
      "Epoch 92/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.3233 - accuracy: 0.8787 - val_loss: 0.5182 - val_accuracy: 0.8397\n",
      "Epoch 93/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.3133 - accuracy: 0.8934 - val_loss: 0.4896 - val_accuracy: 0.8309\n",
      "Epoch 94/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.3176 - accuracy: 0.8831 - val_loss: 0.5241 - val_accuracy: 0.8338\n",
      "Epoch 95/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.2894 - accuracy: 0.8904 - val_loss: 0.4791 - val_accuracy: 0.8484\n",
      "Epoch 96/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.2961 - accuracy: 0.8970 - val_loss: 0.5162 - val_accuracy: 0.8367\n",
      "Epoch 97/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.3144 - accuracy: 0.8758 - val_loss: 0.5193 - val_accuracy: 0.8338\n",
      "Epoch 98/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.2871 - accuracy: 0.8926 - val_loss: 0.5259 - val_accuracy: 0.8367\n",
      "Epoch 99/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.2861 - accuracy: 0.8897 - val_loss: 0.4784 - val_accuracy: 0.8455\n",
      "Epoch 100/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.3024 - accuracy: 0.8817 - val_loss: 0.5142 - val_accuracy: 0.8192\n",
      "Epoch 101/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.3027 - accuracy: 0.8912 - val_loss: 0.4941 - val_accuracy: 0.8280\n",
      "Epoch 102/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.3101 - accuracy: 0.8875 - val_loss: 0.5091 - val_accuracy: 0.8367\n",
      "Epoch 103/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.2930 - accuracy: 0.8955 - val_loss: 0.4848 - val_accuracy: 0.8397\n",
      "Epoch 104/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.2971 - accuracy: 0.8868 - val_loss: 0.5031 - val_accuracy: 0.8397\n",
      "Epoch 105/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.2830 - accuracy: 0.8897 - val_loss: 0.5200 - val_accuracy: 0.8309\n",
      "Epoch 106/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.2670 - accuracy: 0.8992 - val_loss: 0.4760 - val_accuracy: 0.8397\n",
      "Epoch 107/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.2684 - accuracy: 0.8970 - val_loss: 0.5459 - val_accuracy: 0.8192\n",
      "Epoch 108/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.2671 - accuracy: 0.8948 - val_loss: 0.5139 - val_accuracy: 0.8280\n",
      "Epoch 109/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.2771 - accuracy: 0.8970 - val_loss: 0.5158 - val_accuracy: 0.8455\n",
      "Epoch 110/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.2788 - accuracy: 0.8955 - val_loss: 0.5012 - val_accuracy: 0.8367\n",
      "Epoch 111/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.2914 - accuracy: 0.8882 - val_loss: 0.4869 - val_accuracy: 0.8484\n",
      "Epoch 112/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.2760 - accuracy: 0.8970 - val_loss: 0.4939 - val_accuracy: 0.8484\n",
      "Epoch 113/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.2705 - accuracy: 0.8977 - val_loss: 0.5246 - val_accuracy: 0.8367\n",
      "Epoch 114/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.2727 - accuracy: 0.9014 - val_loss: 0.5124 - val_accuracy: 0.8484\n",
      "Epoch 115/2500\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.2846 - accuracy: 0.8934 - val_loss: 0.4999 - val_accuracy: 0.8542\n",
      "Epoch 116/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.2742 - accuracy: 0.8963 - val_loss: 0.5102 - val_accuracy: 0.8426\n",
      "Epoch 117/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.2589 - accuracy: 0.9058 - val_loss: 0.5440 - val_accuracy: 0.8076\n",
      "Epoch 118/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.2661 - accuracy: 0.8970 - val_loss: 0.5003 - val_accuracy: 0.8513\n",
      "Epoch 119/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.2676 - accuracy: 0.8963 - val_loss: 0.5514 - val_accuracy: 0.8542\n",
      "Epoch 120/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.2859 - accuracy: 0.8955 - val_loss: 0.5063 - val_accuracy: 0.8397\n",
      "Epoch 121/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.2957 - accuracy: 0.8817 - val_loss: 0.5260 - val_accuracy: 0.8426\n",
      "Epoch 122/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.2744 - accuracy: 0.8897 - val_loss: 0.5145 - val_accuracy: 0.8309\n",
      "Epoch 123/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.2830 - accuracy: 0.8904 - val_loss: 0.5028 - val_accuracy: 0.8309\n",
      "Epoch 124/2500\n",
      "18/18 [==============================] - 1s 28ms/step - loss: 0.2927 - accuracy: 0.8860 - val_loss: 0.4785 - val_accuracy: 0.8426\n",
      "Epoch 125/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.2681 - accuracy: 0.9021 - val_loss: 0.4979 - val_accuracy: 0.8397\n",
      "Epoch 126/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.2592 - accuracy: 0.9065 - val_loss: 0.5264 - val_accuracy: 0.8367\n",
      "Epoch 127/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.2745 - accuracy: 0.8926 - val_loss: 0.4770 - val_accuracy: 0.8397\n",
      "Epoch 128/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.2822 - accuracy: 0.8912 - val_loss: 0.5725 - val_accuracy: 0.8017\n",
      "Epoch 129/2500\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.2846 - accuracy: 0.8890 - val_loss: 0.5622 - val_accuracy: 0.8397\n",
      "Epoch 130/2500\n",
      "18/18 [==============================] - 1s 28ms/step - loss: 0.2652 - accuracy: 0.9021 - val_loss: 0.5263 - val_accuracy: 0.8309\n",
      "Epoch 131/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.2596 - accuracy: 0.8985 - val_loss: 0.5445 - val_accuracy: 0.8455\n",
      "Epoch 132/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.2694 - accuracy: 0.9021 - val_loss: 0.5285 - val_accuracy: 0.8455\n",
      "Epoch 133/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.2748 - accuracy: 0.8890 - val_loss: 0.5164 - val_accuracy: 0.8338\n",
      "Epoch 134/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.2871 - accuracy: 0.8926 - val_loss: 0.4919 - val_accuracy: 0.8426\n",
      "Epoch 135/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.2739 - accuracy: 0.8955 - val_loss: 0.5166 - val_accuracy: 0.8426\n",
      "Epoch 136/2500\n",
      "18/18 [==============================] - 1s 28ms/step - loss: 0.2743 - accuracy: 0.9043 - val_loss: 0.5260 - val_accuracy: 0.8367\n",
      "Epoch 137/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.2535 - accuracy: 0.8999 - val_loss: 0.5371 - val_accuracy: 0.8280\n",
      "Epoch 138/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.2608 - accuracy: 0.9043 - val_loss: 0.5142 - val_accuracy: 0.8280\n",
      "Epoch 139/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.2696 - accuracy: 0.8977 - val_loss: 0.5578 - val_accuracy: 0.8280\n",
      "Epoch 140/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.2385 - accuracy: 0.9102 - val_loss: 0.5071 - val_accuracy: 0.8426\n",
      "Epoch 141/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.2477 - accuracy: 0.9102 - val_loss: 0.5058 - val_accuracy: 0.8513\n",
      "Epoch 142/2500\n",
      "18/18 [==============================] - 1s 28ms/step - loss: 0.2593 - accuracy: 0.8919 - val_loss: 0.5112 - val_accuracy: 0.8484\n",
      "Epoch 143/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.2459 - accuracy: 0.9036 - val_loss: 0.5361 - val_accuracy: 0.8367\n",
      "Epoch 144/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.2585 - accuracy: 0.9007 - val_loss: 0.5398 - val_accuracy: 0.8338\n",
      "Epoch 145/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.2564 - accuracy: 0.9028 - val_loss: 0.5293 - val_accuracy: 0.8397\n",
      "Epoch 146/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.2548 - accuracy: 0.9036 - val_loss: 0.5511 - val_accuracy: 0.8338\n",
      "Epoch 147/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.2519 - accuracy: 0.9065 - val_loss: 0.5292 - val_accuracy: 0.8542\n",
      "Epoch 148/2500\n",
      "18/18 [==============================] - 1s 28ms/step - loss: 0.2612 - accuracy: 0.8934 - val_loss: 0.5863 - val_accuracy: 0.8251\n",
      "Epoch 149/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.2601 - accuracy: 0.8963 - val_loss: 0.5254 - val_accuracy: 0.8163\n",
      "Epoch 150/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.2611 - accuracy: 0.9036 - val_loss: 0.5185 - val_accuracy: 0.8426\n",
      "Epoch 151/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.2498 - accuracy: 0.9058 - val_loss: 0.5546 - val_accuracy: 0.8309\n",
      "Epoch 152/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.2371 - accuracy: 0.9116 - val_loss: 0.5228 - val_accuracy: 0.8455\n",
      "Epoch 153/2500\n",
      "18/18 [==============================] - 0s 28ms/step - loss: 0.2372 - accuracy: 0.9036 - val_loss: 0.5409 - val_accuracy: 0.8397\n",
      "Epoch 154/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.2543 - accuracy: 0.9043 - val_loss: 0.5405 - val_accuracy: 0.8542\n",
      "Epoch 155/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.2484 - accuracy: 0.9109 - val_loss: 0.5529 - val_accuracy: 0.8280\n",
      "Epoch 156/2500\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.3182 - accuracy: 0.8868 - val_loss: 0.5313 - val_accuracy: 0.8338\n",
      "Epoch 157/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.2468 - accuracy: 0.9080 - val_loss: 0.5148 - val_accuracy: 0.8426\n",
      "Epoch 158/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.2389 - accuracy: 0.9087 - val_loss: 0.5491 - val_accuracy: 0.8280\n",
      "Epoch 159/2500\n",
      "18/18 [==============================] - 1s 28ms/step - loss: 0.2387 - accuracy: 0.9080 - val_loss: 0.5148 - val_accuracy: 0.8484\n",
      "Epoch 160/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.2440 - accuracy: 0.8985 - val_loss: 0.5356 - val_accuracy: 0.8309\n",
      "Epoch 161/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.2273 - accuracy: 0.9123 - val_loss: 0.5126 - val_accuracy: 0.8571\n",
      "Epoch 162/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.2636 - accuracy: 0.8985 - val_loss: 0.5539 - val_accuracy: 0.8367\n",
      "Epoch 163/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.2598 - accuracy: 0.8999 - val_loss: 0.5516 - val_accuracy: 0.8397\n",
      "Epoch 164/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.2636 - accuracy: 0.9021 - val_loss: 0.5513 - val_accuracy: 0.8455\n",
      "Epoch 165/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.2576 - accuracy: 0.9043 - val_loss: 0.5329 - val_accuracy: 0.8280\n",
      "Epoch 166/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.2447 - accuracy: 0.9058 - val_loss: 0.5550 - val_accuracy: 0.8426\n",
      "Epoch 167/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.2349 - accuracy: 0.9087 - val_loss: 0.5456 - val_accuracy: 0.8426\n",
      "Epoch 168/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.2221 - accuracy: 0.9160 - val_loss: 0.5386 - val_accuracy: 0.8426\n",
      "Epoch 169/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.2292 - accuracy: 0.9138 - val_loss: 0.5685 - val_accuracy: 0.8280\n",
      "Epoch 170/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.2408 - accuracy: 0.9094 - val_loss: 0.5361 - val_accuracy: 0.8513\n",
      "Epoch 171/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.2497 - accuracy: 0.9065 - val_loss: 0.5418 - val_accuracy: 0.8397\n",
      "Epoch 172/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.2311 - accuracy: 0.9145 - val_loss: 0.5418 - val_accuracy: 0.8455\n",
      "Epoch 173/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.2562 - accuracy: 0.9014 - val_loss: 0.5117 - val_accuracy: 0.8455\n",
      "Epoch 174/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.2288 - accuracy: 0.9102 - val_loss: 0.5509 - val_accuracy: 0.8484\n",
      "Epoch 175/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.2189 - accuracy: 0.9116 - val_loss: 0.5570 - val_accuracy: 0.8309\n",
      "Epoch 176/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.2297 - accuracy: 0.9182 - val_loss: 0.5528 - val_accuracy: 0.8397\n",
      "Epoch 177/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.2334 - accuracy: 0.9167 - val_loss: 0.5625 - val_accuracy: 0.8367\n",
      "Epoch 178/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.2461 - accuracy: 0.9021 - val_loss: 0.5374 - val_accuracy: 0.8367\n",
      "Epoch 179/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.2201 - accuracy: 0.9175 - val_loss: 0.5556 - val_accuracy: 0.8338\n",
      "Epoch 180/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.2526 - accuracy: 0.9036 - val_loss: 0.5544 - val_accuracy: 0.8484\n",
      "Epoch 181/2500\n",
      "18/18 [==============================] - 0s 29ms/step - loss: 0.2300 - accuracy: 0.9145 - val_loss: 0.5566 - val_accuracy: 0.8309\n",
      "Epoch 182/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.2445 - accuracy: 0.9007 - val_loss: 0.5602 - val_accuracy: 0.8513\n",
      "Epoch 183/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.2249 - accuracy: 0.9138 - val_loss: 0.5451 - val_accuracy: 0.8455\n",
      "Epoch 184/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.2242 - accuracy: 0.9160 - val_loss: 0.5289 - val_accuracy: 0.8397\n",
      "Epoch 185/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.2190 - accuracy: 0.9196 - val_loss: 0.5693 - val_accuracy: 0.8397\n",
      "Epoch 186/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.2190 - accuracy: 0.9153 - val_loss: 0.5434 - val_accuracy: 0.8601\n",
      "Epoch 187/2500\n",
      "18/18 [==============================] - 1s 25ms/step - loss: 0.2206 - accuracy: 0.9116 - val_loss: 0.5775 - val_accuracy: 0.8309\n",
      "Epoch 188/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.2486 - accuracy: 0.9102 - val_loss: 0.5153 - val_accuracy: 0.8397\n",
      "Epoch 189/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.2287 - accuracy: 0.9131 - val_loss: 0.5527 - val_accuracy: 0.8397\n",
      "Epoch 190/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.2589 - accuracy: 0.9028 - val_loss: 0.5627 - val_accuracy: 0.8426\n",
      "Epoch 191/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.2354 - accuracy: 0.9094 - val_loss: 0.5385 - val_accuracy: 0.8513\n",
      "Epoch 192/2500\n",
      "18/18 [==============================] - 1s 28ms/step - loss: 0.2244 - accuracy: 0.9131 - val_loss: 0.5480 - val_accuracy: 0.8397\n",
      "Epoch 193/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.2113 - accuracy: 0.9182 - val_loss: 0.5608 - val_accuracy: 0.8309\n",
      "Epoch 194/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.2139 - accuracy: 0.9211 - val_loss: 0.5436 - val_accuracy: 0.8455\n",
      "Epoch 195/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.2283 - accuracy: 0.9145 - val_loss: 0.5497 - val_accuracy: 0.8426\n",
      "Epoch 196/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.2428 - accuracy: 0.9080 - val_loss: 0.5687 - val_accuracy: 0.8222\n",
      "Epoch 197/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.2225 - accuracy: 0.9123 - val_loss: 0.5156 - val_accuracy: 0.8484\n",
      "Epoch 198/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.2291 - accuracy: 0.9094 - val_loss: 0.5661 - val_accuracy: 0.8484\n",
      "Epoch 199/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.2258 - accuracy: 0.9109 - val_loss: 0.5517 - val_accuracy: 0.8397\n",
      "Epoch 200/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.2114 - accuracy: 0.9211 - val_loss: 0.5383 - val_accuracy: 0.8484\n",
      "Epoch 201/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.2026 - accuracy: 0.9211 - val_loss: 0.5697 - val_accuracy: 0.8455\n",
      "Epoch 202/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.2594 - accuracy: 0.9072 - val_loss: 0.5494 - val_accuracy: 0.8426\n",
      "Epoch 203/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.2381 - accuracy: 0.9058 - val_loss: 0.5751 - val_accuracy: 0.8397\n",
      "Epoch 204/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.2266 - accuracy: 0.9102 - val_loss: 0.5991 - val_accuracy: 0.8484\n",
      "Epoch 205/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.2252 - accuracy: 0.9145 - val_loss: 0.5622 - val_accuracy: 0.8513\n",
      "Epoch 206/2500\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.2273 - accuracy: 0.9196 - val_loss: 0.5585 - val_accuracy: 0.8455\n",
      "Epoch 207/2500\n",
      "18/18 [==============================] - 1s 28ms/step - loss: 0.2374 - accuracy: 0.9065 - val_loss: 0.5433 - val_accuracy: 0.8484\n",
      "Epoch 208/2500\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.2136 - accuracy: 0.9131 - val_loss: 0.5504 - val_accuracy: 0.8397\n",
      "Epoch 209/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.2315 - accuracy: 0.9123 - val_loss: 0.5538 - val_accuracy: 0.8251\n",
      "Epoch 210/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.2238 - accuracy: 0.9204 - val_loss: 0.5475 - val_accuracy: 0.8280\n",
      "Epoch 211/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.2058 - accuracy: 0.9189 - val_loss: 0.5488 - val_accuracy: 0.8513\n",
      "Epoch 212/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.1948 - accuracy: 0.9138 - val_loss: 0.5531 - val_accuracy: 0.8542\n",
      "Epoch 213/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.2154 - accuracy: 0.9094 - val_loss: 0.5835 - val_accuracy: 0.8397\n",
      "Epoch 214/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.2226 - accuracy: 0.9167 - val_loss: 0.5672 - val_accuracy: 0.8367\n",
      "Epoch 215/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.2249 - accuracy: 0.9153 - val_loss: 0.5721 - val_accuracy: 0.8455\n",
      "Epoch 216/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.2268 - accuracy: 0.9065 - val_loss: 0.5602 - val_accuracy: 0.8397\n",
      "Epoch 217/2500\n",
      "18/18 [==============================] - 1s 28ms/step - loss: 0.2147 - accuracy: 0.9189 - val_loss: 0.5881 - val_accuracy: 0.8338\n",
      "Epoch 218/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.2219 - accuracy: 0.9138 - val_loss: 0.5524 - val_accuracy: 0.8513\n",
      "Epoch 219/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.2180 - accuracy: 0.9080 - val_loss: 0.5845 - val_accuracy: 0.8426\n",
      "Epoch 220/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.2263 - accuracy: 0.9109 - val_loss: 0.6150 - val_accuracy: 0.8426\n",
      "Epoch 221/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.2114 - accuracy: 0.9233 - val_loss: 0.5659 - val_accuracy: 0.8571\n",
      "Epoch 222/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.2122 - accuracy: 0.9196 - val_loss: 0.5586 - val_accuracy: 0.8397\n",
      "Epoch 223/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.2077 - accuracy: 0.9204 - val_loss: 0.5687 - val_accuracy: 0.8397\n",
      "Epoch 224/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.2139 - accuracy: 0.9167 - val_loss: 0.6061 - val_accuracy: 0.8251\n",
      "Epoch 225/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.2030 - accuracy: 0.9131 - val_loss: 0.5667 - val_accuracy: 0.8484\n",
      "Epoch 226/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.2289 - accuracy: 0.9123 - val_loss: 0.6173 - val_accuracy: 0.8251\n",
      "Epoch 227/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.2125 - accuracy: 0.9211 - val_loss: 0.5709 - val_accuracy: 0.8426\n",
      "Epoch 228/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.2288 - accuracy: 0.9102 - val_loss: 0.5673 - val_accuracy: 0.8426\n",
      "Epoch 229/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.2184 - accuracy: 0.9131 - val_loss: 0.5742 - val_accuracy: 0.8455\n",
      "Epoch 230/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.2079 - accuracy: 0.9233 - val_loss: 0.5563 - val_accuracy: 0.8455\n",
      "Epoch 231/2500\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.2001 - accuracy: 0.9255 - val_loss: 0.5958 - val_accuracy: 0.8309\n",
      "Epoch 232/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1998 - accuracy: 0.9291 - val_loss: 0.5670 - val_accuracy: 0.8367\n",
      "Epoch 233/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.2142 - accuracy: 0.9167 - val_loss: 0.5595 - val_accuracy: 0.8542\n",
      "Epoch 234/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.2068 - accuracy: 0.9167 - val_loss: 0.5726 - val_accuracy: 0.8309\n",
      "Epoch 235/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.2109 - accuracy: 0.9218 - val_loss: 0.5754 - val_accuracy: 0.8397\n",
      "Epoch 236/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.2051 - accuracy: 0.9211 - val_loss: 0.5582 - val_accuracy: 0.8542\n",
      "Epoch 237/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.2394 - accuracy: 0.9058 - val_loss: 0.5526 - val_accuracy: 0.8571\n",
      "Epoch 238/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.2128 - accuracy: 0.9102 - val_loss: 0.5871 - val_accuracy: 0.8338\n",
      "Epoch 239/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.2035 - accuracy: 0.9211 - val_loss: 0.5600 - val_accuracy: 0.8397\n",
      "Epoch 240/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.2020 - accuracy: 0.9233 - val_loss: 0.5378 - val_accuracy: 0.8367\n",
      "Epoch 241/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.2079 - accuracy: 0.9109 - val_loss: 0.5520 - val_accuracy: 0.8455\n",
      "Epoch 242/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1877 - accuracy: 0.9262 - val_loss: 0.5616 - val_accuracy: 0.8484\n",
      "Epoch 243/2500\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.2018 - accuracy: 0.9291 - val_loss: 0.5372 - val_accuracy: 0.8455\n",
      "Epoch 244/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1932 - accuracy: 0.9255 - val_loss: 0.5519 - val_accuracy: 0.8571\n",
      "Epoch 245/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1908 - accuracy: 0.9218 - val_loss: 0.5714 - val_accuracy: 0.8397\n",
      "Epoch 246/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.2002 - accuracy: 0.9240 - val_loss: 0.5892 - val_accuracy: 0.8338\n",
      "Epoch 247/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.2136 - accuracy: 0.9145 - val_loss: 0.5529 - val_accuracy: 0.8513\n",
      "Epoch 248/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.2208 - accuracy: 0.9072 - val_loss: 0.5777 - val_accuracy: 0.8455\n",
      "Epoch 249/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.2049 - accuracy: 0.9160 - val_loss: 0.5810 - val_accuracy: 0.8338\n",
      "Epoch 250/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1933 - accuracy: 0.9270 - val_loss: 0.5458 - val_accuracy: 0.8484\n",
      "Epoch 251/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1845 - accuracy: 0.9291 - val_loss: 0.5637 - val_accuracy: 0.8601\n",
      "Epoch 252/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1970 - accuracy: 0.9248 - val_loss: 0.5628 - val_accuracy: 0.8542\n",
      "Epoch 253/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1934 - accuracy: 0.9291 - val_loss: 0.5376 - val_accuracy: 0.8571\n",
      "Epoch 254/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.2034 - accuracy: 0.9218 - val_loss: 0.5841 - val_accuracy: 0.8397\n",
      "Epoch 255/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1840 - accuracy: 0.9284 - val_loss: 0.5445 - val_accuracy: 0.8571\n",
      "Epoch 256/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1988 - accuracy: 0.9240 - val_loss: 0.5717 - val_accuracy: 0.8542\n",
      "Epoch 257/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1831 - accuracy: 0.9270 - val_loss: 0.5663 - val_accuracy: 0.8571\n",
      "Epoch 258/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1917 - accuracy: 0.9255 - val_loss: 0.5770 - val_accuracy: 0.8338\n",
      "Epoch 259/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1991 - accuracy: 0.9233 - val_loss: 0.5683 - val_accuracy: 0.8367\n",
      "Epoch 260/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.2191 - accuracy: 0.9145 - val_loss: 0.5579 - val_accuracy: 0.8397\n",
      "Epoch 261/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.2041 - accuracy: 0.9175 - val_loss: 0.5546 - val_accuracy: 0.8513\n",
      "Epoch 262/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.2103 - accuracy: 0.9182 - val_loss: 0.5619 - val_accuracy: 0.8426\n",
      "Epoch 263/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1842 - accuracy: 0.9240 - val_loss: 0.5815 - val_accuracy: 0.8397\n",
      "Epoch 264/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1967 - accuracy: 0.9204 - val_loss: 0.5716 - val_accuracy: 0.8397\n",
      "Epoch 265/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.2092 - accuracy: 0.9175 - val_loss: 0.5747 - val_accuracy: 0.8338\n",
      "Epoch 266/2500\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.1886 - accuracy: 0.9211 - val_loss: 0.5596 - val_accuracy: 0.8397\n",
      "Epoch 267/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1969 - accuracy: 0.9262 - val_loss: 0.5430 - val_accuracy: 0.8513\n",
      "Epoch 268/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.2290 - accuracy: 0.9116 - val_loss: 0.5702 - val_accuracy: 0.8455\n",
      "Epoch 269/2500\n",
      "18/18 [==============================] - 0s 28ms/step - loss: 0.2253 - accuracy: 0.9109 - val_loss: 0.5531 - val_accuracy: 0.8455\n",
      "Epoch 270/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.2111 - accuracy: 0.9153 - val_loss: 0.5697 - val_accuracy: 0.8484\n",
      "Epoch 271/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.2052 - accuracy: 0.9233 - val_loss: 0.5767 - val_accuracy: 0.8367\n",
      "Epoch 272/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.2048 - accuracy: 0.9240 - val_loss: 0.5656 - val_accuracy: 0.8426\n",
      "Epoch 273/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1952 - accuracy: 0.9291 - val_loss: 0.5786 - val_accuracy: 0.8397\n",
      "Epoch 274/2500\n",
      "18/18 [==============================] - 1s 28ms/step - loss: 0.1987 - accuracy: 0.9204 - val_loss: 0.5791 - val_accuracy: 0.8571\n",
      "Epoch 275/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1878 - accuracy: 0.9284 - val_loss: 0.5561 - val_accuracy: 0.8601\n",
      "Epoch 276/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1749 - accuracy: 0.9313 - val_loss: 0.5599 - val_accuracy: 0.8455\n",
      "Epoch 277/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1936 - accuracy: 0.9299 - val_loss: 0.5624 - val_accuracy: 0.8542\n",
      "Epoch 278/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.2111 - accuracy: 0.9189 - val_loss: 0.5725 - val_accuracy: 0.8513\n",
      "Epoch 279/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.2145 - accuracy: 0.9204 - val_loss: 0.6164 - val_accuracy: 0.8484\n",
      "Epoch 280/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1994 - accuracy: 0.9226 - val_loss: 0.5847 - val_accuracy: 0.8484\n",
      "Epoch 281/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.2010 - accuracy: 0.9262 - val_loss: 0.5667 - val_accuracy: 0.8513\n",
      "Epoch 282/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.2159 - accuracy: 0.9204 - val_loss: 0.5785 - val_accuracy: 0.8426\n",
      "Epoch 283/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.2007 - accuracy: 0.9204 - val_loss: 0.6259 - val_accuracy: 0.8397\n",
      "Epoch 284/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.2011 - accuracy: 0.9204 - val_loss: 0.5964 - val_accuracy: 0.8601\n",
      "Epoch 285/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.2043 - accuracy: 0.9138 - val_loss: 0.5766 - val_accuracy: 0.8455\n",
      "Epoch 286/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.2016 - accuracy: 0.9167 - val_loss: 0.5503 - val_accuracy: 0.8513\n",
      "Epoch 287/2500\n",
      "18/18 [==============================] - 1s 28ms/step - loss: 0.1817 - accuracy: 0.9313 - val_loss: 0.5585 - val_accuracy: 0.8513\n",
      "Epoch 288/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1821 - accuracy: 0.9291 - val_loss: 0.5615 - val_accuracy: 0.8513\n",
      "Epoch 289/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1801 - accuracy: 0.9306 - val_loss: 0.5487 - val_accuracy: 0.8571\n",
      "Epoch 290/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1895 - accuracy: 0.9270 - val_loss: 0.5299 - val_accuracy: 0.8717\n",
      "Epoch 291/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.2035 - accuracy: 0.9182 - val_loss: 0.5507 - val_accuracy: 0.8367\n",
      "Epoch 292/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1999 - accuracy: 0.9291 - val_loss: 0.5429 - val_accuracy: 0.8542\n",
      "Epoch 293/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1885 - accuracy: 0.9204 - val_loss: 0.5588 - val_accuracy: 0.8426\n",
      "Epoch 294/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1964 - accuracy: 0.9240 - val_loss: 0.5759 - val_accuracy: 0.8484\n",
      "Epoch 295/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1995 - accuracy: 0.9131 - val_loss: 0.5390 - val_accuracy: 0.8659\n",
      "Epoch 296/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.2018 - accuracy: 0.9262 - val_loss: 0.5753 - val_accuracy: 0.8484\n",
      "Epoch 297/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1966 - accuracy: 0.9262 - val_loss: 0.6071 - val_accuracy: 0.8426\n",
      "Epoch 298/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.2207 - accuracy: 0.9204 - val_loss: 0.5549 - val_accuracy: 0.8601\n",
      "Epoch 299/2500\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.1871 - accuracy: 0.9262 - val_loss: 0.5632 - val_accuracy: 0.8601\n",
      "Epoch 300/2500\n",
      "18/18 [==============================] - 1s 28ms/step - loss: 0.1843 - accuracy: 0.9284 - val_loss: 0.5643 - val_accuracy: 0.8397\n",
      "Epoch 301/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1692 - accuracy: 0.9350 - val_loss: 0.5551 - val_accuracy: 0.8571\n",
      "Epoch 302/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1933 - accuracy: 0.9189 - val_loss: 0.5757 - val_accuracy: 0.8455\n",
      "Epoch 303/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.2055 - accuracy: 0.9196 - val_loss: 0.5747 - val_accuracy: 0.8309\n",
      "Epoch 304/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1901 - accuracy: 0.9270 - val_loss: 0.5413 - val_accuracy: 0.8630\n",
      "Epoch 305/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1864 - accuracy: 0.9335 - val_loss: 0.5580 - val_accuracy: 0.8367\n",
      "Epoch 306/2500\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.1752 - accuracy: 0.9299 - val_loss: 0.5678 - val_accuracy: 0.8338\n",
      "Epoch 307/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1904 - accuracy: 0.9335 - val_loss: 0.5728 - val_accuracy: 0.8455\n",
      "Epoch 308/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1711 - accuracy: 0.9335 - val_loss: 0.5846 - val_accuracy: 0.8484\n",
      "Epoch 309/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1685 - accuracy: 0.9343 - val_loss: 0.5940 - val_accuracy: 0.8367\n",
      "Epoch 310/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1978 - accuracy: 0.9248 - val_loss: 0.5651 - val_accuracy: 0.8571\n",
      "Epoch 311/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1664 - accuracy: 0.9335 - val_loss: 0.5672 - val_accuracy: 0.8659\n",
      "Epoch 312/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.2023 - accuracy: 0.9218 - val_loss: 0.5797 - val_accuracy: 0.8484\n",
      "Epoch 313/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1766 - accuracy: 0.9321 - val_loss: 0.6186 - val_accuracy: 0.8397\n",
      "Epoch 314/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1870 - accuracy: 0.9233 - val_loss: 0.5791 - val_accuracy: 0.8397\n",
      "Epoch 315/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1860 - accuracy: 0.9248 - val_loss: 0.5826 - val_accuracy: 0.8338\n",
      "Epoch 316/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1839 - accuracy: 0.9233 - val_loss: 0.5785 - val_accuracy: 0.8513\n",
      "Epoch 317/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1950 - accuracy: 0.9233 - val_loss: 0.5678 - val_accuracy: 0.8601\n",
      "Epoch 318/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1745 - accuracy: 0.9313 - val_loss: 0.5613 - val_accuracy: 0.8571\n",
      "Epoch 319/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1719 - accuracy: 0.9270 - val_loss: 0.5704 - val_accuracy: 0.8280\n",
      "Epoch 320/2500\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.1826 - accuracy: 0.9313 - val_loss: 0.5649 - val_accuracy: 0.8426\n",
      "Epoch 321/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1902 - accuracy: 0.9299 - val_loss: 0.6351 - val_accuracy: 0.8309\n",
      "Epoch 322/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1855 - accuracy: 0.9204 - val_loss: 0.5560 - val_accuracy: 0.8542\n",
      "Epoch 323/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1951 - accuracy: 0.9240 - val_loss: 0.5875 - val_accuracy: 0.8426\n",
      "Epoch 324/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1882 - accuracy: 0.9211 - val_loss: 0.5816 - val_accuracy: 0.8484\n",
      "Epoch 325/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1798 - accuracy: 0.9343 - val_loss: 0.5926 - val_accuracy: 0.8367\n",
      "Epoch 326/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1806 - accuracy: 0.9218 - val_loss: 0.5643 - val_accuracy: 0.8426\n",
      "Epoch 327/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1851 - accuracy: 0.9248 - val_loss: 0.6099 - val_accuracy: 0.8367\n",
      "Epoch 328/2500\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.1885 - accuracy: 0.9335 - val_loss: 0.5795 - val_accuracy: 0.8542\n",
      "Epoch 329/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1827 - accuracy: 0.9291 - val_loss: 0.6177 - val_accuracy: 0.8571\n",
      "Epoch 330/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1831 - accuracy: 0.9270 - val_loss: 0.6113 - val_accuracy: 0.8455\n",
      "Epoch 331/2500\n",
      "18/18 [==============================] - 1s 27ms/step - loss: 0.1869 - accuracy: 0.9211 - val_loss: 0.5740 - val_accuracy: 0.8805\n",
      "Epoch 332/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1650 - accuracy: 0.9364 - val_loss: 0.5930 - val_accuracy: 0.8426\n",
      "Epoch 333/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1636 - accuracy: 0.9335 - val_loss: 0.6037 - val_accuracy: 0.8426\n",
      "Epoch 334/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1723 - accuracy: 0.9313 - val_loss: 0.5962 - val_accuracy: 0.8571\n",
      "Epoch 335/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1765 - accuracy: 0.9313 - val_loss: 0.6216 - val_accuracy: 0.8426\n",
      "Epoch 336/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1843 - accuracy: 0.9299 - val_loss: 0.6038 - val_accuracy: 0.8513\n",
      "Epoch 337/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1722 - accuracy: 0.9313 - val_loss: 0.6269 - val_accuracy: 0.8484\n",
      "Epoch 338/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1733 - accuracy: 0.9248 - val_loss: 0.6094 - val_accuracy: 0.8397\n",
      "Epoch 339/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1849 - accuracy: 0.9175 - val_loss: 0.6193 - val_accuracy: 0.8426\n",
      "Epoch 340/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1759 - accuracy: 0.9248 - val_loss: 0.6132 - val_accuracy: 0.8426\n",
      "Epoch 341/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1929 - accuracy: 0.9240 - val_loss: 0.6357 - val_accuracy: 0.8542\n",
      "Epoch 342/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1750 - accuracy: 0.9277 - val_loss: 0.6195 - val_accuracy: 0.8513\n",
      "Epoch 343/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1609 - accuracy: 0.9364 - val_loss: 0.6012 - val_accuracy: 0.8397\n",
      "Epoch 344/2500\n",
      "18/18 [==============================] - 1s 28ms/step - loss: 0.1713 - accuracy: 0.9306 - val_loss: 0.6327 - val_accuracy: 0.8513\n",
      "Epoch 345/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.2165 - accuracy: 0.9153 - val_loss: 0.5970 - val_accuracy: 0.8542\n",
      "Epoch 346/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.2096 - accuracy: 0.9240 - val_loss: 0.5989 - val_accuracy: 0.8484\n",
      "Epoch 347/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1956 - accuracy: 0.9218 - val_loss: 0.5809 - val_accuracy: 0.8484\n",
      "Epoch 348/2500\n",
      "18/18 [==============================] - 0s 28ms/step - loss: 0.1699 - accuracy: 0.9364 - val_loss: 0.5786 - val_accuracy: 0.8455\n",
      "Epoch 349/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1779 - accuracy: 0.9299 - val_loss: 0.6069 - val_accuracy: 0.8484\n",
      "Epoch 350/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1666 - accuracy: 0.9321 - val_loss: 0.6002 - val_accuracy: 0.8397\n",
      "Epoch 351/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1705 - accuracy: 0.9270 - val_loss: 0.5918 - val_accuracy: 0.8397\n",
      "Epoch 352/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1567 - accuracy: 0.9416 - val_loss: 0.6069 - val_accuracy: 0.8484\n",
      "Epoch 353/2500\n",
      "18/18 [==============================] - 1s 28ms/step - loss: 0.1645 - accuracy: 0.9401 - val_loss: 0.5866 - val_accuracy: 0.8484\n",
      "Epoch 354/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1737 - accuracy: 0.9291 - val_loss: 0.5676 - val_accuracy: 0.8688\n",
      "Epoch 355/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1705 - accuracy: 0.9321 - val_loss: 0.5874 - val_accuracy: 0.8426\n",
      "Epoch 356/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1906 - accuracy: 0.9189 - val_loss: 0.5956 - val_accuracy: 0.8338\n",
      "Epoch 357/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1773 - accuracy: 0.9270 - val_loss: 0.5973 - val_accuracy: 0.8571\n",
      "Epoch 358/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1807 - accuracy: 0.9270 - val_loss: 0.5842 - val_accuracy: 0.8455\n",
      "Epoch 359/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1663 - accuracy: 0.9299 - val_loss: 0.5931 - val_accuracy: 0.8455\n",
      "Epoch 360/2500\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.1796 - accuracy: 0.9270 - val_loss: 0.5855 - val_accuracy: 0.8455\n",
      "Epoch 361/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1599 - accuracy: 0.9357 - val_loss: 0.5779 - val_accuracy: 0.8397\n",
      "Epoch 362/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.2046 - accuracy: 0.9160 - val_loss: 0.5986 - val_accuracy: 0.8455\n",
      "Epoch 363/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1851 - accuracy: 0.9321 - val_loss: 0.5981 - val_accuracy: 0.8397\n",
      "Epoch 364/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1810 - accuracy: 0.9313 - val_loss: 0.5956 - val_accuracy: 0.8601\n",
      "Epoch 365/2500\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 0.1651 - accuracy: 0.9401 - val_loss: 0.6119 - val_accuracy: 0.8455\n",
      "Epoch 366/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.2234 - accuracy: 0.9262 - val_loss: 0.6104 - val_accuracy: 0.8397\n",
      "Epoch 367/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.2003 - accuracy: 0.9196 - val_loss: 0.6085 - val_accuracy: 0.8571\n",
      "Epoch 368/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1650 - accuracy: 0.9328 - val_loss: 0.6233 - val_accuracy: 0.8601\n",
      "Epoch 369/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1792 - accuracy: 0.9248 - val_loss: 0.5902 - val_accuracy: 0.8630\n",
      "Epoch 370/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1661 - accuracy: 0.9350 - val_loss: 0.5872 - val_accuracy: 0.8513\n",
      "Epoch 371/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1594 - accuracy: 0.9386 - val_loss: 0.6363 - val_accuracy: 0.8367\n",
      "Epoch 372/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1867 - accuracy: 0.9189 - val_loss: 0.6534 - val_accuracy: 0.8397\n",
      "Epoch 373/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1739 - accuracy: 0.9299 - val_loss: 0.6326 - val_accuracy: 0.8426\n",
      "Epoch 374/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1761 - accuracy: 0.9335 - val_loss: 0.6318 - val_accuracy: 0.8484\n",
      "Epoch 375/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1784 - accuracy: 0.9277 - val_loss: 0.6214 - val_accuracy: 0.8426\n",
      "Epoch 376/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1784 - accuracy: 0.9226 - val_loss: 0.6271 - val_accuracy: 0.8601\n",
      "Epoch 377/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1957 - accuracy: 0.9306 - val_loss: 0.5871 - val_accuracy: 0.8659\n",
      "Epoch 378/2500\n",
      "18/18 [==============================] - 1s 28ms/step - loss: 0.1952 - accuracy: 0.9277 - val_loss: 0.6015 - val_accuracy: 0.8484\n",
      "Epoch 379/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.2127 - accuracy: 0.9196 - val_loss: 0.6652 - val_accuracy: 0.8222\n",
      "Epoch 380/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1835 - accuracy: 0.9262 - val_loss: 0.6298 - val_accuracy: 0.8630\n",
      "Epoch 381/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1901 - accuracy: 0.9299 - val_loss: 0.6189 - val_accuracy: 0.8338\n",
      "Epoch 382/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1704 - accuracy: 0.9364 - val_loss: 0.6046 - val_accuracy: 0.8367\n",
      "Epoch 383/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1787 - accuracy: 0.9233 - val_loss: 0.6136 - val_accuracy: 0.8601\n",
      "Epoch 384/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.2026 - accuracy: 0.9255 - val_loss: 0.6281 - val_accuracy: 0.8367\n",
      "Epoch 385/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1793 - accuracy: 0.9299 - val_loss: 0.6048 - val_accuracy: 0.8571\n",
      "Epoch 386/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1589 - accuracy: 0.9379 - val_loss: 0.6112 - val_accuracy: 0.8571\n",
      "Epoch 387/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1739 - accuracy: 0.9357 - val_loss: 0.6219 - val_accuracy: 0.8455\n",
      "Epoch 388/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1740 - accuracy: 0.9277 - val_loss: 0.6293 - val_accuracy: 0.8309\n",
      "Epoch 389/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1812 - accuracy: 0.9284 - val_loss: 0.6468 - val_accuracy: 0.8426\n",
      "Epoch 390/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1667 - accuracy: 0.9321 - val_loss: 0.5956 - val_accuracy: 0.8717\n",
      "Epoch 391/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1840 - accuracy: 0.9291 - val_loss: 0.6163 - val_accuracy: 0.8367\n",
      "Epoch 392/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1772 - accuracy: 0.9284 - val_loss: 0.6039 - val_accuracy: 0.8542\n",
      "Epoch 393/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1656 - accuracy: 0.9350 - val_loss: 0.5916 - val_accuracy: 0.8601\n",
      "Epoch 394/2500\n",
      "18/18 [==============================] - 1s 28ms/step - loss: 0.1632 - accuracy: 0.9328 - val_loss: 0.6034 - val_accuracy: 0.8571\n",
      "Epoch 395/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1876 - accuracy: 0.9262 - val_loss: 0.6219 - val_accuracy: 0.8513\n",
      "Epoch 396/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1636 - accuracy: 0.9335 - val_loss: 0.6205 - val_accuracy: 0.8484\n",
      "Epoch 397/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1795 - accuracy: 0.9313 - val_loss: 0.6298 - val_accuracy: 0.8484\n",
      "Epoch 398/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1793 - accuracy: 0.9306 - val_loss: 0.5927 - val_accuracy: 0.8659\n",
      "Epoch 399/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1579 - accuracy: 0.9364 - val_loss: 0.6198 - val_accuracy: 0.8455\n",
      "Epoch 400/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1611 - accuracy: 0.9343 - val_loss: 0.6305 - val_accuracy: 0.8484\n",
      "Epoch 401/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1561 - accuracy: 0.9364 - val_loss: 0.6440 - val_accuracy: 0.8571\n",
      "Epoch 402/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1537 - accuracy: 0.9386 - val_loss: 0.6451 - val_accuracy: 0.8426\n",
      "Epoch 403/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1565 - accuracy: 0.9335 - val_loss: 0.6178 - val_accuracy: 0.8746\n",
      "Epoch 404/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1561 - accuracy: 0.9335 - val_loss: 0.6328 - val_accuracy: 0.8571\n",
      "Epoch 405/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1590 - accuracy: 0.9430 - val_loss: 0.6351 - val_accuracy: 0.8513\n",
      "Epoch 406/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1725 - accuracy: 0.9335 - val_loss: 0.6506 - val_accuracy: 0.8397\n",
      "Epoch 407/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1626 - accuracy: 0.9328 - val_loss: 0.6189 - val_accuracy: 0.8426\n",
      "Epoch 408/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1540 - accuracy: 0.9372 - val_loss: 0.6194 - val_accuracy: 0.8542\n",
      "Epoch 409/2500\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.1749 - accuracy: 0.9291 - val_loss: 0.6350 - val_accuracy: 0.8513\n",
      "Epoch 410/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1870 - accuracy: 0.9270 - val_loss: 0.6253 - val_accuracy: 0.8542\n",
      "Epoch 411/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.2031 - accuracy: 0.9196 - val_loss: 0.6182 - val_accuracy: 0.8367\n",
      "Epoch 412/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1953 - accuracy: 0.9226 - val_loss: 0.6064 - val_accuracy: 0.8513\n",
      "Epoch 413/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1827 - accuracy: 0.9270 - val_loss: 0.5912 - val_accuracy: 0.8717\n",
      "Epoch 414/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1679 - accuracy: 0.9277 - val_loss: 0.6162 - val_accuracy: 0.8455\n",
      "Epoch 415/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1665 - accuracy: 0.9335 - val_loss: 0.6277 - val_accuracy: 0.8397\n",
      "Epoch 416/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1669 - accuracy: 0.9284 - val_loss: 0.6166 - val_accuracy: 0.8601\n",
      "Epoch 417/2500\n",
      "18/18 [==============================] - 1s 28ms/step - loss: 0.1459 - accuracy: 0.9416 - val_loss: 0.6085 - val_accuracy: 0.8601\n",
      "Epoch 418/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1616 - accuracy: 0.9328 - val_loss: 0.5963 - val_accuracy: 0.8455\n",
      "Epoch 419/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1548 - accuracy: 0.9343 - val_loss: 0.6176 - val_accuracy: 0.8659\n",
      "Epoch 420/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1552 - accuracy: 0.9386 - val_loss: 0.6209 - val_accuracy: 0.8542\n",
      "Epoch 421/2500\n",
      "18/18 [==============================] - 1s 27ms/step - loss: 0.1512 - accuracy: 0.9379 - val_loss: 0.6168 - val_accuracy: 0.8571\n",
      "Epoch 422/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1451 - accuracy: 0.9386 - val_loss: 0.6354 - val_accuracy: 0.8542\n",
      "Epoch 423/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1609 - accuracy: 0.9335 - val_loss: 0.6235 - val_accuracy: 0.8367\n",
      "Epoch 424/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1733 - accuracy: 0.9226 - val_loss: 0.6350 - val_accuracy: 0.8601\n",
      "Epoch 425/2500\n",
      "18/18 [==============================] - 1s 24ms/step - loss: 0.1627 - accuracy: 0.9386 - val_loss: 0.6124 - val_accuracy: 0.8659\n",
      "Epoch 426/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1484 - accuracy: 0.9416 - val_loss: 0.6253 - val_accuracy: 0.8542\n",
      "Epoch 427/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1506 - accuracy: 0.9379 - val_loss: 0.6340 - val_accuracy: 0.8484\n",
      "Epoch 428/2500\n",
      "18/18 [==============================] - 0s 28ms/step - loss: 0.1642 - accuracy: 0.9321 - val_loss: 0.6030 - val_accuracy: 0.8571\n",
      "Epoch 429/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1653 - accuracy: 0.9321 - val_loss: 0.6330 - val_accuracy: 0.8659\n",
      "Epoch 430/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1520 - accuracy: 0.9321 - val_loss: 0.6329 - val_accuracy: 0.8426\n",
      "Epoch 431/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1696 - accuracy: 0.9270 - val_loss: 0.6315 - val_accuracy: 0.8571\n",
      "Epoch 432/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1663 - accuracy: 0.9328 - val_loss: 0.6512 - val_accuracy: 0.8513\n",
      "Epoch 433/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1617 - accuracy: 0.9328 - val_loss: 0.6363 - val_accuracy: 0.8571\n",
      "Epoch 434/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1519 - accuracy: 0.9386 - val_loss: 0.6235 - val_accuracy: 0.8542\n",
      "Epoch 435/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1509 - accuracy: 0.9343 - val_loss: 0.6268 - val_accuracy: 0.8630\n",
      "Epoch 436/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1692 - accuracy: 0.9321 - val_loss: 0.6180 - val_accuracy: 0.8426\n",
      "Epoch 437/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1564 - accuracy: 0.9372 - val_loss: 0.6274 - val_accuracy: 0.8484\n",
      "Epoch 438/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1544 - accuracy: 0.9364 - val_loss: 0.6307 - val_accuracy: 0.8513\n",
      "Epoch 439/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1453 - accuracy: 0.9416 - val_loss: 0.6117 - val_accuracy: 0.8571\n",
      "Epoch 440/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1651 - accuracy: 0.9416 - val_loss: 0.5927 - val_accuracy: 0.8630\n",
      "Epoch 441/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1646 - accuracy: 0.9284 - val_loss: 0.6309 - val_accuracy: 0.8367\n",
      "Epoch 442/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1597 - accuracy: 0.9343 - val_loss: 0.6252 - val_accuracy: 0.8513\n",
      "Epoch 443/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1498 - accuracy: 0.9416 - val_loss: 0.6351 - val_accuracy: 0.8542\n",
      "Epoch 444/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1548 - accuracy: 0.9408 - val_loss: 0.6221 - val_accuracy: 0.8542\n",
      "Epoch 445/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1442 - accuracy: 0.9445 - val_loss: 0.6355 - val_accuracy: 0.8571\n",
      "Epoch 446/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1566 - accuracy: 0.9459 - val_loss: 0.6492 - val_accuracy: 0.8367\n",
      "Epoch 447/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1661 - accuracy: 0.9328 - val_loss: 0.6566 - val_accuracy: 0.8571\n",
      "Epoch 448/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1579 - accuracy: 0.9401 - val_loss: 0.6272 - val_accuracy: 0.8630\n",
      "Epoch 449/2500\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.1416 - accuracy: 0.9423 - val_loss: 0.6258 - val_accuracy: 0.8513\n",
      "Epoch 450/2500\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 0.1476 - accuracy: 0.9386 - val_loss: 0.6338 - val_accuracy: 0.8571\n",
      "Epoch 451/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1508 - accuracy: 0.9372 - val_loss: 0.6305 - val_accuracy: 0.8688\n",
      "Epoch 452/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1572 - accuracy: 0.9343 - val_loss: 0.6677 - val_accuracy: 0.8484\n",
      "Epoch 453/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1715 - accuracy: 0.9291 - val_loss: 0.6385 - val_accuracy: 0.8571\n",
      "Epoch 454/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1932 - accuracy: 0.9306 - val_loss: 0.5988 - val_accuracy: 0.8601\n",
      "Epoch 455/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1764 - accuracy: 0.9277 - val_loss: 0.6108 - val_accuracy: 0.8542\n",
      "Epoch 456/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1579 - accuracy: 0.9350 - val_loss: 0.6179 - val_accuracy: 0.8571\n",
      "Epoch 457/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1599 - accuracy: 0.9364 - val_loss: 0.6350 - val_accuracy: 0.8513\n",
      "Epoch 458/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1604 - accuracy: 0.9357 - val_loss: 0.6624 - val_accuracy: 0.8542\n",
      "Epoch 459/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1595 - accuracy: 0.9306 - val_loss: 0.6047 - val_accuracy: 0.8513\n",
      "Epoch 460/2500\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.1609 - accuracy: 0.9386 - val_loss: 0.6469 - val_accuracy: 0.8397\n",
      "Epoch 461/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1561 - accuracy: 0.9350 - val_loss: 0.6550 - val_accuracy: 0.8484\n",
      "Epoch 462/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1520 - accuracy: 0.9372 - val_loss: 0.6375 - val_accuracy: 0.8571\n",
      "Epoch 463/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1578 - accuracy: 0.9386 - val_loss: 0.6177 - val_accuracy: 0.8455\n",
      "Epoch 464/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1694 - accuracy: 0.9364 - val_loss: 0.5968 - val_accuracy: 0.8659\n",
      "Epoch 465/2500\n",
      "18/18 [==============================] - 0s 28ms/step - loss: 0.1568 - accuracy: 0.9343 - val_loss: 0.6195 - val_accuracy: 0.8426\n",
      "Epoch 466/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1639 - accuracy: 0.9328 - val_loss: 0.6285 - val_accuracy: 0.8484\n",
      "Epoch 467/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1547 - accuracy: 0.9386 - val_loss: 0.6398 - val_accuracy: 0.8513\n",
      "Epoch 468/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1611 - accuracy: 0.9350 - val_loss: 0.6416 - val_accuracy: 0.8513\n",
      "Epoch 469/2500\n",
      "18/18 [==============================] - 0s 28ms/step - loss: 0.1673 - accuracy: 0.9328 - val_loss: 0.6410 - val_accuracy: 0.8484\n",
      "Epoch 470/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1559 - accuracy: 0.9321 - val_loss: 0.6176 - val_accuracy: 0.8601\n",
      "Epoch 471/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1546 - accuracy: 0.9364 - val_loss: 0.6053 - val_accuracy: 0.8513\n",
      "Epoch 472/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1448 - accuracy: 0.9394 - val_loss: 0.6165 - val_accuracy: 0.8601\n",
      "Epoch 473/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1570 - accuracy: 0.9321 - val_loss: 0.6463 - val_accuracy: 0.8513\n",
      "Epoch 474/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1849 - accuracy: 0.9233 - val_loss: 0.6231 - val_accuracy: 0.8630\n",
      "Epoch 475/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1579 - accuracy: 0.9357 - val_loss: 0.6367 - val_accuracy: 0.8397\n",
      "Epoch 476/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1576 - accuracy: 0.9328 - val_loss: 0.6314 - val_accuracy: 0.8571\n",
      "Epoch 477/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1569 - accuracy: 0.9335 - val_loss: 0.6029 - val_accuracy: 0.8571\n",
      "Epoch 478/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1575 - accuracy: 0.9357 - val_loss: 0.6252 - val_accuracy: 0.8542\n",
      "Epoch 479/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1637 - accuracy: 0.9328 - val_loss: 0.6182 - val_accuracy: 0.8571\n",
      "Epoch 480/2500\n",
      "18/18 [==============================] - 0s 28ms/step - loss: 0.1575 - accuracy: 0.9364 - val_loss: 0.6150 - val_accuracy: 0.8688\n",
      "Epoch 481/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1711 - accuracy: 0.9313 - val_loss: 0.6269 - val_accuracy: 0.8630\n",
      "Epoch 482/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1579 - accuracy: 0.9379 - val_loss: 0.6290 - val_accuracy: 0.8571\n",
      "Epoch 483/2500\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.1671 - accuracy: 0.9350 - val_loss: 0.6424 - val_accuracy: 0.8367\n",
      "Epoch 484/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1683 - accuracy: 0.9350 - val_loss: 0.6400 - val_accuracy: 0.8571\n",
      "Epoch 485/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1714 - accuracy: 0.9270 - val_loss: 0.6266 - val_accuracy: 0.8571\n",
      "Epoch 486/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1432 - accuracy: 0.9408 - val_loss: 0.5961 - val_accuracy: 0.8571\n",
      "Epoch 487/2500\n",
      "18/18 [==============================] - 1s 28ms/step - loss: 0.1597 - accuracy: 0.9328 - val_loss: 0.6384 - val_accuracy: 0.8309\n",
      "Epoch 488/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1802 - accuracy: 0.9218 - val_loss: 0.6039 - val_accuracy: 0.8542\n",
      "Epoch 489/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1640 - accuracy: 0.9394 - val_loss: 0.5848 - val_accuracy: 0.8688\n",
      "Epoch 490/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1736 - accuracy: 0.9270 - val_loss: 0.5998 - val_accuracy: 0.8484\n",
      "Epoch 491/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1654 - accuracy: 0.9291 - val_loss: 0.5945 - val_accuracy: 0.8484\n",
      "Epoch 492/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1515 - accuracy: 0.9357 - val_loss: 0.6029 - val_accuracy: 0.8542\n",
      "Epoch 493/2500\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.1471 - accuracy: 0.9379 - val_loss: 0.5978 - val_accuracy: 0.8688\n",
      "Epoch 494/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1424 - accuracy: 0.9445 - val_loss: 0.5883 - val_accuracy: 0.8630\n",
      "Epoch 495/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1491 - accuracy: 0.9379 - val_loss: 0.5974 - val_accuracy: 0.8659\n",
      "Epoch 496/2500\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.1472 - accuracy: 0.9357 - val_loss: 0.5967 - val_accuracy: 0.8688\n",
      "Epoch 497/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1686 - accuracy: 0.9343 - val_loss: 0.6195 - val_accuracy: 0.8776\n",
      "Epoch 498/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1986 - accuracy: 0.9196 - val_loss: 0.6377 - val_accuracy: 0.8455\n",
      "Epoch 499/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1716 - accuracy: 0.9277 - val_loss: 0.6211 - val_accuracy: 0.8746\n",
      "Epoch 500/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1821 - accuracy: 0.9255 - val_loss: 0.6415 - val_accuracy: 0.8542\n",
      "Epoch 501/2500\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 0.1711 - accuracy: 0.9364 - val_loss: 0.6147 - val_accuracy: 0.8571\n",
      "Epoch 502/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1545 - accuracy: 0.9357 - val_loss: 0.6177 - val_accuracy: 0.8601\n",
      "Epoch 503/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1670 - accuracy: 0.9328 - val_loss: 0.6107 - val_accuracy: 0.8659\n",
      "Epoch 504/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1533 - accuracy: 0.9394 - val_loss: 0.6306 - val_accuracy: 0.8688\n",
      "Epoch 505/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1712 - accuracy: 0.9299 - val_loss: 0.6040 - val_accuracy: 0.8601\n",
      "Epoch 506/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1578 - accuracy: 0.9321 - val_loss: 0.6268 - val_accuracy: 0.8571\n",
      "Epoch 507/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1644 - accuracy: 0.9372 - val_loss: 0.6119 - val_accuracy: 0.8426\n",
      "Epoch 508/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1559 - accuracy: 0.9452 - val_loss: 0.6123 - val_accuracy: 0.8571\n",
      "Epoch 509/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1623 - accuracy: 0.9321 - val_loss: 0.6141 - val_accuracy: 0.8688\n",
      "Epoch 510/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1719 - accuracy: 0.9299 - val_loss: 0.6373 - val_accuracy: 0.8455\n",
      "Epoch 511/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1730 - accuracy: 0.9364 - val_loss: 0.6307 - val_accuracy: 0.8484\n",
      "Epoch 512/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1572 - accuracy: 0.9394 - val_loss: 0.6555 - val_accuracy: 0.8455\n",
      "Epoch 513/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1545 - accuracy: 0.9386 - val_loss: 0.6206 - val_accuracy: 0.8688\n",
      "Epoch 514/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1475 - accuracy: 0.9423 - val_loss: 0.6123 - val_accuracy: 0.8746\n",
      "Epoch 515/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1576 - accuracy: 0.9328 - val_loss: 0.6167 - val_accuracy: 0.8455\n",
      "Epoch 516/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1614 - accuracy: 0.9306 - val_loss: 0.6162 - val_accuracy: 0.8513\n",
      "Epoch 517/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1461 - accuracy: 0.9401 - val_loss: 0.6303 - val_accuracy: 0.8542\n",
      "Epoch 518/2500\n",
      "18/18 [==============================] - 1s 28ms/step - loss: 0.1586 - accuracy: 0.9357 - val_loss: 0.6373 - val_accuracy: 0.8455\n",
      "Epoch 519/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1657 - accuracy: 0.9321 - val_loss: 0.6090 - val_accuracy: 0.8717\n",
      "Epoch 520/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1536 - accuracy: 0.9386 - val_loss: 0.6346 - val_accuracy: 0.8426\n",
      "Epoch 521/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1429 - accuracy: 0.9379 - val_loss: 0.6122 - val_accuracy: 0.8630\n",
      "Epoch 522/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1336 - accuracy: 0.9459 - val_loss: 0.6434 - val_accuracy: 0.8513\n",
      "Epoch 523/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1550 - accuracy: 0.9379 - val_loss: 0.6186 - val_accuracy: 0.8601\n",
      "Epoch 524/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1520 - accuracy: 0.9408 - val_loss: 0.6059 - val_accuracy: 0.8659\n",
      "Epoch 525/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1329 - accuracy: 0.9452 - val_loss: 0.6393 - val_accuracy: 0.8630\n",
      "Epoch 526/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1456 - accuracy: 0.9394 - val_loss: 0.6368 - val_accuracy: 0.8484\n",
      "Epoch 527/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1574 - accuracy: 0.9386 - val_loss: 0.6453 - val_accuracy: 0.8630\n",
      "Epoch 528/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1460 - accuracy: 0.9328 - val_loss: 0.6288 - val_accuracy: 0.8630\n",
      "Epoch 529/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1530 - accuracy: 0.9423 - val_loss: 0.6347 - val_accuracy: 0.8542\n",
      "Epoch 530/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1521 - accuracy: 0.9364 - val_loss: 0.6377 - val_accuracy: 0.8601\n",
      "Epoch 531/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1513 - accuracy: 0.9386 - val_loss: 0.6340 - val_accuracy: 0.8484\n",
      "Epoch 532/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1476 - accuracy: 0.9379 - val_loss: 0.6155 - val_accuracy: 0.8542\n",
      "Epoch 533/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1448 - accuracy: 0.9416 - val_loss: 0.6190 - val_accuracy: 0.8776\n",
      "Epoch 534/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1423 - accuracy: 0.9394 - val_loss: 0.6193 - val_accuracy: 0.8601\n",
      "Epoch 535/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1500 - accuracy: 0.9386 - val_loss: 0.6300 - val_accuracy: 0.8513\n",
      "Epoch 536/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1415 - accuracy: 0.9357 - val_loss: 0.6420 - val_accuracy: 0.8601\n",
      "Epoch 537/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1639 - accuracy: 0.9328 - val_loss: 0.6254 - val_accuracy: 0.8601\n",
      "Epoch 538/2500\n",
      "18/18 [==============================] - 0s 28ms/step - loss: 0.1502 - accuracy: 0.9357 - val_loss: 0.6666 - val_accuracy: 0.8542\n",
      "Epoch 539/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1354 - accuracy: 0.9408 - val_loss: 0.6707 - val_accuracy: 0.8484\n",
      "Epoch 540/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1479 - accuracy: 0.9372 - val_loss: 0.6402 - val_accuracy: 0.8484\n",
      "Epoch 541/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1404 - accuracy: 0.9416 - val_loss: 0.6218 - val_accuracy: 0.8542\n",
      "Epoch 542/2500\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.1429 - accuracy: 0.9423 - val_loss: 0.6659 - val_accuracy: 0.8484\n",
      "Epoch 543/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1620 - accuracy: 0.9394 - val_loss: 0.6864 - val_accuracy: 0.8309\n",
      "Epoch 544/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1479 - accuracy: 0.9386 - val_loss: 0.6604 - val_accuracy: 0.8571\n",
      "Epoch 545/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1385 - accuracy: 0.9408 - val_loss: 0.6466 - val_accuracy: 0.8601\n",
      "Epoch 546/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1452 - accuracy: 0.9386 - val_loss: 0.6409 - val_accuracy: 0.8601\n",
      "Epoch 547/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1503 - accuracy: 0.9364 - val_loss: 0.6222 - val_accuracy: 0.8601\n",
      "Epoch 548/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1454 - accuracy: 0.9430 - val_loss: 0.6278 - val_accuracy: 0.8630\n",
      "Epoch 549/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1436 - accuracy: 0.9394 - val_loss: 0.6372 - val_accuracy: 0.8542\n",
      "Epoch 550/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1504 - accuracy: 0.9321 - val_loss: 0.6651 - val_accuracy: 0.8659\n",
      "Epoch 551/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1331 - accuracy: 0.9430 - val_loss: 0.6367 - val_accuracy: 0.8601\n",
      "Epoch 552/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1485 - accuracy: 0.9408 - val_loss: 0.6549 - val_accuracy: 0.8601\n",
      "Epoch 553/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1528 - accuracy: 0.9372 - val_loss: 0.6404 - val_accuracy: 0.8659\n",
      "Epoch 554/2500\n",
      "18/18 [==============================] - 0s 28ms/step - loss: 0.1546 - accuracy: 0.9364 - val_loss: 0.6498 - val_accuracy: 0.8571\n",
      "Epoch 555/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1630 - accuracy: 0.9364 - val_loss: 0.6323 - val_accuracy: 0.8542\n",
      "Epoch 556/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1438 - accuracy: 0.9328 - val_loss: 0.6349 - val_accuracy: 0.8571\n",
      "Epoch 557/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1415 - accuracy: 0.9394 - val_loss: 0.6395 - val_accuracy: 0.8717\n",
      "Epoch 558/2500\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.1473 - accuracy: 0.9394 - val_loss: 0.6242 - val_accuracy: 0.8717\n",
      "Epoch 559/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1453 - accuracy: 0.9401 - val_loss: 0.6228 - val_accuracy: 0.8659\n",
      "Epoch 560/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.1403 - accuracy: 0.9408 - val_loss: 0.6401 - val_accuracy: 0.8601\n",
      "Epoch 561/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1428 - accuracy: 0.9438 - val_loss: 0.6422 - val_accuracy: 0.8513\n",
      "Epoch 562/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1306 - accuracy: 0.9481 - val_loss: 0.6439 - val_accuracy: 0.8542\n",
      "Epoch 563/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1578 - accuracy: 0.9277 - val_loss: 0.6273 - val_accuracy: 0.8688\n",
      "Epoch 564/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1300 - accuracy: 0.9423 - val_loss: 0.6517 - val_accuracy: 0.8426\n",
      "Epoch 565/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1462 - accuracy: 0.9364 - val_loss: 0.6540 - val_accuracy: 0.8717\n",
      "Epoch 566/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1422 - accuracy: 0.9364 - val_loss: 0.6511 - val_accuracy: 0.8571\n",
      "Epoch 567/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1479 - accuracy: 0.9394 - val_loss: 0.6549 - val_accuracy: 0.8659\n",
      "Epoch 568/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1375 - accuracy: 0.9459 - val_loss: 0.6295 - val_accuracy: 0.8601\n",
      "Epoch 569/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1400 - accuracy: 0.9438 - val_loss: 0.6301 - val_accuracy: 0.8601\n",
      "Epoch 570/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1403 - accuracy: 0.9445 - val_loss: 0.6456 - val_accuracy: 0.8746\n",
      "Epoch 571/2500\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.1489 - accuracy: 0.9350 - val_loss: 0.6605 - val_accuracy: 0.8630\n",
      "Epoch 572/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1553 - accuracy: 0.9386 - val_loss: 0.6527 - val_accuracy: 0.8746\n",
      "Epoch 573/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1387 - accuracy: 0.9445 - val_loss: 0.6640 - val_accuracy: 0.8571\n",
      "Epoch 574/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1601 - accuracy: 0.9313 - val_loss: 0.6403 - val_accuracy: 0.8659\n",
      "Epoch 575/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1376 - accuracy: 0.9430 - val_loss: 0.6828 - val_accuracy: 0.8513\n",
      "Epoch 576/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1430 - accuracy: 0.9416 - val_loss: 0.6889 - val_accuracy: 0.8484\n",
      "Epoch 577/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1417 - accuracy: 0.9401 - val_loss: 0.6505 - val_accuracy: 0.8776\n",
      "Epoch 578/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1491 - accuracy: 0.9364 - val_loss: 0.6196 - val_accuracy: 0.8601\n",
      "Epoch 579/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1549 - accuracy: 0.9401 - val_loss: 0.6503 - val_accuracy: 0.8630\n",
      "Epoch 580/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1573 - accuracy: 0.9372 - val_loss: 0.6572 - val_accuracy: 0.8455\n",
      "Epoch 581/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1377 - accuracy: 0.9438 - val_loss: 0.6625 - val_accuracy: 0.8571\n",
      "Epoch 582/2500\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.1399 - accuracy: 0.9438 - val_loss: 0.6408 - val_accuracy: 0.8571\n",
      "Epoch 583/2500\n",
      "18/18 [==============================] - 1s 28ms/step - loss: 0.1377 - accuracy: 0.9445 - val_loss: 0.6456 - val_accuracy: 0.8426\n",
      "Epoch 584/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1381 - accuracy: 0.9379 - val_loss: 0.6244 - val_accuracy: 0.8717\n",
      "Epoch 585/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1586 - accuracy: 0.9321 - val_loss: 0.6227 - val_accuracy: 0.8659\n",
      "Epoch 586/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1388 - accuracy: 0.9386 - val_loss: 0.6570 - val_accuracy: 0.8542\n",
      "Epoch 587/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1472 - accuracy: 0.9343 - val_loss: 0.6605 - val_accuracy: 0.8513\n",
      "Epoch 588/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1452 - accuracy: 0.9416 - val_loss: 0.6262 - val_accuracy: 0.8601\n",
      "Epoch 589/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1512 - accuracy: 0.9386 - val_loss: 0.6675 - val_accuracy: 0.8630\n",
      "Epoch 590/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.1333 - accuracy: 0.9438 - val_loss: 0.6748 - val_accuracy: 0.8397\n",
      "Epoch 591/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1272 - accuracy: 0.9459 - val_loss: 0.6592 - val_accuracy: 0.8630\n",
      "Epoch 592/2500\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.1487 - accuracy: 0.9408 - val_loss: 0.6387 - val_accuracy: 0.8455\n",
      "Epoch 593/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1337 - accuracy: 0.9481 - val_loss: 0.6633 - val_accuracy: 0.8630\n",
      "Epoch 594/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1534 - accuracy: 0.9401 - val_loss: 0.6354 - val_accuracy: 0.8571\n",
      "Epoch 595/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1529 - accuracy: 0.9321 - val_loss: 0.6288 - val_accuracy: 0.8601\n",
      "Epoch 596/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1521 - accuracy: 0.9394 - val_loss: 0.6605 - val_accuracy: 0.8484\n",
      "Epoch 597/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1444 - accuracy: 0.9343 - val_loss: 0.6597 - val_accuracy: 0.8630\n",
      "Epoch 598/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1396 - accuracy: 0.9416 - val_loss: 0.6660 - val_accuracy: 0.8571\n",
      "Epoch 599/2500\n",
      "18/18 [==============================] - 0s 28ms/step - loss: 0.1358 - accuracy: 0.9416 - val_loss: 0.6560 - val_accuracy: 0.8688\n",
      "Epoch 600/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1256 - accuracy: 0.9438 - val_loss: 0.6391 - val_accuracy: 0.8571\n",
      "Epoch 601/2500\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.1489 - accuracy: 0.9408 - val_loss: 0.6583 - val_accuracy: 0.8601\n",
      "Epoch 602/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1333 - accuracy: 0.9452 - val_loss: 0.6390 - val_accuracy: 0.8571\n",
      "Epoch 603/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1385 - accuracy: 0.9423 - val_loss: 0.6303 - val_accuracy: 0.8571\n",
      "Epoch 604/2500\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.1425 - accuracy: 0.9401 - val_loss: 0.6813 - val_accuracy: 0.8338\n",
      "Epoch 605/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1318 - accuracy: 0.9430 - val_loss: 0.6677 - val_accuracy: 0.8571\n",
      "Epoch 606/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1507 - accuracy: 0.9379 - val_loss: 0.6685 - val_accuracy: 0.8659\n",
      "Epoch 607/2500\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.1379 - accuracy: 0.9386 - val_loss: 0.6665 - val_accuracy: 0.8630\n",
      "Epoch 608/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1477 - accuracy: 0.9408 - val_loss: 0.6396 - val_accuracy: 0.8601\n",
      "Epoch 609/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1374 - accuracy: 0.9481 - val_loss: 0.6647 - val_accuracy: 0.8513\n",
      "Epoch 610/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1346 - accuracy: 0.9379 - val_loss: 0.6568 - val_accuracy: 0.8630\n",
      "Epoch 611/2500\n",
      "18/18 [==============================] - 1s 28ms/step - loss: 0.1409 - accuracy: 0.9438 - val_loss: 0.6868 - val_accuracy: 0.8484\n",
      "Epoch 612/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1425 - accuracy: 0.9401 - val_loss: 0.6897 - val_accuracy: 0.8601\n",
      "Epoch 613/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1465 - accuracy: 0.9379 - val_loss: 0.6669 - val_accuracy: 0.8688\n",
      "Epoch 614/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1413 - accuracy: 0.9438 - val_loss: 0.6815 - val_accuracy: 0.8513\n",
      "Epoch 615/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1508 - accuracy: 0.9313 - val_loss: 0.6663 - val_accuracy: 0.8659\n",
      "Epoch 616/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1354 - accuracy: 0.9445 - val_loss: 0.6854 - val_accuracy: 0.8397\n",
      "Epoch 617/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1324 - accuracy: 0.9438 - val_loss: 0.6663 - val_accuracy: 0.8601\n",
      "Epoch 618/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1622 - accuracy: 0.9313 - val_loss: 0.6614 - val_accuracy: 0.8455\n",
      "Epoch 619/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1610 - accuracy: 0.9350 - val_loss: 0.6656 - val_accuracy: 0.8659\n",
      "Epoch 620/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1596 - accuracy: 0.9350 - val_loss: 0.6433 - val_accuracy: 0.8455\n",
      "Epoch 621/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1466 - accuracy: 0.9394 - val_loss: 0.6553 - val_accuracy: 0.8542\n",
      "Epoch 622/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1428 - accuracy: 0.9394 - val_loss: 0.6451 - val_accuracy: 0.8717\n",
      "Epoch 623/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.1437 - accuracy: 0.9372 - val_loss: 0.6568 - val_accuracy: 0.8630\n",
      "Epoch 624/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1458 - accuracy: 0.9372 - val_loss: 0.6607 - val_accuracy: 0.8542\n",
      "Epoch 625/2500\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.1431 - accuracy: 0.9438 - val_loss: 0.6777 - val_accuracy: 0.8601\n",
      "Epoch 626/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1695 - accuracy: 0.9372 - val_loss: 0.6512 - val_accuracy: 0.8367\n",
      "Epoch 627/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1445 - accuracy: 0.9357 - val_loss: 0.6445 - val_accuracy: 0.8717\n",
      "Epoch 628/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1439 - accuracy: 0.9372 - val_loss: 0.6222 - val_accuracy: 0.8513\n",
      "Epoch 629/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1390 - accuracy: 0.9394 - val_loss: 0.6479 - val_accuracy: 0.8630\n",
      "Epoch 630/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1481 - accuracy: 0.9430 - val_loss: 0.6507 - val_accuracy: 0.8542\n",
      "Epoch 631/2500\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.1336 - accuracy: 0.9416 - val_loss: 0.6493 - val_accuracy: 0.8630\n",
      "Epoch 632/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1386 - accuracy: 0.9357 - val_loss: 0.6554 - val_accuracy: 0.8688\n",
      "Epoch 633/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1505 - accuracy: 0.9423 - val_loss: 0.6276 - val_accuracy: 0.8688\n",
      "Epoch 634/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1369 - accuracy: 0.9423 - val_loss: 0.6489 - val_accuracy: 0.8542\n",
      "Epoch 635/2500\n",
      "18/18 [==============================] - 1s 28ms/step - loss: 0.1330 - accuracy: 0.9481 - val_loss: 0.6484 - val_accuracy: 0.8571\n",
      "Epoch 636/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1472 - accuracy: 0.9408 - val_loss: 0.6680 - val_accuracy: 0.8717\n",
      "Epoch 637/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1447 - accuracy: 0.9386 - val_loss: 0.6492 - val_accuracy: 0.8571\n",
      "Epoch 638/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1369 - accuracy: 0.9423 - val_loss: 0.6363 - val_accuracy: 0.8601\n",
      "Epoch 639/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1390 - accuracy: 0.9394 - val_loss: 0.6211 - val_accuracy: 0.8746\n",
      "Epoch 640/2500\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.1333 - accuracy: 0.9423 - val_loss: 0.6612 - val_accuracy: 0.8746\n",
      "Epoch 641/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1493 - accuracy: 0.9430 - val_loss: 0.6520 - val_accuracy: 0.8542\n",
      "Epoch 642/2500\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 0.1409 - accuracy: 0.9430 - val_loss: 0.6547 - val_accuracy: 0.8630\n",
      "Epoch 643/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1428 - accuracy: 0.9423 - val_loss: 0.6719 - val_accuracy: 0.8455\n",
      "Epoch 644/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.1463 - accuracy: 0.9379 - val_loss: 0.6770 - val_accuracy: 0.8630\n",
      "Epoch 645/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1346 - accuracy: 0.9445 - val_loss: 0.6604 - val_accuracy: 0.8571\n",
      "Epoch 646/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1396 - accuracy: 0.9459 - val_loss: 0.6726 - val_accuracy: 0.8601\n",
      "Epoch 647/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1336 - accuracy: 0.9511 - val_loss: 0.6920 - val_accuracy: 0.8601\n",
      "Epoch 648/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1429 - accuracy: 0.9386 - val_loss: 0.6852 - val_accuracy: 0.8601\n",
      "Epoch 649/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1264 - accuracy: 0.9445 - val_loss: 0.6810 - val_accuracy: 0.8630\n",
      "Epoch 650/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.1324 - accuracy: 0.9474 - val_loss: 0.6563 - val_accuracy: 0.8717\n",
      "Epoch 651/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1361 - accuracy: 0.9430 - val_loss: 0.6769 - val_accuracy: 0.8542\n",
      "Epoch 652/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1233 - accuracy: 0.9438 - val_loss: 0.6631 - val_accuracy: 0.8630\n",
      "Epoch 653/2500\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.1405 - accuracy: 0.9401 - val_loss: 0.6843 - val_accuracy: 0.8688\n",
      "Epoch 654/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1391 - accuracy: 0.9416 - val_loss: 0.6715 - val_accuracy: 0.8630\n",
      "Epoch 655/2500\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.1317 - accuracy: 0.9452 - val_loss: 0.6462 - val_accuracy: 0.8746\n",
      "Epoch 656/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.1381 - accuracy: 0.9408 - val_loss: 0.6576 - val_accuracy: 0.8601\n",
      "Epoch 657/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1383 - accuracy: 0.9438 - val_loss: 0.6891 - val_accuracy: 0.8484\n",
      "Epoch 658/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1364 - accuracy: 0.9430 - val_loss: 0.6499 - val_accuracy: 0.8571\n",
      "Epoch 659/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1378 - accuracy: 0.9423 - val_loss: 0.6524 - val_accuracy: 0.8601\n",
      "Epoch 660/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1411 - accuracy: 0.9416 - val_loss: 0.6913 - val_accuracy: 0.8659\n",
      "Epoch 661/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1485 - accuracy: 0.9364 - val_loss: 0.6766 - val_accuracy: 0.8571\n",
      "Epoch 662/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1396 - accuracy: 0.9408 - val_loss: 0.6745 - val_accuracy: 0.8513\n",
      "Epoch 663/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1421 - accuracy: 0.9416 - val_loss: 0.6734 - val_accuracy: 0.8630\n",
      "Epoch 664/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1267 - accuracy: 0.9503 - val_loss: 0.6628 - val_accuracy: 0.8601\n",
      "Epoch 665/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1404 - accuracy: 0.9394 - val_loss: 0.6941 - val_accuracy: 0.8571\n",
      "Epoch 666/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1280 - accuracy: 0.9474 - val_loss: 0.7059 - val_accuracy: 0.8659\n",
      "Epoch 667/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1776 - accuracy: 0.9240 - val_loss: 0.7061 - val_accuracy: 0.8309\n",
      "Epoch 668/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1494 - accuracy: 0.9386 - val_loss: 0.6781 - val_accuracy: 0.8601\n",
      "Epoch 669/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1323 - accuracy: 0.9438 - val_loss: 0.6571 - val_accuracy: 0.8455\n",
      "Epoch 670/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1284 - accuracy: 0.9401 - val_loss: 0.6706 - val_accuracy: 0.8659\n",
      "Epoch 671/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1317 - accuracy: 0.9416 - val_loss: 0.6652 - val_accuracy: 0.8513\n",
      "Epoch 672/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1331 - accuracy: 0.9408 - val_loss: 0.6553 - val_accuracy: 0.8630\n",
      "Epoch 673/2500\n",
      "18/18 [==============================] - 1s 33ms/step - loss: 0.1519 - accuracy: 0.9379 - val_loss: 0.6684 - val_accuracy: 0.8601\n",
      "Epoch 674/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1413 - accuracy: 0.9401 - val_loss: 0.6661 - val_accuracy: 0.8659\n",
      "Epoch 675/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1347 - accuracy: 0.9416 - val_loss: 0.6713 - val_accuracy: 0.8688\n",
      "Epoch 676/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.1377 - accuracy: 0.9511 - val_loss: 0.6582 - val_accuracy: 0.8513\n",
      "Epoch 677/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1251 - accuracy: 0.9489 - val_loss: 0.6584 - val_accuracy: 0.8513\n",
      "Epoch 678/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1228 - accuracy: 0.9496 - val_loss: 0.6950 - val_accuracy: 0.8542\n",
      "Epoch 679/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1329 - accuracy: 0.9416 - val_loss: 0.6910 - val_accuracy: 0.8571\n",
      "Epoch 680/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1261 - accuracy: 0.9481 - val_loss: 0.6892 - val_accuracy: 0.8659\n",
      "Epoch 681/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1210 - accuracy: 0.9489 - val_loss: 0.6851 - val_accuracy: 0.8805\n",
      "Epoch 682/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1561 - accuracy: 0.9343 - val_loss: 0.7106 - val_accuracy: 0.8542\n",
      "Epoch 683/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1446 - accuracy: 0.9372 - val_loss: 0.6745 - val_accuracy: 0.8659\n",
      "Epoch 684/2500\n",
      "18/18 [==============================] - 1s 28ms/step - loss: 0.1399 - accuracy: 0.9452 - val_loss: 0.6614 - val_accuracy: 0.8688\n",
      "Epoch 685/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1450 - accuracy: 0.9452 - val_loss: 0.6680 - val_accuracy: 0.8688\n",
      "Epoch 686/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1427 - accuracy: 0.9394 - val_loss: 0.6487 - val_accuracy: 0.8659\n",
      "Epoch 687/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1353 - accuracy: 0.9459 - val_loss: 0.6475 - val_accuracy: 0.8659\n",
      "Epoch 688/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1336 - accuracy: 0.9481 - val_loss: 0.6425 - val_accuracy: 0.8630\n",
      "Epoch 689/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1278 - accuracy: 0.9423 - val_loss: 0.6450 - val_accuracy: 0.8542\n",
      "Epoch 690/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.1297 - accuracy: 0.9438 - val_loss: 0.6646 - val_accuracy: 0.8659\n",
      "Epoch 691/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1535 - accuracy: 0.9364 - val_loss: 0.6646 - val_accuracy: 0.8601\n",
      "Epoch 692/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1339 - accuracy: 0.9408 - val_loss: 0.6476 - val_accuracy: 0.8688\n",
      "Epoch 693/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1349 - accuracy: 0.9452 - val_loss: 0.6679 - val_accuracy: 0.8688\n",
      "Epoch 694/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1356 - accuracy: 0.9452 - val_loss: 0.6604 - val_accuracy: 0.8717\n",
      "Epoch 695/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1434 - accuracy: 0.9459 - val_loss: 0.6701 - val_accuracy: 0.8601\n",
      "Epoch 696/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1444 - accuracy: 0.9416 - val_loss: 0.6607 - val_accuracy: 0.8542\n",
      "Epoch 697/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1276 - accuracy: 0.9438 - val_loss: 0.6631 - val_accuracy: 0.8659\n",
      "Epoch 698/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1457 - accuracy: 0.9379 - val_loss: 0.6534 - val_accuracy: 0.8746\n",
      "Epoch 699/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1473 - accuracy: 0.9379 - val_loss: 0.6841 - val_accuracy: 0.8601\n",
      "Epoch 700/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1493 - accuracy: 0.9343 - val_loss: 0.6763 - val_accuracy: 0.8513\n",
      "Epoch 701/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1347 - accuracy: 0.9445 - val_loss: 0.6866 - val_accuracy: 0.8630\n",
      "Epoch 702/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1313 - accuracy: 0.9452 - val_loss: 0.6871 - val_accuracy: 0.8746\n",
      "Epoch 703/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1492 - accuracy: 0.9386 - val_loss: 0.6877 - val_accuracy: 0.8659\n",
      "Epoch 704/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1388 - accuracy: 0.9379 - val_loss: 0.6753 - val_accuracy: 0.8484\n",
      "Epoch 705/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1426 - accuracy: 0.9394 - val_loss: 0.6630 - val_accuracy: 0.8805\n",
      "Epoch 706/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1327 - accuracy: 0.9408 - val_loss: 0.6818 - val_accuracy: 0.8601\n",
      "Epoch 707/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1452 - accuracy: 0.9416 - val_loss: 0.6924 - val_accuracy: 0.8630\n",
      "Epoch 708/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1351 - accuracy: 0.9379 - val_loss: 0.6953 - val_accuracy: 0.8717\n",
      "Epoch 709/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1335 - accuracy: 0.9452 - val_loss: 0.6785 - val_accuracy: 0.8542\n",
      "Epoch 710/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1423 - accuracy: 0.9408 - val_loss: 0.7079 - val_accuracy: 0.8513\n",
      "Epoch 711/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1273 - accuracy: 0.9474 - val_loss: 0.7121 - val_accuracy: 0.8717\n",
      "Epoch 712/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1324 - accuracy: 0.9423 - val_loss: 0.7238 - val_accuracy: 0.8659\n",
      "Epoch 713/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1244 - accuracy: 0.9481 - val_loss: 0.7048 - val_accuracy: 0.8630\n",
      "Epoch 714/2500\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.1347 - accuracy: 0.9489 - val_loss: 0.6927 - val_accuracy: 0.8630\n",
      "Epoch 715/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1306 - accuracy: 0.9408 - val_loss: 0.7095 - val_accuracy: 0.8630\n",
      "Epoch 716/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.1394 - accuracy: 0.9408 - val_loss: 0.7018 - val_accuracy: 0.8571\n",
      "Epoch 717/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1256 - accuracy: 0.9481 - val_loss: 0.6919 - val_accuracy: 0.8571\n",
      "Epoch 718/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1348 - accuracy: 0.9467 - val_loss: 0.6927 - val_accuracy: 0.8601\n",
      "Epoch 719/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1192 - accuracy: 0.9467 - val_loss: 0.6948 - val_accuracy: 0.8601\n",
      "Epoch 720/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1373 - accuracy: 0.9364 - val_loss: 0.6916 - val_accuracy: 0.8659\n",
      "Epoch 721/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1309 - accuracy: 0.9357 - val_loss: 0.6747 - val_accuracy: 0.8659\n",
      "Epoch 722/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1503 - accuracy: 0.9394 - val_loss: 0.6993 - val_accuracy: 0.8601\n",
      "Epoch 723/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1523 - accuracy: 0.9364 - val_loss: 0.6792 - val_accuracy: 0.8717\n",
      "Epoch 724/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.1383 - accuracy: 0.9438 - val_loss: 0.6777 - val_accuracy: 0.8630\n",
      "Epoch 725/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1259 - accuracy: 0.9459 - val_loss: 0.6646 - val_accuracy: 0.8571\n",
      "Epoch 726/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1221 - accuracy: 0.9474 - val_loss: 0.6703 - val_accuracy: 0.8688\n",
      "Epoch 727/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1289 - accuracy: 0.9474 - val_loss: 0.6810 - val_accuracy: 0.8630\n",
      "Epoch 728/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1263 - accuracy: 0.9481 - val_loss: 0.6807 - val_accuracy: 0.8659\n",
      "Epoch 729/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1173 - accuracy: 0.9459 - val_loss: 0.6953 - val_accuracy: 0.8601\n",
      "Epoch 730/2500\n",
      "18/18 [==============================] - 0s 28ms/step - loss: 0.1364 - accuracy: 0.9408 - val_loss: 0.6847 - val_accuracy: 0.8630\n",
      "Epoch 731/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1389 - accuracy: 0.9386 - val_loss: 0.7395 - val_accuracy: 0.8571\n",
      "Epoch 732/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1406 - accuracy: 0.9379 - val_loss: 0.6995 - val_accuracy: 0.8630\n",
      "Epoch 733/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.1347 - accuracy: 0.9481 - val_loss: 0.6927 - val_accuracy: 0.8630\n",
      "Epoch 734/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1325 - accuracy: 0.9445 - val_loss: 0.6808 - val_accuracy: 0.8659\n",
      "Epoch 735/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1349 - accuracy: 0.9379 - val_loss: 0.6771 - val_accuracy: 0.8717\n",
      "Epoch 736/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1242 - accuracy: 0.9481 - val_loss: 0.6996 - val_accuracy: 0.8688\n",
      "Epoch 737/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1234 - accuracy: 0.9503 - val_loss: 0.7395 - val_accuracy: 0.8513\n",
      "Epoch 738/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1411 - accuracy: 0.9364 - val_loss: 0.7044 - val_accuracy: 0.8601\n",
      "Epoch 739/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1299 - accuracy: 0.9467 - val_loss: 0.7030 - val_accuracy: 0.8513\n",
      "Epoch 740/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1320 - accuracy: 0.9452 - val_loss: 0.7080 - val_accuracy: 0.8630\n",
      "Epoch 741/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1377 - accuracy: 0.9430 - val_loss: 0.6811 - val_accuracy: 0.8688\n",
      "Epoch 742/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1357 - accuracy: 0.9430 - val_loss: 0.7083 - val_accuracy: 0.8484\n",
      "Epoch 743/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1333 - accuracy: 0.9401 - val_loss: 0.7208 - val_accuracy: 0.8542\n",
      "Epoch 744/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1559 - accuracy: 0.9372 - val_loss: 0.6920 - val_accuracy: 0.8542\n",
      "Epoch 745/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1274 - accuracy: 0.9452 - val_loss: 0.6938 - val_accuracy: 0.8571\n",
      "Epoch 746/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1384 - accuracy: 0.9445 - val_loss: 0.7165 - val_accuracy: 0.8542\n",
      "Epoch 747/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1344 - accuracy: 0.9438 - val_loss: 0.6915 - val_accuracy: 0.8513\n",
      "Epoch 748/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1401 - accuracy: 0.9416 - val_loss: 0.6956 - val_accuracy: 0.8513\n",
      "Epoch 749/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1840 - accuracy: 0.9357 - val_loss: 0.6801 - val_accuracy: 0.8601\n",
      "Epoch 750/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1596 - accuracy: 0.9408 - val_loss: 0.6915 - val_accuracy: 0.8513\n",
      "Epoch 751/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1274 - accuracy: 0.9452 - val_loss: 0.6934 - val_accuracy: 0.8601\n",
      "Epoch 752/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1306 - accuracy: 0.9474 - val_loss: 0.6903 - val_accuracy: 0.8630\n",
      "Epoch 753/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1199 - accuracy: 0.9445 - val_loss: 0.6735 - val_accuracy: 0.8717\n",
      "Epoch 754/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1276 - accuracy: 0.9430 - val_loss: 0.6814 - val_accuracy: 0.8717\n",
      "Epoch 755/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1368 - accuracy: 0.9416 - val_loss: 0.6833 - val_accuracy: 0.8571\n",
      "Epoch 756/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1186 - accuracy: 0.9489 - val_loss: 0.6898 - val_accuracy: 0.8659\n",
      "Epoch 757/2500\n",
      "18/18 [==============================] - 1s 28ms/step - loss: 0.1302 - accuracy: 0.9459 - val_loss: 0.7098 - val_accuracy: 0.8542\n",
      "Epoch 758/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1384 - accuracy: 0.9408 - val_loss: 0.6855 - val_accuracy: 0.8542\n",
      "Epoch 759/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1292 - accuracy: 0.9445 - val_loss: 0.6896 - val_accuracy: 0.8630\n",
      "Epoch 760/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1361 - accuracy: 0.9372 - val_loss: 0.7027 - val_accuracy: 0.8659\n",
      "Epoch 761/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1497 - accuracy: 0.9459 - val_loss: 0.7069 - val_accuracy: 0.8601\n",
      "Epoch 762/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1431 - accuracy: 0.9416 - val_loss: 0.6775 - val_accuracy: 0.8746\n",
      "Epoch 763/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1478 - accuracy: 0.9416 - val_loss: 0.6751 - val_accuracy: 0.8776\n",
      "Epoch 764/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1465 - accuracy: 0.9343 - val_loss: 0.6906 - val_accuracy: 0.8863\n",
      "Epoch 765/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.1224 - accuracy: 0.9467 - val_loss: 0.6903 - val_accuracy: 0.8776\n",
      "Epoch 766/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1403 - accuracy: 0.9423 - val_loss: 0.7015 - val_accuracy: 0.8513\n",
      "Epoch 767/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1430 - accuracy: 0.9379 - val_loss: 0.6805 - val_accuracy: 0.8688\n",
      "Epoch 768/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1386 - accuracy: 0.9364 - val_loss: 0.6705 - val_accuracy: 0.8601\n",
      "Epoch 769/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1267 - accuracy: 0.9423 - val_loss: 0.6886 - val_accuracy: 0.8601\n",
      "Epoch 770/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1212 - accuracy: 0.9489 - val_loss: 0.6895 - val_accuracy: 0.8688\n",
      "Epoch 771/2500\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.1337 - accuracy: 0.9438 - val_loss: 0.7277 - val_accuracy: 0.8542\n",
      "Epoch 772/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1391 - accuracy: 0.9379 - val_loss: 0.7365 - val_accuracy: 0.8630\n",
      "Epoch 773/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1376 - accuracy: 0.9489 - val_loss: 0.7301 - val_accuracy: 0.8717\n",
      "Epoch 774/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1298 - accuracy: 0.9416 - val_loss: 0.6846 - val_accuracy: 0.8717\n",
      "Epoch 775/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1325 - accuracy: 0.9445 - val_loss: 0.6918 - val_accuracy: 0.8717\n",
      "Epoch 776/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1624 - accuracy: 0.9350 - val_loss: 0.6973 - val_accuracy: 0.8717\n",
      "Epoch 777/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1346 - accuracy: 0.9423 - val_loss: 0.6711 - val_accuracy: 0.8630\n",
      "Epoch 778/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1247 - accuracy: 0.9445 - val_loss: 0.6735 - val_accuracy: 0.8776\n",
      "Epoch 779/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1224 - accuracy: 0.9489 - val_loss: 0.7062 - val_accuracy: 0.8717\n",
      "Epoch 780/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1407 - accuracy: 0.9386 - val_loss: 0.7101 - val_accuracy: 0.8513\n",
      "Epoch 781/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1242 - accuracy: 0.9503 - val_loss: 0.6879 - val_accuracy: 0.8659\n",
      "Epoch 782/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1356 - accuracy: 0.9423 - val_loss: 0.6944 - val_accuracy: 0.8659\n",
      "Epoch 783/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1444 - accuracy: 0.9416 - val_loss: 0.6972 - val_accuracy: 0.8659\n",
      "Epoch 784/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.1283 - accuracy: 0.9445 - val_loss: 0.6750 - val_accuracy: 0.8659\n",
      "Epoch 785/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1244 - accuracy: 0.9459 - val_loss: 0.6764 - val_accuracy: 0.8630\n",
      "Epoch 786/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1440 - accuracy: 0.9401 - val_loss: 0.6932 - val_accuracy: 0.8601\n",
      "Epoch 787/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1280 - accuracy: 0.9452 - val_loss: 0.6908 - val_accuracy: 0.8542\n",
      "Epoch 788/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1258 - accuracy: 0.9438 - val_loss: 0.6765 - val_accuracy: 0.8688\n",
      "Epoch 789/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1293 - accuracy: 0.9459 - val_loss: 0.6629 - val_accuracy: 0.8717\n",
      "Epoch 790/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1237 - accuracy: 0.9459 - val_loss: 0.6679 - val_accuracy: 0.8688\n",
      "Epoch 791/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1227 - accuracy: 0.9481 - val_loss: 0.6581 - val_accuracy: 0.8630\n",
      "Epoch 792/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1229 - accuracy: 0.9430 - val_loss: 0.6761 - val_accuracy: 0.8513\n",
      "Epoch 793/2500\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.1223 - accuracy: 0.9489 - val_loss: 0.7092 - val_accuracy: 0.8688\n",
      "Epoch 794/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1187 - accuracy: 0.9481 - val_loss: 0.7097 - val_accuracy: 0.8659\n",
      "Epoch 795/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1277 - accuracy: 0.9438 - val_loss: 0.7062 - val_accuracy: 0.8513\n",
      "Epoch 796/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1287 - accuracy: 0.9481 - val_loss: 0.6960 - val_accuracy: 0.8601\n",
      "Epoch 797/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1312 - accuracy: 0.9438 - val_loss: 0.7005 - val_accuracy: 0.8746\n",
      "Epoch 798/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1397 - accuracy: 0.9474 - val_loss: 0.7084 - val_accuracy: 0.8571\n",
      "Epoch 799/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1307 - accuracy: 0.9452 - val_loss: 0.7042 - val_accuracy: 0.8601\n",
      "Epoch 800/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1229 - accuracy: 0.9481 - val_loss: 0.7106 - val_accuracy: 0.8542\n",
      "Epoch 801/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1327 - accuracy: 0.9452 - val_loss: 0.7004 - val_accuracy: 0.8542\n",
      "Epoch 802/2500\n",
      "18/18 [==============================] - 0s 28ms/step - loss: 0.1244 - accuracy: 0.9445 - val_loss: 0.6926 - val_accuracy: 0.8630\n",
      "Epoch 803/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1344 - accuracy: 0.9386 - val_loss: 0.6857 - val_accuracy: 0.8659\n",
      "Epoch 804/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1240 - accuracy: 0.9474 - val_loss: 0.7058 - val_accuracy: 0.8717\n",
      "Epoch 805/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1286 - accuracy: 0.9467 - val_loss: 0.6760 - val_accuracy: 0.8542\n",
      "Epoch 806/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1335 - accuracy: 0.9438 - val_loss: 0.6877 - val_accuracy: 0.8659\n",
      "Epoch 807/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1301 - accuracy: 0.9423 - val_loss: 0.7165 - val_accuracy: 0.8571\n",
      "Epoch 808/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1265 - accuracy: 0.9438 - val_loss: 0.7024 - val_accuracy: 0.8659\n",
      "Epoch 809/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1237 - accuracy: 0.9489 - val_loss: 0.7766 - val_accuracy: 0.8601\n",
      "Epoch 810/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1278 - accuracy: 0.9503 - val_loss: 0.7710 - val_accuracy: 0.8659\n",
      "Epoch 811/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1608 - accuracy: 0.9372 - val_loss: 0.7508 - val_accuracy: 0.8542\n",
      "Epoch 812/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1281 - accuracy: 0.9416 - val_loss: 0.7371 - val_accuracy: 0.8601\n",
      "Epoch 813/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1371 - accuracy: 0.9459 - val_loss: 0.7370 - val_accuracy: 0.8776\n",
      "Epoch 814/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1252 - accuracy: 0.9459 - val_loss: 0.7517 - val_accuracy: 0.8746\n",
      "Epoch 815/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1284 - accuracy: 0.9438 - val_loss: 0.7061 - val_accuracy: 0.8717\n",
      "Epoch 816/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1270 - accuracy: 0.9503 - val_loss: 0.7149 - val_accuracy: 0.8630\n",
      "Epoch 817/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1181 - accuracy: 0.9467 - val_loss: 0.7350 - val_accuracy: 0.8601\n",
      "Epoch 818/2500\n",
      "18/18 [==============================] - 1s 28ms/step - loss: 0.1325 - accuracy: 0.9445 - val_loss: 0.7649 - val_accuracy: 0.8630\n",
      "Epoch 819/2500\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.1389 - accuracy: 0.9430 - val_loss: 0.7248 - val_accuracy: 0.8659\n",
      "Epoch 820/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1289 - accuracy: 0.9438 - val_loss: 0.7059 - val_accuracy: 0.8659\n",
      "Epoch 821/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1276 - accuracy: 0.9459 - val_loss: 0.7250 - val_accuracy: 0.8659\n",
      "Epoch 822/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1440 - accuracy: 0.9416 - val_loss: 0.7267 - val_accuracy: 0.8601\n",
      "Epoch 823/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1222 - accuracy: 0.9438 - val_loss: 0.7430 - val_accuracy: 0.8601\n",
      "Epoch 824/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1327 - accuracy: 0.9525 - val_loss: 0.7365 - val_accuracy: 0.8746\n",
      "Epoch 825/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1238 - accuracy: 0.9445 - val_loss: 0.7390 - val_accuracy: 0.8746\n",
      "Epoch 826/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1191 - accuracy: 0.9467 - val_loss: 0.7372 - val_accuracy: 0.8571\n",
      "Epoch 827/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1281 - accuracy: 0.9438 - val_loss: 0.7417 - val_accuracy: 0.8542\n",
      "Epoch 828/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1375 - accuracy: 0.9503 - val_loss: 0.7475 - val_accuracy: 0.8630\n",
      "Epoch 829/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1222 - accuracy: 0.9372 - val_loss: 0.7465 - val_accuracy: 0.8659\n",
      "Epoch 830/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1207 - accuracy: 0.9467 - val_loss: 0.7329 - val_accuracy: 0.8542\n",
      "Epoch 831/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1257 - accuracy: 0.9489 - val_loss: 0.7588 - val_accuracy: 0.8630\n",
      "Epoch 832/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1263 - accuracy: 0.9467 - val_loss: 0.7523 - val_accuracy: 0.8630\n",
      "Epoch 833/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1281 - accuracy: 0.9452 - val_loss: 0.7479 - val_accuracy: 0.8717\n",
      "Epoch 834/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1431 - accuracy: 0.9489 - val_loss: 0.7647 - val_accuracy: 0.8571\n",
      "Epoch 835/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1248 - accuracy: 0.9459 - val_loss: 0.7930 - val_accuracy: 0.8513\n",
      "Epoch 836/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1231 - accuracy: 0.9467 - val_loss: 0.7677 - val_accuracy: 0.8601\n",
      "Epoch 837/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1213 - accuracy: 0.9452 - val_loss: 0.7395 - val_accuracy: 0.8601\n",
      "Epoch 838/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1169 - accuracy: 0.9481 - val_loss: 0.7428 - val_accuracy: 0.8542\n",
      "Epoch 839/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1210 - accuracy: 0.9481 - val_loss: 0.7271 - val_accuracy: 0.8659\n",
      "Epoch 840/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1161 - accuracy: 0.9496 - val_loss: 0.7340 - val_accuracy: 0.8571\n",
      "Epoch 841/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1246 - accuracy: 0.9481 - val_loss: 0.7330 - val_accuracy: 0.8542\n",
      "Epoch 842/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1177 - accuracy: 0.9445 - val_loss: 0.7319 - val_accuracy: 0.8571\n",
      "Epoch 843/2500\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.1206 - accuracy: 0.9459 - val_loss: 0.7146 - val_accuracy: 0.8601\n",
      "Epoch 844/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1220 - accuracy: 0.9511 - val_loss: 0.7013 - val_accuracy: 0.8746\n",
      "Epoch 845/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1340 - accuracy: 0.9416 - val_loss: 0.7162 - val_accuracy: 0.8601\n",
      "Epoch 846/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1165 - accuracy: 0.9474 - val_loss: 0.7231 - val_accuracy: 0.8717\n",
      "Epoch 847/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1355 - accuracy: 0.9474 - val_loss: 0.7462 - val_accuracy: 0.8688\n",
      "Epoch 848/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1174 - accuracy: 0.9489 - val_loss: 0.7567 - val_accuracy: 0.8513\n",
      "Epoch 849/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1225 - accuracy: 0.9481 - val_loss: 0.7416 - val_accuracy: 0.8688\n",
      "Epoch 850/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1226 - accuracy: 0.9467 - val_loss: 0.7209 - val_accuracy: 0.8659\n",
      "Epoch 851/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1215 - accuracy: 0.9430 - val_loss: 0.7555 - val_accuracy: 0.8717\n",
      "Epoch 852/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1152 - accuracy: 0.9489 - val_loss: 0.7362 - val_accuracy: 0.8571\n",
      "Epoch 853/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1171 - accuracy: 0.9481 - val_loss: 0.7248 - val_accuracy: 0.8571\n",
      "Epoch 854/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1248 - accuracy: 0.9438 - val_loss: 0.7358 - val_accuracy: 0.8776\n",
      "Epoch 855/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1336 - accuracy: 0.9467 - val_loss: 0.7409 - val_accuracy: 0.8601\n",
      "Epoch 856/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1589 - accuracy: 0.9372 - val_loss: 0.7526 - val_accuracy: 0.8601\n",
      "Epoch 857/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1350 - accuracy: 0.9438 - val_loss: 0.7459 - val_accuracy: 0.8455\n",
      "Epoch 858/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1392 - accuracy: 0.9423 - val_loss: 0.7107 - val_accuracy: 0.8542\n",
      "Epoch 859/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1235 - accuracy: 0.9452 - val_loss: 0.7422 - val_accuracy: 0.8571\n",
      "Epoch 860/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1275 - accuracy: 0.9438 - val_loss: 0.7449 - val_accuracy: 0.8455\n",
      "Epoch 861/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1296 - accuracy: 0.9423 - val_loss: 0.7494 - val_accuracy: 0.8601\n",
      "Epoch 862/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1210 - accuracy: 0.9525 - val_loss: 0.7424 - val_accuracy: 0.8601\n",
      "Epoch 863/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1213 - accuracy: 0.9438 - val_loss: 0.7260 - val_accuracy: 0.8601\n",
      "Epoch 864/2500\n",
      "18/18 [==============================] - 1s 27ms/step - loss: 0.1147 - accuracy: 0.9518 - val_loss: 0.7314 - val_accuracy: 0.8630\n",
      "Epoch 865/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1159 - accuracy: 0.9474 - val_loss: 0.7541 - val_accuracy: 0.8659\n",
      "Epoch 866/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1244 - accuracy: 0.9445 - val_loss: 0.7556 - val_accuracy: 0.8746\n",
      "Epoch 867/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1225 - accuracy: 0.9489 - val_loss: 0.7484 - val_accuracy: 0.8630\n",
      "Epoch 868/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1377 - accuracy: 0.9423 - val_loss: 0.7413 - val_accuracy: 0.8426\n",
      "Epoch 869/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1222 - accuracy: 0.9408 - val_loss: 0.7294 - val_accuracy: 0.8542\n",
      "Epoch 870/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1214 - accuracy: 0.9503 - val_loss: 0.7055 - val_accuracy: 0.8659\n",
      "Epoch 871/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1287 - accuracy: 0.9394 - val_loss: 0.7377 - val_accuracy: 0.8542\n",
      "Epoch 872/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1331 - accuracy: 0.9430 - val_loss: 0.7290 - val_accuracy: 0.8484\n",
      "Epoch 873/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1561 - accuracy: 0.9423 - val_loss: 0.7260 - val_accuracy: 0.8426\n",
      "Epoch 874/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1260 - accuracy: 0.9503 - val_loss: 0.7088 - val_accuracy: 0.8426\n",
      "Epoch 875/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1173 - accuracy: 0.9452 - val_loss: 0.7357 - val_accuracy: 0.8601\n",
      "Epoch 876/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1329 - accuracy: 0.9430 - val_loss: 0.7481 - val_accuracy: 0.8513\n",
      "Epoch 877/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1183 - accuracy: 0.9481 - val_loss: 0.7396 - val_accuracy: 0.8571\n",
      "Epoch 878/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1207 - accuracy: 0.9445 - val_loss: 0.7466 - val_accuracy: 0.8455\n",
      "Epoch 879/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1244 - accuracy: 0.9445 - val_loss: 0.7281 - val_accuracy: 0.8571\n",
      "Epoch 880/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1187 - accuracy: 0.9474 - val_loss: 0.7335 - val_accuracy: 0.8455\n",
      "Epoch 881/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.1281 - accuracy: 0.9489 - val_loss: 0.7236 - val_accuracy: 0.8542\n",
      "Epoch 882/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1230 - accuracy: 0.9474 - val_loss: 0.7206 - val_accuracy: 0.8542\n",
      "Epoch 883/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1157 - accuracy: 0.9533 - val_loss: 0.7243 - val_accuracy: 0.8688\n",
      "Epoch 884/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1134 - accuracy: 0.9496 - val_loss: 0.7316 - val_accuracy: 0.8746\n",
      "Epoch 885/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1269 - accuracy: 0.9452 - val_loss: 0.7447 - val_accuracy: 0.8571\n",
      "Epoch 886/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1304 - accuracy: 0.9394 - val_loss: 0.7169 - val_accuracy: 0.8659\n",
      "Epoch 887/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1759 - accuracy: 0.9313 - val_loss: 0.6774 - val_accuracy: 0.8571\n",
      "Epoch 888/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1373 - accuracy: 0.9445 - val_loss: 0.7279 - val_accuracy: 0.8571\n",
      "Epoch 889/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1476 - accuracy: 0.9394 - val_loss: 0.6782 - val_accuracy: 0.8688\n",
      "Epoch 890/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1277 - accuracy: 0.9445 - val_loss: 0.6817 - val_accuracy: 0.8688\n",
      "Epoch 891/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1293 - accuracy: 0.9438 - val_loss: 0.7131 - val_accuracy: 0.8659\n",
      "Epoch 892/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1301 - accuracy: 0.9467 - val_loss: 0.7266 - val_accuracy: 0.8630\n",
      "Epoch 893/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1205 - accuracy: 0.9438 - val_loss: 0.7363 - val_accuracy: 0.8397\n",
      "Epoch 894/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1322 - accuracy: 0.9452 - val_loss: 0.7003 - val_accuracy: 0.8630\n",
      "Epoch 895/2500\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.1366 - accuracy: 0.9364 - val_loss: 0.7203 - val_accuracy: 0.8601\n",
      "Epoch 896/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1207 - accuracy: 0.9481 - val_loss: 0.7049 - val_accuracy: 0.8571\n",
      "Epoch 897/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1341 - accuracy: 0.9452 - val_loss: 0.7157 - val_accuracy: 0.8484\n",
      "Epoch 898/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1279 - accuracy: 0.9430 - val_loss: 0.6916 - val_accuracy: 0.8659\n",
      "Epoch 899/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1341 - accuracy: 0.9430 - val_loss: 0.7172 - val_accuracy: 0.8571\n",
      "Epoch 900/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1339 - accuracy: 0.9430 - val_loss: 0.7310 - val_accuracy: 0.8542\n",
      "Epoch 901/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1189 - accuracy: 0.9489 - val_loss: 0.7435 - val_accuracy: 0.8542\n",
      "Epoch 902/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1190 - accuracy: 0.9474 - val_loss: 0.7195 - val_accuracy: 0.8571\n",
      "Epoch 903/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1148 - accuracy: 0.9467 - val_loss: 0.7356 - val_accuracy: 0.8513\n",
      "Epoch 904/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1188 - accuracy: 0.9511 - val_loss: 0.7428 - val_accuracy: 0.8542\n",
      "Epoch 905/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1132 - accuracy: 0.9511 - val_loss: 0.7364 - val_accuracy: 0.8571\n",
      "Epoch 906/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1210 - accuracy: 0.9459 - val_loss: 0.7330 - val_accuracy: 0.8630\n",
      "Epoch 907/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1303 - accuracy: 0.9438 - val_loss: 0.7363 - val_accuracy: 0.8542\n",
      "Epoch 908/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1552 - accuracy: 0.9408 - val_loss: 0.7478 - val_accuracy: 0.8571\n",
      "Epoch 909/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1368 - accuracy: 0.9394 - val_loss: 0.7475 - val_accuracy: 0.8571\n",
      "Epoch 910/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1262 - accuracy: 0.9467 - val_loss: 0.7358 - val_accuracy: 0.8717\n",
      "Epoch 911/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1225 - accuracy: 0.9438 - val_loss: 0.7120 - val_accuracy: 0.8601\n",
      "Epoch 912/2500\n",
      "18/18 [==============================] - 1s 28ms/step - loss: 0.1179 - accuracy: 0.9481 - val_loss: 0.7353 - val_accuracy: 0.8659\n",
      "Epoch 913/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1187 - accuracy: 0.9496 - val_loss: 0.7357 - val_accuracy: 0.8601\n",
      "Epoch 914/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1175 - accuracy: 0.9467 - val_loss: 0.7556 - val_accuracy: 0.8630\n",
      "Epoch 915/2500\n",
      "18/18 [==============================] - 1s 28ms/step - loss: 0.1201 - accuracy: 0.9481 - val_loss: 0.7541 - val_accuracy: 0.8601\n",
      "Epoch 916/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1243 - accuracy: 0.9459 - val_loss: 0.7845 - val_accuracy: 0.8542\n",
      "Epoch 917/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1318 - accuracy: 0.9452 - val_loss: 0.7733 - val_accuracy: 0.8571\n",
      "Epoch 918/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1246 - accuracy: 0.9503 - val_loss: 0.7460 - val_accuracy: 0.8513\n",
      "Epoch 919/2500\n",
      "18/18 [==============================] - 1s 28ms/step - loss: 0.1193 - accuracy: 0.9518 - val_loss: 0.7420 - val_accuracy: 0.8426\n",
      "Epoch 920/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1217 - accuracy: 0.9503 - val_loss: 0.7558 - val_accuracy: 0.8542\n",
      "Epoch 921/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1160 - accuracy: 0.9438 - val_loss: 0.7550 - val_accuracy: 0.8688\n",
      "Epoch 922/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1164 - accuracy: 0.9496 - val_loss: 0.7491 - val_accuracy: 0.8513\n",
      "Epoch 923/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1156 - accuracy: 0.9481 - val_loss: 0.7489 - val_accuracy: 0.8688\n",
      "Epoch 924/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1199 - accuracy: 0.9438 - val_loss: 0.7536 - val_accuracy: 0.8601\n",
      "Epoch 925/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1214 - accuracy: 0.9445 - val_loss: 0.7405 - val_accuracy: 0.8659\n",
      "Epoch 926/2500\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 0.1264 - accuracy: 0.9438 - val_loss: 0.7327 - val_accuracy: 0.8601\n",
      "Epoch 927/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1146 - accuracy: 0.9481 - val_loss: 0.7235 - val_accuracy: 0.8659\n",
      "Epoch 928/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1184 - accuracy: 0.9467 - val_loss: 0.7249 - val_accuracy: 0.8659\n",
      "Epoch 929/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1167 - accuracy: 0.9474 - val_loss: 0.7415 - val_accuracy: 0.8746\n",
      "Epoch 930/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1152 - accuracy: 0.9540 - val_loss: 0.7140 - val_accuracy: 0.8688\n",
      "Epoch 931/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1175 - accuracy: 0.9459 - val_loss: 0.7649 - val_accuracy: 0.8688\n",
      "Epoch 932/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1079 - accuracy: 0.9511 - val_loss: 0.7459 - val_accuracy: 0.8513\n",
      "Epoch 933/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1359 - accuracy: 0.9474 - val_loss: 0.7192 - val_accuracy: 0.8746\n",
      "Epoch 934/2500\n",
      "18/18 [==============================] - 0s 28ms/step - loss: 0.1380 - accuracy: 0.9335 - val_loss: 0.7458 - val_accuracy: 0.8688\n",
      "Epoch 935/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1337 - accuracy: 0.9379 - val_loss: 0.7512 - val_accuracy: 0.8542\n",
      "Epoch 936/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1200 - accuracy: 0.9438 - val_loss: 0.7471 - val_accuracy: 0.8542\n",
      "Epoch 937/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1219 - accuracy: 0.9503 - val_loss: 0.7647 - val_accuracy: 0.8630\n",
      "Epoch 938/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1274 - accuracy: 0.9430 - val_loss: 0.7704 - val_accuracy: 0.8601\n",
      "Epoch 939/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.1179 - accuracy: 0.9452 - val_loss: 0.7681 - val_accuracy: 0.8688\n",
      "Epoch 940/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1146 - accuracy: 0.9452 - val_loss: 0.7138 - val_accuracy: 0.8688\n",
      "Epoch 941/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1336 - accuracy: 0.9364 - val_loss: 0.7353 - val_accuracy: 0.8542\n",
      "Epoch 942/2500\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.1240 - accuracy: 0.9511 - val_loss: 0.7203 - val_accuracy: 0.8630\n",
      "Epoch 943/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1315 - accuracy: 0.9452 - val_loss: 0.7375 - val_accuracy: 0.8601\n",
      "Epoch 944/2500\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.1288 - accuracy: 0.9467 - val_loss: 0.7107 - val_accuracy: 0.8746\n",
      "Epoch 945/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1329 - accuracy: 0.9416 - val_loss: 0.7325 - val_accuracy: 0.8542\n",
      "Epoch 946/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1172 - accuracy: 0.9533 - val_loss: 0.7239 - val_accuracy: 0.8746\n",
      "Epoch 947/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1202 - accuracy: 0.9474 - val_loss: 0.7417 - val_accuracy: 0.8630\n",
      "Epoch 948/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1246 - accuracy: 0.9496 - val_loss: 0.7631 - val_accuracy: 0.8484\n",
      "Epoch 949/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1097 - accuracy: 0.9533 - val_loss: 0.7439 - val_accuracy: 0.8571\n",
      "Epoch 950/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1168 - accuracy: 0.9489 - val_loss: 0.7236 - val_accuracy: 0.8805\n",
      "Epoch 951/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1195 - accuracy: 0.9423 - val_loss: 0.7275 - val_accuracy: 0.8746\n",
      "Epoch 952/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1182 - accuracy: 0.9452 - val_loss: 0.7029 - val_accuracy: 0.8659\n",
      "Epoch 953/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1318 - accuracy: 0.9364 - val_loss: 0.7119 - val_accuracy: 0.8601\n",
      "Epoch 954/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1182 - accuracy: 0.9467 - val_loss: 0.7253 - val_accuracy: 0.8688\n",
      "Epoch 955/2500\n",
      "18/18 [==============================] - 0s 28ms/step - loss: 0.1146 - accuracy: 0.9474 - val_loss: 0.7499 - val_accuracy: 0.8717\n",
      "Epoch 956/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1261 - accuracy: 0.9481 - val_loss: 0.7569 - val_accuracy: 0.8601\n",
      "Epoch 957/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1086 - accuracy: 0.9511 - val_loss: 0.7570 - val_accuracy: 0.8571\n",
      "Epoch 958/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1146 - accuracy: 0.9474 - val_loss: 0.7492 - val_accuracy: 0.8571\n",
      "Epoch 959/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1105 - accuracy: 0.9481 - val_loss: 0.7600 - val_accuracy: 0.8630\n",
      "Epoch 960/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1239 - accuracy: 0.9474 - val_loss: 0.7559 - val_accuracy: 0.8513\n",
      "Epoch 961/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1124 - accuracy: 0.9518 - val_loss: 0.7877 - val_accuracy: 0.8688\n",
      "Epoch 962/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1157 - accuracy: 0.9445 - val_loss: 0.7819 - val_accuracy: 0.8542\n",
      "Epoch 963/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1138 - accuracy: 0.9503 - val_loss: 0.7652 - val_accuracy: 0.8601\n",
      "Epoch 964/2500\n",
      "18/18 [==============================] - 0s 28ms/step - loss: 0.1130 - accuracy: 0.9503 - val_loss: 0.7754 - val_accuracy: 0.8455\n",
      "Epoch 965/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1304 - accuracy: 0.9416 - val_loss: 0.7757 - val_accuracy: 0.8571\n",
      "Epoch 966/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1230 - accuracy: 0.9496 - val_loss: 0.7662 - val_accuracy: 0.8542\n",
      "Epoch 967/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1154 - accuracy: 0.9452 - val_loss: 0.7585 - val_accuracy: 0.8659\n",
      "Epoch 968/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1112 - accuracy: 0.9554 - val_loss: 0.7543 - val_accuracy: 0.8717\n",
      "Epoch 969/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1176 - accuracy: 0.9452 - val_loss: 0.7511 - val_accuracy: 0.8542\n",
      "Epoch 970/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1071 - accuracy: 0.9503 - val_loss: 0.7705 - val_accuracy: 0.8542\n",
      "Epoch 971/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1403 - accuracy: 0.9423 - val_loss: 0.7697 - val_accuracy: 0.8513\n",
      "Epoch 972/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1297 - accuracy: 0.9423 - val_loss: 0.7597 - val_accuracy: 0.8630\n",
      "Epoch 973/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1335 - accuracy: 0.9445 - val_loss: 0.7626 - val_accuracy: 0.8571\n",
      "Epoch 974/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1326 - accuracy: 0.9430 - val_loss: 0.7311 - val_accuracy: 0.8571\n",
      "Epoch 975/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1253 - accuracy: 0.9452 - val_loss: 0.6966 - val_accuracy: 0.8601\n",
      "Epoch 976/2500\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.1454 - accuracy: 0.9408 - val_loss: 0.7093 - val_accuracy: 0.8571\n",
      "Epoch 977/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1212 - accuracy: 0.9518 - val_loss: 0.6944 - val_accuracy: 0.8601\n",
      "Epoch 978/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.1233 - accuracy: 0.9467 - val_loss: 0.7291 - val_accuracy: 0.8571\n",
      "Epoch 979/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1254 - accuracy: 0.9416 - val_loss: 0.7201 - val_accuracy: 0.8688\n",
      "Epoch 980/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.1289 - accuracy: 0.9438 - val_loss: 0.7429 - val_accuracy: 0.8659\n",
      "Epoch 981/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1359 - accuracy: 0.9474 - val_loss: 0.7752 - val_accuracy: 0.8542\n",
      "Epoch 982/2500\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 0.1411 - accuracy: 0.9438 - val_loss: 0.7459 - val_accuracy: 0.8571\n",
      "Epoch 983/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1141 - accuracy: 0.9474 - val_loss: 0.7535 - val_accuracy: 0.8542\n",
      "Epoch 984/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1155 - accuracy: 0.9503 - val_loss: 0.7390 - val_accuracy: 0.8542\n",
      "Epoch 985/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1280 - accuracy: 0.9423 - val_loss: 0.7417 - val_accuracy: 0.8571\n",
      "Epoch 986/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1232 - accuracy: 0.9481 - val_loss: 0.7300 - val_accuracy: 0.8484\n",
      "Epoch 987/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1194 - accuracy: 0.9496 - val_loss: 0.7409 - val_accuracy: 0.8601\n",
      "Epoch 988/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1218 - accuracy: 0.9489 - val_loss: 0.7143 - val_accuracy: 0.8571\n",
      "Epoch 989/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1430 - accuracy: 0.9357 - val_loss: 0.7046 - val_accuracy: 0.8484\n",
      "Epoch 990/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1304 - accuracy: 0.9430 - val_loss: 0.6885 - val_accuracy: 0.8776\n",
      "Epoch 991/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1307 - accuracy: 0.9386 - val_loss: 0.7356 - val_accuracy: 0.8513\n",
      "Epoch 992/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1185 - accuracy: 0.9459 - val_loss: 0.7660 - val_accuracy: 0.8659\n",
      "Epoch 993/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1112 - accuracy: 0.9547 - val_loss: 0.7549 - val_accuracy: 0.8601\n",
      "Epoch 994/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1176 - accuracy: 0.9467 - val_loss: 0.7415 - val_accuracy: 0.8717\n",
      "Epoch 995/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1139 - accuracy: 0.9496 - val_loss: 0.7420 - val_accuracy: 0.8659\n",
      "Epoch 996/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1158 - accuracy: 0.9518 - val_loss: 0.7603 - val_accuracy: 0.8659\n",
      "Epoch 997/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1097 - accuracy: 0.9503 - val_loss: 0.7646 - val_accuracy: 0.8659\n",
      "Epoch 998/2500\n",
      "18/18 [==============================] - 1s 27ms/step - loss: 0.1090 - accuracy: 0.9511 - val_loss: 0.7879 - val_accuracy: 0.8630\n",
      "Epoch 999/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1124 - accuracy: 0.9459 - val_loss: 0.7646 - val_accuracy: 0.8688\n",
      "Epoch 1000/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1148 - accuracy: 0.9503 - val_loss: 0.7615 - val_accuracy: 0.8571\n",
      "Epoch 1001/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1211 - accuracy: 0.9489 - val_loss: 0.7671 - val_accuracy: 0.8746\n",
      "Epoch 1002/2500\n",
      "18/18 [==============================] - 0s 28ms/step - loss: 0.1135 - accuracy: 0.9503 - val_loss: 0.7659 - val_accuracy: 0.8659\n",
      "Epoch 1003/2500\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.1150 - accuracy: 0.9496 - val_loss: 0.7894 - val_accuracy: 0.8601\n",
      "Epoch 1004/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.1122 - accuracy: 0.9533 - val_loss: 0.7717 - val_accuracy: 0.8601\n",
      "Epoch 1005/2500\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.1104 - accuracy: 0.9511 - val_loss: 0.7758 - val_accuracy: 0.8513\n",
      "Epoch 1006/2500\n",
      "18/18 [==============================] - 1s 28ms/step - loss: 0.1271 - accuracy: 0.9533 - val_loss: 0.7656 - val_accuracy: 0.8630\n",
      "Epoch 1007/2500\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.1131 - accuracy: 0.9496 - val_loss: 0.7759 - val_accuracy: 0.8601\n",
      "Epoch 1008/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1321 - accuracy: 0.9430 - val_loss: 0.7956 - val_accuracy: 0.8688\n",
      "Epoch 1009/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1242 - accuracy: 0.9438 - val_loss: 0.8064 - val_accuracy: 0.8601\n",
      "Epoch 1010/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1313 - accuracy: 0.9438 - val_loss: 0.7793 - val_accuracy: 0.8630\n",
      "Epoch 1011/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1178 - accuracy: 0.9452 - val_loss: 0.7710 - val_accuracy: 0.8571\n",
      "Epoch 1012/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1283 - accuracy: 0.9489 - val_loss: 0.7459 - val_accuracy: 0.8542\n",
      "Epoch 1013/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1497 - accuracy: 0.9401 - val_loss: 0.7371 - val_accuracy: 0.8571\n",
      "Epoch 1014/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1294 - accuracy: 0.9386 - val_loss: 0.7421 - val_accuracy: 0.8484\n",
      "Epoch 1015/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1203 - accuracy: 0.9496 - val_loss: 0.7338 - val_accuracy: 0.8630\n",
      "Epoch 1016/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1153 - accuracy: 0.9496 - val_loss: 0.7952 - val_accuracy: 0.8426\n",
      "Epoch 1017/2500\n",
      "18/18 [==============================] - 1s 28ms/step - loss: 0.1203 - accuracy: 0.9474 - val_loss: 0.7415 - val_accuracy: 0.8659\n",
      "Epoch 1018/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1273 - accuracy: 0.9459 - val_loss: 0.7465 - val_accuracy: 0.8455\n",
      "Epoch 1019/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.1229 - accuracy: 0.9489 - val_loss: 0.7407 - val_accuracy: 0.8513\n",
      "Epoch 1020/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1248 - accuracy: 0.9496 - val_loss: 0.7482 - val_accuracy: 0.8601\n",
      "Epoch 1021/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1348 - accuracy: 0.9474 - val_loss: 0.7584 - val_accuracy: 0.8688\n",
      "Epoch 1022/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1295 - accuracy: 0.9416 - val_loss: 0.7707 - val_accuracy: 0.8571\n",
      "Epoch 1023/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1096 - accuracy: 0.9481 - val_loss: 0.7836 - val_accuracy: 0.8630\n",
      "Epoch 1024/2500\n",
      "18/18 [==============================] - 1s 28ms/step - loss: 0.1242 - accuracy: 0.9489 - val_loss: 0.7516 - val_accuracy: 0.8484\n",
      "Epoch 1025/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1134 - accuracy: 0.9518 - val_loss: 0.7843 - val_accuracy: 0.8659\n",
      "Epoch 1026/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.1314 - accuracy: 0.9401 - val_loss: 0.7820 - val_accuracy: 0.8659\n",
      "Epoch 1027/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1219 - accuracy: 0.9423 - val_loss: 0.7645 - val_accuracy: 0.8571\n",
      "Epoch 1028/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1176 - accuracy: 0.9518 - val_loss: 0.7691 - val_accuracy: 0.8484\n",
      "Epoch 1029/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1210 - accuracy: 0.9518 - val_loss: 0.7580 - val_accuracy: 0.8746\n",
      "Epoch 1030/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1331 - accuracy: 0.9401 - val_loss: 0.7618 - val_accuracy: 0.8659\n",
      "Epoch 1031/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1225 - accuracy: 0.9481 - val_loss: 0.7503 - val_accuracy: 0.8630\n",
      "Epoch 1032/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1183 - accuracy: 0.9430 - val_loss: 0.7673 - val_accuracy: 0.8630\n",
      "Epoch 1033/2500\n",
      "18/18 [==============================] - 1s 28ms/step - loss: 0.1205 - accuracy: 0.9467 - val_loss: 0.7971 - val_accuracy: 0.8571\n",
      "Epoch 1034/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1243 - accuracy: 0.9481 - val_loss: 0.7843 - val_accuracy: 0.8659\n",
      "Epoch 1035/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1213 - accuracy: 0.9525 - val_loss: 0.7960 - val_accuracy: 0.8571\n",
      "Epoch 1036/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1306 - accuracy: 0.9430 - val_loss: 0.8150 - val_accuracy: 0.8513\n",
      "Epoch 1037/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1227 - accuracy: 0.9518 - val_loss: 0.8027 - val_accuracy: 0.8659\n",
      "Epoch 1038/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1197 - accuracy: 0.9452 - val_loss: 0.8131 - val_accuracy: 0.8513\n",
      "Epoch 1039/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1086 - accuracy: 0.9511 - val_loss: 0.8242 - val_accuracy: 0.8484\n",
      "Epoch 1040/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1251 - accuracy: 0.9511 - val_loss: 0.7850 - val_accuracy: 0.8542\n",
      "Epoch 1041/2500\n",
      "18/18 [==============================] - 1s 28ms/step - loss: 0.1282 - accuracy: 0.9496 - val_loss: 0.7644 - val_accuracy: 0.8630\n",
      "Epoch 1042/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1235 - accuracy: 0.9438 - val_loss: 0.7666 - val_accuracy: 0.8717\n",
      "Epoch 1043/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1193 - accuracy: 0.9496 - val_loss: 0.7832 - val_accuracy: 0.8659\n",
      "Epoch 1044/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1147 - accuracy: 0.9467 - val_loss: 0.7833 - val_accuracy: 0.8542\n",
      "Epoch 1045/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1393 - accuracy: 0.9474 - val_loss: 0.7698 - val_accuracy: 0.8513\n",
      "Epoch 1046/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1100 - accuracy: 0.9503 - val_loss: 0.7743 - val_accuracy: 0.8513\n",
      "Epoch 1047/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1168 - accuracy: 0.9474 - val_loss: 0.7955 - val_accuracy: 0.8571\n",
      "Epoch 1048/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1247 - accuracy: 0.9445 - val_loss: 0.7656 - val_accuracy: 0.8659\n",
      "Epoch 1049/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1273 - accuracy: 0.9423 - val_loss: 0.7758 - val_accuracy: 0.8601\n",
      "Epoch 1050/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1077 - accuracy: 0.9511 - val_loss: 0.8084 - val_accuracy: 0.8659\n",
      "Epoch 1051/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.1254 - accuracy: 0.9416 - val_loss: 0.7825 - val_accuracy: 0.8542\n",
      "Epoch 1052/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1245 - accuracy: 0.9394 - val_loss: 0.7930 - val_accuracy: 0.8630\n",
      "Epoch 1053/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1128 - accuracy: 0.9511 - val_loss: 0.7652 - val_accuracy: 0.8776\n",
      "Epoch 1054/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1153 - accuracy: 0.9474 - val_loss: 0.7706 - val_accuracy: 0.8484\n",
      "Epoch 1055/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1078 - accuracy: 0.9525 - val_loss: 0.7950 - val_accuracy: 0.8630\n",
      "Epoch 1056/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1281 - accuracy: 0.9474 - val_loss: 0.8402 - val_accuracy: 0.8688\n",
      "Epoch 1057/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1189 - accuracy: 0.9452 - val_loss: 0.8036 - val_accuracy: 0.8659\n",
      "Epoch 1058/2500\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.1064 - accuracy: 0.9459 - val_loss: 0.7782 - val_accuracy: 0.8571\n",
      "Epoch 1059/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1255 - accuracy: 0.9379 - val_loss: 0.7696 - val_accuracy: 0.8630\n",
      "Epoch 1060/2500\n",
      "18/18 [==============================] - 1s 27ms/step - loss: 0.1099 - accuracy: 0.9511 - val_loss: 0.7627 - val_accuracy: 0.8717\n",
      "Epoch 1061/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0997 - accuracy: 0.9547 - val_loss: 0.7767 - val_accuracy: 0.8630\n",
      "Epoch 1062/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.1079 - accuracy: 0.9518 - val_loss: 0.7887 - val_accuracy: 0.8601\n",
      "Epoch 1063/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1025 - accuracy: 0.9503 - val_loss: 0.7977 - val_accuracy: 0.8630\n",
      "Epoch 1064/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1219 - accuracy: 0.9474 - val_loss: 0.7688 - val_accuracy: 0.8659\n",
      "Epoch 1065/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1170 - accuracy: 0.9503 - val_loss: 0.7703 - val_accuracy: 0.8659\n",
      "Epoch 1066/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.1195 - accuracy: 0.9459 - val_loss: 0.7555 - val_accuracy: 0.8455\n",
      "Epoch 1067/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1118 - accuracy: 0.9547 - val_loss: 0.7467 - val_accuracy: 0.8542\n",
      "Epoch 1068/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1226 - accuracy: 0.9474 - val_loss: 0.7460 - val_accuracy: 0.8805\n",
      "Epoch 1069/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1266 - accuracy: 0.9459 - val_loss: 0.7246 - val_accuracy: 0.8717\n",
      "Epoch 1070/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1172 - accuracy: 0.9445 - val_loss: 0.7185 - val_accuracy: 0.8834\n",
      "Epoch 1071/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1169 - accuracy: 0.9511 - val_loss: 0.7462 - val_accuracy: 0.8542\n",
      "Epoch 1072/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1295 - accuracy: 0.9481 - val_loss: 0.7654 - val_accuracy: 0.8455\n",
      "Epoch 1073/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1269 - accuracy: 0.9423 - val_loss: 0.7233 - val_accuracy: 0.8776\n",
      "Epoch 1074/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1267 - accuracy: 0.9438 - val_loss: 0.7533 - val_accuracy: 0.8542\n",
      "Epoch 1075/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1130 - accuracy: 0.9496 - val_loss: 0.7683 - val_accuracy: 0.8571\n",
      "Epoch 1076/2500\n",
      "18/18 [==============================] - 0s 28ms/step - loss: 0.1252 - accuracy: 0.9438 - val_loss: 0.7301 - val_accuracy: 0.8659\n",
      "Epoch 1077/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1109 - accuracy: 0.9554 - val_loss: 0.7469 - val_accuracy: 0.8630\n",
      "Epoch 1078/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1127 - accuracy: 0.9503 - val_loss: 0.7510 - val_accuracy: 0.8688\n",
      "Epoch 1079/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1215 - accuracy: 0.9438 - val_loss: 0.7798 - val_accuracy: 0.8630\n",
      "Epoch 1080/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1171 - accuracy: 0.9467 - val_loss: 0.7513 - val_accuracy: 0.8601\n",
      "Epoch 1081/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1327 - accuracy: 0.9386 - val_loss: 0.7587 - val_accuracy: 0.8688\n",
      "Epoch 1082/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1105 - accuracy: 0.9540 - val_loss: 0.7626 - val_accuracy: 0.8688\n",
      "Epoch 1083/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.1215 - accuracy: 0.9459 - val_loss: 0.7373 - val_accuracy: 0.8630\n",
      "Epoch 1084/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1163 - accuracy: 0.9467 - val_loss: 0.7562 - val_accuracy: 0.8688\n",
      "Epoch 1085/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.1254 - accuracy: 0.9503 - val_loss: 0.7562 - val_accuracy: 0.8746\n",
      "Epoch 1086/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1160 - accuracy: 0.9496 - val_loss: 0.7660 - val_accuracy: 0.8659\n",
      "Epoch 1087/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1341 - accuracy: 0.9452 - val_loss: 0.7993 - val_accuracy: 0.8542\n",
      "Epoch 1088/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1096 - accuracy: 0.9467 - val_loss: 0.7938 - val_accuracy: 0.8630\n",
      "Epoch 1089/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1157 - accuracy: 0.9452 - val_loss: 0.7906 - val_accuracy: 0.8630\n",
      "Epoch 1090/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1120 - accuracy: 0.9518 - val_loss: 0.8213 - val_accuracy: 0.8659\n",
      "Epoch 1091/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.1041 - accuracy: 0.9569 - val_loss: 0.8078 - val_accuracy: 0.8542\n",
      "Epoch 1092/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1114 - accuracy: 0.9511 - val_loss: 0.8349 - val_accuracy: 0.8426\n",
      "Epoch 1093/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1340 - accuracy: 0.9445 - val_loss: 0.7931 - val_accuracy: 0.8601\n",
      "Epoch 1094/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1229 - accuracy: 0.9452 - val_loss: 0.8026 - val_accuracy: 0.8571\n",
      "Epoch 1095/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1240 - accuracy: 0.9459 - val_loss: 0.7951 - val_accuracy: 0.8513\n",
      "Epoch 1096/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1190 - accuracy: 0.9452 - val_loss: 0.7693 - val_accuracy: 0.8484\n",
      "Epoch 1097/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1189 - accuracy: 0.9445 - val_loss: 0.7752 - val_accuracy: 0.8571\n",
      "Epoch 1098/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1168 - accuracy: 0.9467 - val_loss: 0.7620 - val_accuracy: 0.8659\n",
      "Epoch 1099/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1128 - accuracy: 0.9518 - val_loss: 0.7598 - val_accuracy: 0.8542\n",
      "Epoch 1100/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1188 - accuracy: 0.9525 - val_loss: 0.7663 - val_accuracy: 0.8542\n",
      "Epoch 1101/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.1134 - accuracy: 0.9525 - val_loss: 0.7484 - val_accuracy: 0.8484\n",
      "Epoch 1102/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1185 - accuracy: 0.9481 - val_loss: 0.7678 - val_accuracy: 0.8571\n",
      "Epoch 1103/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1147 - accuracy: 0.9496 - val_loss: 0.7906 - val_accuracy: 0.8513\n",
      "Epoch 1104/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1048 - accuracy: 0.9562 - val_loss: 0.7955 - val_accuracy: 0.8659\n",
      "Epoch 1105/2500\n",
      "18/18 [==============================] - 1s 33ms/step - loss: 0.1077 - accuracy: 0.9489 - val_loss: 0.8196 - val_accuracy: 0.8630\n",
      "Epoch 1106/2500\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.1209 - accuracy: 0.9481 - val_loss: 0.8151 - val_accuracy: 0.8659\n",
      "Epoch 1107/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1129 - accuracy: 0.9467 - val_loss: 0.7973 - val_accuracy: 0.8571\n",
      "Epoch 1108/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1182 - accuracy: 0.9459 - val_loss: 0.7811 - val_accuracy: 0.8659\n",
      "Epoch 1109/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1103 - accuracy: 0.9503 - val_loss: 0.7597 - val_accuracy: 0.8688\n",
      "Epoch 1110/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1265 - accuracy: 0.9445 - val_loss: 0.7338 - val_accuracy: 0.8688\n",
      "Epoch 1111/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1196 - accuracy: 0.9459 - val_loss: 0.7590 - val_accuracy: 0.8688\n",
      "Epoch 1112/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1190 - accuracy: 0.9489 - val_loss: 0.7693 - val_accuracy: 0.8571\n",
      "Epoch 1113/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1120 - accuracy: 0.9503 - val_loss: 0.7754 - val_accuracy: 0.8601\n",
      "Epoch 1114/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1180 - accuracy: 0.9503 - val_loss: 0.7735 - val_accuracy: 0.8630\n",
      "Epoch 1115/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1159 - accuracy: 0.9489 - val_loss: 0.7725 - val_accuracy: 0.8659\n",
      "Epoch 1116/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1523 - accuracy: 0.9408 - val_loss: 0.8083 - val_accuracy: 0.8571\n",
      "Epoch 1117/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1261 - accuracy: 0.9423 - val_loss: 0.7722 - val_accuracy: 0.8571\n",
      "Epoch 1118/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1335 - accuracy: 0.9496 - val_loss: 0.7817 - val_accuracy: 0.8601\n",
      "Epoch 1119/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1063 - accuracy: 0.9525 - val_loss: 0.7876 - val_accuracy: 0.8571\n",
      "Epoch 1120/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1109 - accuracy: 0.9489 - val_loss: 0.7910 - val_accuracy: 0.8630\n",
      "Epoch 1121/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.1004 - accuracy: 0.9540 - val_loss: 0.8023 - val_accuracy: 0.8630\n",
      "Epoch 1122/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1084 - accuracy: 0.9481 - val_loss: 0.8102 - val_accuracy: 0.8659\n",
      "Epoch 1123/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1005 - accuracy: 0.9525 - val_loss: 0.7988 - val_accuracy: 0.8630\n",
      "Epoch 1124/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1188 - accuracy: 0.9511 - val_loss: 0.7603 - val_accuracy: 0.8571\n",
      "Epoch 1125/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1149 - accuracy: 0.9474 - val_loss: 0.7902 - val_accuracy: 0.8688\n",
      "Epoch 1126/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1126 - accuracy: 0.9459 - val_loss: 0.7970 - val_accuracy: 0.8630\n",
      "Epoch 1127/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.1084 - accuracy: 0.9554 - val_loss: 0.7952 - val_accuracy: 0.8484\n",
      "Epoch 1128/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1147 - accuracy: 0.9430 - val_loss: 0.8064 - val_accuracy: 0.8717\n",
      "Epoch 1129/2500\n",
      "18/18 [==============================] - 1s 27ms/step - loss: 0.1162 - accuracy: 0.9496 - val_loss: 0.7837 - val_accuracy: 0.8601\n",
      "Epoch 1130/2500\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.1087 - accuracy: 0.9503 - val_loss: 0.7958 - val_accuracy: 0.8688\n",
      "Epoch 1131/2500\n",
      "18/18 [==============================] - 1s 28ms/step - loss: 0.1079 - accuracy: 0.9518 - val_loss: 0.7809 - val_accuracy: 0.8542\n",
      "Epoch 1132/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1141 - accuracy: 0.9489 - val_loss: 0.7931 - val_accuracy: 0.8513\n",
      "Epoch 1133/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1145 - accuracy: 0.9467 - val_loss: 0.7913 - val_accuracy: 0.8484\n",
      "Epoch 1134/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1040 - accuracy: 0.9576 - val_loss: 0.7891 - val_accuracy: 0.8659\n",
      "Epoch 1135/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.1207 - accuracy: 0.9481 - val_loss: 0.8228 - val_accuracy: 0.8746\n",
      "Epoch 1136/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1276 - accuracy: 0.9481 - val_loss: 0.8256 - val_accuracy: 0.8542\n",
      "Epoch 1137/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1242 - accuracy: 0.9459 - val_loss: 0.7961 - val_accuracy: 0.8542\n",
      "Epoch 1138/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1231 - accuracy: 0.9489 - val_loss: 0.8353 - val_accuracy: 0.8659\n",
      "Epoch 1139/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1091 - accuracy: 0.9496 - val_loss: 0.8042 - val_accuracy: 0.8746\n",
      "Epoch 1140/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1114 - accuracy: 0.9489 - val_loss: 0.7994 - val_accuracy: 0.8688\n",
      "Epoch 1141/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1120 - accuracy: 0.9518 - val_loss: 0.8027 - val_accuracy: 0.8601\n",
      "Epoch 1142/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.1255 - accuracy: 0.9496 - val_loss: 0.7579 - val_accuracy: 0.8688\n",
      "Epoch 1143/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1222 - accuracy: 0.9503 - val_loss: 0.7903 - val_accuracy: 0.8630\n",
      "Epoch 1144/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1176 - accuracy: 0.9452 - val_loss: 0.7838 - val_accuracy: 0.8717\n",
      "Epoch 1145/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1159 - accuracy: 0.9474 - val_loss: 0.7954 - val_accuracy: 0.8513\n",
      "Epoch 1146/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1161 - accuracy: 0.9438 - val_loss: 0.8052 - val_accuracy: 0.8571\n",
      "Epoch 1147/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0974 - accuracy: 0.9511 - val_loss: 0.8196 - val_accuracy: 0.8542\n",
      "Epoch 1148/2500\n",
      "18/18 [==============================] - 1s 28ms/step - loss: 0.1134 - accuracy: 0.9481 - val_loss: 0.8078 - val_accuracy: 0.8484\n",
      "Epoch 1149/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1250 - accuracy: 0.9452 - val_loss: 0.8063 - val_accuracy: 0.8688\n",
      "Epoch 1150/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1234 - accuracy: 0.9467 - val_loss: 0.7514 - val_accuracy: 0.8571\n",
      "Epoch 1151/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1109 - accuracy: 0.9518 - val_loss: 0.7719 - val_accuracy: 0.8688\n",
      "Epoch 1152/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1193 - accuracy: 0.9511 - val_loss: 0.7771 - val_accuracy: 0.8455\n",
      "Epoch 1153/2500\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.1226 - accuracy: 0.9503 - val_loss: 0.7929 - val_accuracy: 0.8513\n",
      "Epoch 1154/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1206 - accuracy: 0.9489 - val_loss: 0.7586 - val_accuracy: 0.8601\n",
      "Epoch 1155/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1240 - accuracy: 0.9445 - val_loss: 0.7862 - val_accuracy: 0.8542\n",
      "Epoch 1156/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1089 - accuracy: 0.9569 - val_loss: 0.7685 - val_accuracy: 0.8746\n",
      "Epoch 1157/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1093 - accuracy: 0.9525 - val_loss: 0.7628 - val_accuracy: 0.8659\n",
      "Epoch 1158/2500\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.1183 - accuracy: 0.9489 - val_loss: 0.7434 - val_accuracy: 0.8776\n",
      "Epoch 1159/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1100 - accuracy: 0.9533 - val_loss: 0.7589 - val_accuracy: 0.8746\n",
      "Epoch 1160/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1200 - accuracy: 0.9438 - val_loss: 0.7579 - val_accuracy: 0.8717\n",
      "Epoch 1161/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1120 - accuracy: 0.9467 - val_loss: 0.7513 - val_accuracy: 0.8717\n",
      "Epoch 1162/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1117 - accuracy: 0.9489 - val_loss: 0.7626 - val_accuracy: 0.8746\n",
      "Epoch 1163/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1123 - accuracy: 0.9496 - val_loss: 0.7971 - val_accuracy: 0.8630\n",
      "Epoch 1164/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1181 - accuracy: 0.9452 - val_loss: 0.8007 - val_accuracy: 0.8630\n",
      "Epoch 1165/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1014 - accuracy: 0.9547 - val_loss: 0.7824 - val_accuracy: 0.8688\n",
      "Epoch 1166/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1112 - accuracy: 0.9503 - val_loss: 0.7807 - val_accuracy: 0.8776\n",
      "Epoch 1167/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1144 - accuracy: 0.9518 - val_loss: 0.7725 - val_accuracy: 0.8805\n",
      "Epoch 1168/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1011 - accuracy: 0.9518 - val_loss: 0.8137 - val_accuracy: 0.8688\n",
      "Epoch 1169/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.1275 - accuracy: 0.9467 - val_loss: 0.7727 - val_accuracy: 0.8601\n",
      "Epoch 1170/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1290 - accuracy: 0.9445 - val_loss: 0.8100 - val_accuracy: 0.8601\n",
      "Epoch 1171/2500\n",
      "18/18 [==============================] - 1s 28ms/step - loss: 0.1185 - accuracy: 0.9416 - val_loss: 0.7590 - val_accuracy: 0.8659\n",
      "Epoch 1172/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1139 - accuracy: 0.9503 - val_loss: 0.8016 - val_accuracy: 0.8746\n",
      "Epoch 1173/2500\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.1049 - accuracy: 0.9474 - val_loss: 0.7985 - val_accuracy: 0.8688\n",
      "Epoch 1174/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1061 - accuracy: 0.9489 - val_loss: 0.8161 - val_accuracy: 0.8601\n",
      "Epoch 1175/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1034 - accuracy: 0.9525 - val_loss: 0.8097 - val_accuracy: 0.8659\n",
      "Epoch 1176/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0995 - accuracy: 0.9569 - val_loss: 0.8190 - val_accuracy: 0.8746\n",
      "Epoch 1177/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.1303 - accuracy: 0.9423 - val_loss: 0.8172 - val_accuracy: 0.8659\n",
      "Epoch 1178/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1333 - accuracy: 0.9467 - val_loss: 0.7962 - val_accuracy: 0.8542\n",
      "Epoch 1179/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1272 - accuracy: 0.9408 - val_loss: 0.7801 - val_accuracy: 0.8776\n",
      "Epoch 1180/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1218 - accuracy: 0.9503 - val_loss: 0.7926 - val_accuracy: 0.8601\n",
      "Epoch 1181/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1111 - accuracy: 0.9474 - val_loss: 0.7895 - val_accuracy: 0.8484\n",
      "Epoch 1182/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1100 - accuracy: 0.9474 - val_loss: 0.7761 - val_accuracy: 0.8601\n",
      "Epoch 1183/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1216 - accuracy: 0.9474 - val_loss: 0.8130 - val_accuracy: 0.8426\n",
      "Epoch 1184/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1309 - accuracy: 0.9496 - val_loss: 0.8067 - val_accuracy: 0.8455\n",
      "Epoch 1185/2500\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.1278 - accuracy: 0.9459 - val_loss: 0.7753 - val_accuracy: 0.8630\n",
      "Epoch 1186/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1221 - accuracy: 0.9423 - val_loss: 0.7838 - val_accuracy: 0.8484\n",
      "Epoch 1187/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1140 - accuracy: 0.9540 - val_loss: 0.8081 - val_accuracy: 0.8688\n",
      "Epoch 1188/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1184 - accuracy: 0.9489 - val_loss: 0.8036 - val_accuracy: 0.8630\n",
      "Epoch 1189/2500\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.1068 - accuracy: 0.9562 - val_loss: 0.8033 - val_accuracy: 0.8659\n",
      "Epoch 1190/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1085 - accuracy: 0.9481 - val_loss: 0.7935 - val_accuracy: 0.8659\n",
      "Epoch 1191/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1112 - accuracy: 0.9533 - val_loss: 0.8148 - val_accuracy: 0.8630\n",
      "Epoch 1192/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1079 - accuracy: 0.9525 - val_loss: 0.8106 - val_accuracy: 0.8659\n",
      "Epoch 1193/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1027 - accuracy: 0.9533 - val_loss: 0.8178 - val_accuracy: 0.8688\n",
      "Epoch 1194/2500\n",
      "18/18 [==============================] - 1s 28ms/step - loss: 0.1110 - accuracy: 0.9540 - val_loss: 0.8102 - val_accuracy: 0.8717\n",
      "Epoch 1195/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1081 - accuracy: 0.9518 - val_loss: 0.8039 - val_accuracy: 0.8571\n",
      "Epoch 1196/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1159 - accuracy: 0.9459 - val_loss: 0.7963 - val_accuracy: 0.8805\n",
      "Epoch 1197/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1082 - accuracy: 0.9474 - val_loss: 0.7832 - val_accuracy: 0.8746\n",
      "Epoch 1198/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1222 - accuracy: 0.9496 - val_loss: 0.8090 - val_accuracy: 0.8659\n",
      "Epoch 1199/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1361 - accuracy: 0.9445 - val_loss: 0.8500 - val_accuracy: 0.8630\n",
      "Epoch 1200/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1235 - accuracy: 0.9474 - val_loss: 0.8346 - val_accuracy: 0.8601\n",
      "Epoch 1201/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1202 - accuracy: 0.9489 - val_loss: 0.8329 - val_accuracy: 0.8542\n",
      "Epoch 1202/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1075 - accuracy: 0.9518 - val_loss: 0.8320 - val_accuracy: 0.8571\n",
      "Epoch 1203/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.1106 - accuracy: 0.9438 - val_loss: 0.8337 - val_accuracy: 0.8513\n",
      "Epoch 1204/2500\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.1135 - accuracy: 0.9423 - val_loss: 0.8188 - val_accuracy: 0.8397\n",
      "Epoch 1205/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1148 - accuracy: 0.9547 - val_loss: 0.8175 - val_accuracy: 0.8717\n",
      "Epoch 1206/2500\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.1109 - accuracy: 0.9496 - val_loss: 0.8457 - val_accuracy: 0.8542\n",
      "Epoch 1207/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1251 - accuracy: 0.9474 - val_loss: 0.8328 - val_accuracy: 0.8601\n",
      "Epoch 1208/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1212 - accuracy: 0.9467 - val_loss: 0.8471 - val_accuracy: 0.8484\n",
      "Epoch 1209/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.1134 - accuracy: 0.9525 - val_loss: 0.8400 - val_accuracy: 0.8659\n",
      "Epoch 1210/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1193 - accuracy: 0.9533 - val_loss: 0.8198 - val_accuracy: 0.8630\n",
      "Epoch 1211/2500\n",
      "18/18 [==============================] - 0s 28ms/step - loss: 0.1137 - accuracy: 0.9518 - val_loss: 0.8288 - val_accuracy: 0.8571\n",
      "Epoch 1212/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1090 - accuracy: 0.9540 - val_loss: 0.8133 - val_accuracy: 0.8688\n",
      "Epoch 1213/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1045 - accuracy: 0.9481 - val_loss: 0.8213 - val_accuracy: 0.8630\n",
      "Epoch 1214/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1065 - accuracy: 0.9511 - val_loss: 0.8184 - val_accuracy: 0.8688\n",
      "Epoch 1215/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.1092 - accuracy: 0.9474 - val_loss: 0.8065 - val_accuracy: 0.8717\n",
      "Epoch 1216/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1170 - accuracy: 0.9481 - val_loss: 0.8039 - val_accuracy: 0.8688\n",
      "Epoch 1217/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1169 - accuracy: 0.9496 - val_loss: 0.8028 - val_accuracy: 0.8746\n",
      "Epoch 1218/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1201 - accuracy: 0.9459 - val_loss: 0.8077 - val_accuracy: 0.8571\n",
      "Epoch 1219/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1265 - accuracy: 0.9459 - val_loss: 0.7994 - val_accuracy: 0.8513\n",
      "Epoch 1220/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1155 - accuracy: 0.9467 - val_loss: 0.7728 - val_accuracy: 0.8717\n",
      "Epoch 1221/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1115 - accuracy: 0.9518 - val_loss: 0.7868 - val_accuracy: 0.8688\n",
      "Epoch 1222/2500\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 0.1096 - accuracy: 0.9481 - val_loss: 0.7760 - val_accuracy: 0.8717\n",
      "Epoch 1223/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1118 - accuracy: 0.9452 - val_loss: 0.7838 - val_accuracy: 0.8717\n",
      "Epoch 1224/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.1112 - accuracy: 0.9438 - val_loss: 0.7969 - val_accuracy: 0.8630\n",
      "Epoch 1225/2500\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.1066 - accuracy: 0.9540 - val_loss: 0.8036 - val_accuracy: 0.8659\n",
      "Epoch 1226/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1091 - accuracy: 0.9474 - val_loss: 0.7678 - val_accuracy: 0.8688\n",
      "Epoch 1227/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1089 - accuracy: 0.9503 - val_loss: 0.7809 - val_accuracy: 0.8659\n",
      "Epoch 1228/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1054 - accuracy: 0.9547 - val_loss: 0.7901 - val_accuracy: 0.8542\n",
      "Epoch 1229/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1092 - accuracy: 0.9518 - val_loss: 0.8045 - val_accuracy: 0.8571\n",
      "Epoch 1230/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1116 - accuracy: 0.9503 - val_loss: 0.8199 - val_accuracy: 0.8659\n",
      "Epoch 1231/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1044 - accuracy: 0.9540 - val_loss: 0.8077 - val_accuracy: 0.8659\n",
      "Epoch 1232/2500\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.1051 - accuracy: 0.9540 - val_loss: 0.7835 - val_accuracy: 0.8688\n",
      "Epoch 1233/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.0983 - accuracy: 0.9496 - val_loss: 0.7725 - val_accuracy: 0.8630\n",
      "Epoch 1234/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1011 - accuracy: 0.9503 - val_loss: 0.7928 - val_accuracy: 0.8717\n",
      "Epoch 1235/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1000 - accuracy: 0.9511 - val_loss: 0.8163 - val_accuracy: 0.8571\n",
      "Epoch 1236/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1056 - accuracy: 0.9511 - val_loss: 0.8013 - val_accuracy: 0.8659\n",
      "Epoch 1237/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1061 - accuracy: 0.9474 - val_loss: 0.8093 - val_accuracy: 0.8659\n",
      "Epoch 1238/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1061 - accuracy: 0.9533 - val_loss: 0.8285 - val_accuracy: 0.8513\n",
      "Epoch 1239/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1102 - accuracy: 0.9525 - val_loss: 0.8079 - val_accuracy: 0.8542\n",
      "Epoch 1240/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1155 - accuracy: 0.9540 - val_loss: 0.7910 - val_accuracy: 0.8542\n",
      "Epoch 1241/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1094 - accuracy: 0.9518 - val_loss: 0.7926 - val_accuracy: 0.8601\n",
      "Epoch 1242/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1106 - accuracy: 0.9481 - val_loss: 0.7748 - val_accuracy: 0.8717\n",
      "Epoch 1243/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1155 - accuracy: 0.9547 - val_loss: 0.7543 - val_accuracy: 0.8688\n",
      "Epoch 1244/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.1077 - accuracy: 0.9525 - val_loss: 0.7715 - val_accuracy: 0.8659\n",
      "Epoch 1245/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1077 - accuracy: 0.9489 - val_loss: 0.7877 - val_accuracy: 0.8659\n",
      "Epoch 1246/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1072 - accuracy: 0.9452 - val_loss: 0.7983 - val_accuracy: 0.8571\n",
      "Epoch 1247/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.0994 - accuracy: 0.9562 - val_loss: 0.8033 - val_accuracy: 0.8630\n",
      "Epoch 1248/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1077 - accuracy: 0.9569 - val_loss: 0.7881 - val_accuracy: 0.8659\n",
      "Epoch 1249/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1057 - accuracy: 0.9503 - val_loss: 0.7667 - val_accuracy: 0.8717\n",
      "Epoch 1250/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1096 - accuracy: 0.9511 - val_loss: 0.7761 - val_accuracy: 0.8717\n",
      "Epoch 1251/2500\n",
      "18/18 [==============================] - 0s 28ms/step - loss: 0.1145 - accuracy: 0.9533 - val_loss: 0.8113 - val_accuracy: 0.8659\n",
      "Epoch 1252/2500\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.1110 - accuracy: 0.9518 - val_loss: 0.8205 - val_accuracy: 0.8630\n",
      "Epoch 1253/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.1121 - accuracy: 0.9533 - val_loss: 0.8134 - val_accuracy: 0.8659\n",
      "Epoch 1254/2500\n",
      "18/18 [==============================] - 1s 28ms/step - loss: 0.1308 - accuracy: 0.9452 - val_loss: 0.8043 - val_accuracy: 0.8688\n",
      "Epoch 1255/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1161 - accuracy: 0.9459 - val_loss: 0.7767 - val_accuracy: 0.8746\n",
      "Epoch 1256/2500\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.1124 - accuracy: 0.9474 - val_loss: 0.7918 - val_accuracy: 0.8688\n",
      "Epoch 1257/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1089 - accuracy: 0.9452 - val_loss: 0.8234 - val_accuracy: 0.8717\n",
      "Epoch 1258/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1104 - accuracy: 0.9533 - val_loss: 0.8080 - val_accuracy: 0.8659\n",
      "Epoch 1259/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1071 - accuracy: 0.9547 - val_loss: 0.8104 - val_accuracy: 0.8746\n",
      "Epoch 1260/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.1088 - accuracy: 0.9511 - val_loss: 0.7986 - val_accuracy: 0.8688\n",
      "Epoch 1261/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1012 - accuracy: 0.9489 - val_loss: 0.7967 - val_accuracy: 0.8746\n",
      "Epoch 1262/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1129 - accuracy: 0.9481 - val_loss: 0.8065 - val_accuracy: 0.8659\n",
      "Epoch 1263/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1019 - accuracy: 0.9511 - val_loss: 0.8278 - val_accuracy: 0.8776\n",
      "Epoch 1264/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1157 - accuracy: 0.9496 - val_loss: 0.8123 - val_accuracy: 0.8688\n",
      "Epoch 1265/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1061 - accuracy: 0.9489 - val_loss: 0.8087 - val_accuracy: 0.8659\n",
      "Epoch 1266/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1049 - accuracy: 0.9496 - val_loss: 0.8145 - val_accuracy: 0.8571\n",
      "Epoch 1267/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.1091 - accuracy: 0.9533 - val_loss: 0.8194 - val_accuracy: 0.8542\n",
      "Epoch 1268/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1121 - accuracy: 0.9533 - val_loss: 0.8550 - val_accuracy: 0.8513\n",
      "Epoch 1269/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1299 - accuracy: 0.9401 - val_loss: 0.8528 - val_accuracy: 0.8630\n",
      "Epoch 1270/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.0994 - accuracy: 0.9562 - val_loss: 0.8289 - val_accuracy: 0.8571\n",
      "Epoch 1271/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1082 - accuracy: 0.9518 - val_loss: 0.8308 - val_accuracy: 0.8630\n",
      "Epoch 1272/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1081 - accuracy: 0.9518 - val_loss: 0.8431 - val_accuracy: 0.8659\n",
      "Epoch 1273/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1057 - accuracy: 0.9540 - val_loss: 0.8301 - val_accuracy: 0.8542\n",
      "Epoch 1274/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1387 - accuracy: 0.9416 - val_loss: 0.8292 - val_accuracy: 0.8776\n",
      "Epoch 1275/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1154 - accuracy: 0.9511 - val_loss: 0.7963 - val_accuracy: 0.8659\n",
      "Epoch 1276/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1151 - accuracy: 0.9518 - val_loss: 0.7786 - val_accuracy: 0.8630\n",
      "Epoch 1277/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.1006 - accuracy: 0.9533 - val_loss: 0.7827 - val_accuracy: 0.8688\n",
      "Epoch 1278/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1054 - accuracy: 0.9525 - val_loss: 0.7802 - val_accuracy: 0.8659\n",
      "Epoch 1279/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.1086 - accuracy: 0.9569 - val_loss: 0.7646 - val_accuracy: 0.8688\n",
      "Epoch 1280/2500\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.1144 - accuracy: 0.9540 - val_loss: 0.7429 - val_accuracy: 0.8688\n",
      "Epoch 1281/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.1191 - accuracy: 0.9525 - val_loss: 0.7498 - val_accuracy: 0.8630\n",
      "Epoch 1282/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1067 - accuracy: 0.9518 - val_loss: 0.7625 - val_accuracy: 0.8601\n",
      "Epoch 1283/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.1188 - accuracy: 0.9503 - val_loss: 0.7584 - val_accuracy: 0.8746\n",
      "Epoch 1284/2500\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.1129 - accuracy: 0.9533 - val_loss: 0.7436 - val_accuracy: 0.8717\n",
      "Epoch 1285/2500\n",
      "18/18 [==============================] - 1s 24ms/step - loss: 0.1000 - accuracy: 0.9525 - val_loss: 0.7612 - val_accuracy: 0.8776\n",
      "Epoch 1286/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1154 - accuracy: 0.9503 - val_loss: 0.7834 - val_accuracy: 0.8746\n",
      "Epoch 1287/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1201 - accuracy: 0.9481 - val_loss: 0.7937 - val_accuracy: 0.8601\n",
      "Epoch 1288/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1037 - accuracy: 0.9540 - val_loss: 0.7734 - val_accuracy: 0.8805\n",
      "Epoch 1289/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1240 - accuracy: 0.9408 - val_loss: 0.8172 - val_accuracy: 0.8513\n",
      "Epoch 1290/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1103 - accuracy: 0.9554 - val_loss: 0.7973 - val_accuracy: 0.8746\n",
      "Epoch 1291/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1089 - accuracy: 0.9452 - val_loss: 0.7990 - val_accuracy: 0.8630\n",
      "Epoch 1292/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1064 - accuracy: 0.9598 - val_loss: 0.7776 - val_accuracy: 0.8601\n",
      "Epoch 1293/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1090 - accuracy: 0.9511 - val_loss: 0.7789 - val_accuracy: 0.8776\n",
      "Epoch 1294/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1048 - accuracy: 0.9511 - val_loss: 0.7548 - val_accuracy: 0.8717\n",
      "Epoch 1295/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.1027 - accuracy: 0.9533 - val_loss: 0.7669 - val_accuracy: 0.8834\n",
      "Epoch 1296/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1032 - accuracy: 0.9518 - val_loss: 0.7583 - val_accuracy: 0.8776\n",
      "Epoch 1297/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1199 - accuracy: 0.9496 - val_loss: 0.7697 - val_accuracy: 0.8688\n",
      "Epoch 1298/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1072 - accuracy: 0.9481 - val_loss: 0.7753 - val_accuracy: 0.8776\n",
      "Epoch 1299/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1002 - accuracy: 0.9525 - val_loss: 0.7746 - val_accuracy: 0.8688\n",
      "Epoch 1300/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1147 - accuracy: 0.9525 - val_loss: 0.7328 - val_accuracy: 0.8805\n",
      "Epoch 1301/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1187 - accuracy: 0.9481 - val_loss: 0.7810 - val_accuracy: 0.8659\n",
      "Epoch 1302/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1021 - accuracy: 0.9518 - val_loss: 0.7930 - val_accuracy: 0.8659\n",
      "Epoch 1303/2500\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.1008 - accuracy: 0.9511 - val_loss: 0.8116 - val_accuracy: 0.8542\n",
      "Epoch 1304/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1122 - accuracy: 0.9481 - val_loss: 0.8096 - val_accuracy: 0.8746\n",
      "Epoch 1305/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.0971 - accuracy: 0.9547 - val_loss: 0.7956 - val_accuracy: 0.8776\n",
      "Epoch 1306/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1036 - accuracy: 0.9562 - val_loss: 0.7677 - val_accuracy: 0.8776\n",
      "Epoch 1307/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1051 - accuracy: 0.9554 - val_loss: 0.7891 - val_accuracy: 0.8688\n",
      "Epoch 1308/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1016 - accuracy: 0.9503 - val_loss: 0.7840 - val_accuracy: 0.8688\n",
      "Epoch 1309/2500\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.1097 - accuracy: 0.9503 - val_loss: 0.7522 - val_accuracy: 0.8688\n",
      "Epoch 1310/2500\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.1166 - accuracy: 0.9525 - val_loss: 0.8068 - val_accuracy: 0.8659\n",
      "Epoch 1311/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1113 - accuracy: 0.9540 - val_loss: 0.7782 - val_accuracy: 0.8630\n",
      "Epoch 1312/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.1162 - accuracy: 0.9467 - val_loss: 0.7842 - val_accuracy: 0.8717\n",
      "Epoch 1313/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1155 - accuracy: 0.9496 - val_loss: 0.8039 - val_accuracy: 0.8601\n",
      "Epoch 1314/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1083 - accuracy: 0.9503 - val_loss: 0.8127 - val_accuracy: 0.8746\n",
      "Epoch 1315/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1131 - accuracy: 0.9474 - val_loss: 0.8020 - val_accuracy: 0.8688\n",
      "Epoch 1316/2500\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.0963 - accuracy: 0.9547 - val_loss: 0.8109 - val_accuracy: 0.8630\n",
      "Epoch 1317/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1119 - accuracy: 0.9518 - val_loss: 0.8141 - val_accuracy: 0.8601\n",
      "Epoch 1318/2500\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.1183 - accuracy: 0.9496 - val_loss: 0.7763 - val_accuracy: 0.8688\n",
      "Epoch 1319/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1097 - accuracy: 0.9540 - val_loss: 0.7700 - val_accuracy: 0.8805\n",
      "Epoch 1320/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1107 - accuracy: 0.9525 - val_loss: 0.8205 - val_accuracy: 0.8542\n",
      "Epoch 1321/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1113 - accuracy: 0.9496 - val_loss: 0.8205 - val_accuracy: 0.8805\n",
      "Epoch 1322/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1118 - accuracy: 0.9533 - val_loss: 0.8123 - val_accuracy: 0.8571\n",
      "Epoch 1323/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1070 - accuracy: 0.9562 - val_loss: 0.8180 - val_accuracy: 0.8805\n",
      "Epoch 1324/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1047 - accuracy: 0.9547 - val_loss: 0.8174 - val_accuracy: 0.8688\n",
      "Epoch 1325/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1069 - accuracy: 0.9503 - val_loss: 0.7950 - val_accuracy: 0.8601\n",
      "Epoch 1326/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1221 - accuracy: 0.9481 - val_loss: 0.7967 - val_accuracy: 0.8659\n",
      "Epoch 1327/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1012 - accuracy: 0.9562 - val_loss: 0.7972 - val_accuracy: 0.8834\n",
      "Epoch 1328/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.1081 - accuracy: 0.9489 - val_loss: 0.8128 - val_accuracy: 0.8717\n",
      "Epoch 1329/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1057 - accuracy: 0.9511 - val_loss: 0.8057 - val_accuracy: 0.8776\n",
      "Epoch 1330/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1193 - accuracy: 0.9503 - val_loss: 0.7943 - val_accuracy: 0.8630\n",
      "Epoch 1331/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1012 - accuracy: 0.9533 - val_loss: 0.7971 - val_accuracy: 0.8717\n",
      "Epoch 1332/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0971 - accuracy: 0.9569 - val_loss: 0.7976 - val_accuracy: 0.8630\n",
      "Epoch 1333/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1093 - accuracy: 0.9481 - val_loss: 0.7794 - val_accuracy: 0.8717\n",
      "Epoch 1334/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1060 - accuracy: 0.9562 - val_loss: 0.7844 - val_accuracy: 0.8571\n",
      "Epoch 1335/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.1062 - accuracy: 0.9554 - val_loss: 0.8071 - val_accuracy: 0.8484\n",
      "Epoch 1336/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.1112 - accuracy: 0.9547 - val_loss: 0.8178 - val_accuracy: 0.8659\n",
      "Epoch 1337/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1111 - accuracy: 0.9496 - val_loss: 0.7809 - val_accuracy: 0.8630\n",
      "Epoch 1338/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.1152 - accuracy: 0.9438 - val_loss: 0.8030 - val_accuracy: 0.8513\n",
      "Epoch 1339/2500\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.1058 - accuracy: 0.9467 - val_loss: 0.7980 - val_accuracy: 0.8601\n",
      "Epoch 1340/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.1128 - accuracy: 0.9533 - val_loss: 0.7853 - val_accuracy: 0.8805\n",
      "Epoch 1341/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1124 - accuracy: 0.9481 - val_loss: 0.7791 - val_accuracy: 0.8776\n",
      "Epoch 1342/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1111 - accuracy: 0.9481 - val_loss: 0.7914 - val_accuracy: 0.8921\n",
      "Epoch 1343/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1113 - accuracy: 0.9554 - val_loss: 0.8014 - val_accuracy: 0.8659\n",
      "Epoch 1344/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1147 - accuracy: 0.9474 - val_loss: 0.7819 - val_accuracy: 0.8776\n",
      "Epoch 1345/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1117 - accuracy: 0.9525 - val_loss: 0.7909 - val_accuracy: 0.8571\n",
      "Epoch 1346/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0991 - accuracy: 0.9547 - val_loss: 0.8025 - val_accuracy: 0.8659\n",
      "Epoch 1347/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1113 - accuracy: 0.9511 - val_loss: 0.7997 - val_accuracy: 0.8776\n",
      "Epoch 1348/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1099 - accuracy: 0.9511 - val_loss: 0.8357 - val_accuracy: 0.8688\n",
      "Epoch 1349/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1262 - accuracy: 0.9474 - val_loss: 0.7938 - val_accuracy: 0.8746\n",
      "Epoch 1350/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1100 - accuracy: 0.9511 - val_loss: 0.7724 - val_accuracy: 0.8776\n",
      "Epoch 1351/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1154 - accuracy: 0.9467 - val_loss: 0.7680 - val_accuracy: 0.8717\n",
      "Epoch 1352/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1002 - accuracy: 0.9547 - val_loss: 0.7628 - val_accuracy: 0.8892\n",
      "Epoch 1353/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1101 - accuracy: 0.9518 - val_loss: 0.7957 - val_accuracy: 0.8630\n",
      "Epoch 1354/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.0995 - accuracy: 0.9547 - val_loss: 0.8337 - val_accuracy: 0.8746\n",
      "Epoch 1355/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1073 - accuracy: 0.9489 - val_loss: 0.8120 - val_accuracy: 0.8805\n",
      "Epoch 1356/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.1181 - accuracy: 0.9467 - val_loss: 0.8047 - val_accuracy: 0.8834\n",
      "Epoch 1357/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1279 - accuracy: 0.9489 - val_loss: 0.7889 - val_accuracy: 0.8542\n",
      "Epoch 1358/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1164 - accuracy: 0.9489 - val_loss: 0.7897 - val_accuracy: 0.8717\n",
      "Epoch 1359/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1142 - accuracy: 0.9503 - val_loss: 0.7985 - val_accuracy: 0.8717\n",
      "Epoch 1360/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1123 - accuracy: 0.9481 - val_loss: 0.7638 - val_accuracy: 0.8688\n",
      "Epoch 1361/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1076 - accuracy: 0.9562 - val_loss: 0.7687 - val_accuracy: 0.8805\n",
      "Epoch 1362/2500\n",
      "18/18 [==============================] - 1s 27ms/step - loss: 0.1015 - accuracy: 0.9547 - val_loss: 0.7986 - val_accuracy: 0.8659\n",
      "Epoch 1363/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1091 - accuracy: 0.9489 - val_loss: 0.7876 - val_accuracy: 0.8688\n",
      "Epoch 1364/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1238 - accuracy: 0.9518 - val_loss: 0.8174 - val_accuracy: 0.8659\n",
      "Epoch 1365/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1099 - accuracy: 0.9518 - val_loss: 0.7821 - val_accuracy: 0.8834\n",
      "Epoch 1366/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1067 - accuracy: 0.9481 - val_loss: 0.8206 - val_accuracy: 0.8776\n",
      "Epoch 1367/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1138 - accuracy: 0.9503 - val_loss: 0.7944 - val_accuracy: 0.8630\n",
      "Epoch 1368/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.0999 - accuracy: 0.9503 - val_loss: 0.8068 - val_accuracy: 0.8630\n",
      "Epoch 1369/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1079 - accuracy: 0.9547 - val_loss: 0.7943 - val_accuracy: 0.8542\n",
      "Epoch 1370/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1145 - accuracy: 0.9503 - val_loss: 0.7934 - val_accuracy: 0.8601\n",
      "Epoch 1371/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1080 - accuracy: 0.9547 - val_loss: 0.7824 - val_accuracy: 0.8776\n",
      "Epoch 1372/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0966 - accuracy: 0.9547 - val_loss: 0.7873 - val_accuracy: 0.8717\n",
      "Epoch 1373/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1329 - accuracy: 0.9467 - val_loss: 0.7654 - val_accuracy: 0.8659\n",
      "Epoch 1374/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1171 - accuracy: 0.9503 - val_loss: 0.7864 - val_accuracy: 0.8659\n",
      "Epoch 1375/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1175 - accuracy: 0.9511 - val_loss: 0.8035 - val_accuracy: 0.8630\n",
      "Epoch 1376/2500\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.1211 - accuracy: 0.9518 - val_loss: 0.7902 - val_accuracy: 0.8601\n",
      "Epoch 1377/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.1075 - accuracy: 0.9518 - val_loss: 0.7982 - val_accuracy: 0.8892\n",
      "Epoch 1378/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1111 - accuracy: 0.9525 - val_loss: 0.7965 - val_accuracy: 0.8746\n",
      "Epoch 1379/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1011 - accuracy: 0.9533 - val_loss: 0.8041 - val_accuracy: 0.8776\n",
      "Epoch 1380/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.1008 - accuracy: 0.9540 - val_loss: 0.8211 - val_accuracy: 0.8717\n",
      "Epoch 1381/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.0985 - accuracy: 0.9554 - val_loss: 0.8295 - val_accuracy: 0.8717\n",
      "Epoch 1382/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1121 - accuracy: 0.9481 - val_loss: 0.8177 - val_accuracy: 0.8746\n",
      "Epoch 1383/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1271 - accuracy: 0.9430 - val_loss: 0.8272 - val_accuracy: 0.8688\n",
      "Epoch 1384/2500\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.1138 - accuracy: 0.9503 - val_loss: 0.8268 - val_accuracy: 0.8659\n",
      "Epoch 1385/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1154 - accuracy: 0.9474 - val_loss: 0.8146 - val_accuracy: 0.8776\n",
      "Epoch 1386/2500\n",
      "18/18 [==============================] - 0s 28ms/step - loss: 0.1104 - accuracy: 0.9503 - val_loss: 0.8220 - val_accuracy: 0.8805\n",
      "Epoch 1387/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1049 - accuracy: 0.9518 - val_loss: 0.8355 - val_accuracy: 0.8805\n",
      "Epoch 1388/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1013 - accuracy: 0.9525 - val_loss: 0.8437 - val_accuracy: 0.8717\n",
      "Epoch 1389/2500\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.1053 - accuracy: 0.9525 - val_loss: 0.8420 - val_accuracy: 0.8484\n",
      "Epoch 1390/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.0994 - accuracy: 0.9547 - val_loss: 0.8228 - val_accuracy: 0.8630\n",
      "Epoch 1391/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1037 - accuracy: 0.9547 - val_loss: 0.8313 - val_accuracy: 0.8688\n",
      "Epoch 1392/2500\n",
      "18/18 [==============================] - 1s 25ms/step - loss: 0.1013 - accuracy: 0.9554 - val_loss: 0.8347 - val_accuracy: 0.8805\n",
      "Epoch 1393/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.1044 - accuracy: 0.9503 - val_loss: 0.8858 - val_accuracy: 0.8630\n",
      "Epoch 1394/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1043 - accuracy: 0.9511 - val_loss: 0.8579 - val_accuracy: 0.8601\n",
      "Epoch 1395/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1056 - accuracy: 0.9540 - val_loss: 0.8264 - val_accuracy: 0.8805\n",
      "Epoch 1396/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1031 - accuracy: 0.9569 - val_loss: 0.8234 - val_accuracy: 0.8717\n",
      "Epoch 1397/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1083 - accuracy: 0.9489 - val_loss: 0.8072 - val_accuracy: 0.8834\n",
      "Epoch 1398/2500\n",
      "18/18 [==============================] - 1s 28ms/step - loss: 0.1194 - accuracy: 0.9481 - val_loss: 0.8111 - val_accuracy: 0.8601\n",
      "Epoch 1399/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1065 - accuracy: 0.9525 - val_loss: 0.7844 - val_accuracy: 0.8776\n",
      "Epoch 1400/2500\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.1119 - accuracy: 0.9474 - val_loss: 0.8082 - val_accuracy: 0.8688\n",
      "Epoch 1401/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1078 - accuracy: 0.9518 - val_loss: 0.7785 - val_accuracy: 0.8805\n",
      "Epoch 1402/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.0954 - accuracy: 0.9569 - val_loss: 0.7769 - val_accuracy: 0.8863\n",
      "Epoch 1403/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1014 - accuracy: 0.9525 - val_loss: 0.7731 - val_accuracy: 0.8659\n",
      "Epoch 1404/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1014 - accuracy: 0.9540 - val_loss: 0.7925 - val_accuracy: 0.8659\n",
      "Epoch 1405/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1202 - accuracy: 0.9474 - val_loss: 0.7927 - val_accuracy: 0.8863\n",
      "Epoch 1406/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1073 - accuracy: 0.9547 - val_loss: 0.7971 - val_accuracy: 0.8630\n",
      "Epoch 1407/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1245 - accuracy: 0.9445 - val_loss: 0.8094 - val_accuracy: 0.8776\n",
      "Epoch 1408/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1122 - accuracy: 0.9511 - val_loss: 0.7933 - val_accuracy: 0.8805\n",
      "Epoch 1409/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1130 - accuracy: 0.9525 - val_loss: 0.8068 - val_accuracy: 0.8630\n",
      "Epoch 1410/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.0954 - accuracy: 0.9554 - val_loss: 0.7973 - val_accuracy: 0.8659\n",
      "Epoch 1411/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.1034 - accuracy: 0.9525 - val_loss: 0.8043 - val_accuracy: 0.8805\n",
      "Epoch 1412/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0949 - accuracy: 0.9540 - val_loss: 0.8008 - val_accuracy: 0.8717\n",
      "Epoch 1413/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.0945 - accuracy: 0.9576 - val_loss: 0.7913 - val_accuracy: 0.8717\n",
      "Epoch 1414/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1062 - accuracy: 0.9496 - val_loss: 0.8063 - val_accuracy: 0.8659\n",
      "Epoch 1415/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.1205 - accuracy: 0.9496 - val_loss: 0.8517 - val_accuracy: 0.8688\n",
      "Epoch 1416/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1189 - accuracy: 0.9489 - val_loss: 0.8230 - val_accuracy: 0.8717\n",
      "Epoch 1417/2500\n",
      "18/18 [==============================] - 1s 25ms/step - loss: 0.1069 - accuracy: 0.9474 - val_loss: 0.8479 - val_accuracy: 0.8571\n",
      "Epoch 1418/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1243 - accuracy: 0.9459 - val_loss: 0.8225 - val_accuracy: 0.8688\n",
      "Epoch 1419/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1173 - accuracy: 0.9489 - val_loss: 0.8239 - val_accuracy: 0.8688\n",
      "Epoch 1420/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1217 - accuracy: 0.9533 - val_loss: 0.8408 - val_accuracy: 0.8688\n",
      "Epoch 1421/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1062 - accuracy: 0.9503 - val_loss: 0.8133 - val_accuracy: 0.8688\n",
      "Epoch 1422/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.0980 - accuracy: 0.9576 - val_loss: 0.8162 - val_accuracy: 0.8659\n",
      "Epoch 1423/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.0989 - accuracy: 0.9584 - val_loss: 0.8494 - val_accuracy: 0.8688\n",
      "Epoch 1424/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1005 - accuracy: 0.9518 - val_loss: 0.8548 - val_accuracy: 0.8688\n",
      "Epoch 1425/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1124 - accuracy: 0.9503 - val_loss: 0.8405 - val_accuracy: 0.8892\n",
      "Epoch 1426/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1017 - accuracy: 0.9525 - val_loss: 0.8706 - val_accuracy: 0.8630\n",
      "Epoch 1427/2500\n",
      "18/18 [==============================] - 0s 28ms/step - loss: 0.1096 - accuracy: 0.9474 - val_loss: 0.8621 - val_accuracy: 0.8630\n",
      "Epoch 1428/2500\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.1067 - accuracy: 0.9525 - val_loss: 0.8697 - val_accuracy: 0.8601\n",
      "Epoch 1429/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.0965 - accuracy: 0.9547 - val_loss: 0.8588 - val_accuracy: 0.8746\n",
      "Epoch 1430/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1002 - accuracy: 0.9547 - val_loss: 0.8713 - val_accuracy: 0.8746\n",
      "Epoch 1431/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1099 - accuracy: 0.9518 - val_loss: 0.8569 - val_accuracy: 0.8601\n",
      "Epoch 1432/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1132 - accuracy: 0.9518 - val_loss: 0.8535 - val_accuracy: 0.8659\n",
      "Epoch 1433/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0986 - accuracy: 0.9569 - val_loss: 0.8561 - val_accuracy: 0.8746\n",
      "Epoch 1434/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1058 - accuracy: 0.9503 - val_loss: 0.8602 - val_accuracy: 0.8688\n",
      "Epoch 1435/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1125 - accuracy: 0.9547 - val_loss: 0.8385 - val_accuracy: 0.8776\n",
      "Epoch 1436/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1000 - accuracy: 0.9533 - val_loss: 0.8220 - val_accuracy: 0.8717\n",
      "Epoch 1437/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1047 - accuracy: 0.9591 - val_loss: 0.8274 - val_accuracy: 0.8746\n",
      "Epoch 1438/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0933 - accuracy: 0.9547 - val_loss: 0.8537 - val_accuracy: 0.8688\n",
      "Epoch 1439/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.1035 - accuracy: 0.9562 - val_loss: 0.8388 - val_accuracy: 0.8746\n",
      "Epoch 1440/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1011 - accuracy: 0.9533 - val_loss: 0.8380 - val_accuracy: 0.8805\n",
      "Epoch 1441/2500\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.0937 - accuracy: 0.9591 - val_loss: 0.8540 - val_accuracy: 0.8746\n",
      "Epoch 1442/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1053 - accuracy: 0.9533 - val_loss: 0.8559 - val_accuracy: 0.8659\n",
      "Epoch 1443/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1102 - accuracy: 0.9518 - val_loss: 0.8758 - val_accuracy: 0.8717\n",
      "Epoch 1444/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1100 - accuracy: 0.9459 - val_loss: 0.8544 - val_accuracy: 0.8892\n",
      "Epoch 1445/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.1017 - accuracy: 0.9540 - val_loss: 0.8554 - val_accuracy: 0.8834\n",
      "Epoch 1446/2500\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.1184 - accuracy: 0.9518 - val_loss: 0.8307 - val_accuracy: 0.8659\n",
      "Epoch 1447/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1030 - accuracy: 0.9547 - val_loss: 0.8145 - val_accuracy: 0.8659\n",
      "Epoch 1448/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1074 - accuracy: 0.9496 - val_loss: 0.8299 - val_accuracy: 0.8776\n",
      "Epoch 1449/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1140 - accuracy: 0.9562 - val_loss: 0.8200 - val_accuracy: 0.8717\n",
      "Epoch 1450/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0986 - accuracy: 0.9540 - val_loss: 0.8249 - val_accuracy: 0.8717\n",
      "Epoch 1451/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.0980 - accuracy: 0.9540 - val_loss: 0.8414 - val_accuracy: 0.8863\n",
      "Epoch 1452/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.0993 - accuracy: 0.9533 - val_loss: 0.8492 - val_accuracy: 0.8688\n",
      "Epoch 1453/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1025 - accuracy: 0.9554 - val_loss: 0.8890 - val_accuracy: 0.8746\n",
      "Epoch 1454/2500\n",
      "18/18 [==============================] - 1s 25ms/step - loss: 0.1377 - accuracy: 0.9430 - val_loss: 0.8810 - val_accuracy: 0.8717\n",
      "Epoch 1455/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1230 - accuracy: 0.9452 - val_loss: 0.8516 - val_accuracy: 0.8601\n",
      "Epoch 1456/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0954 - accuracy: 0.9591 - val_loss: 0.8660 - val_accuracy: 0.8863\n",
      "Epoch 1457/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1020 - accuracy: 0.9584 - val_loss: 0.8615 - val_accuracy: 0.8863\n",
      "Epoch 1458/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1090 - accuracy: 0.9547 - val_loss: 0.8289 - val_accuracy: 0.8950\n",
      "Epoch 1459/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.0983 - accuracy: 0.9576 - val_loss: 0.8456 - val_accuracy: 0.8834\n",
      "Epoch 1460/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1071 - accuracy: 0.9547 - val_loss: 0.8540 - val_accuracy: 0.8863\n",
      "Epoch 1461/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1123 - accuracy: 0.9489 - val_loss: 0.8519 - val_accuracy: 0.8659\n",
      "Epoch 1462/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1032 - accuracy: 0.9569 - val_loss: 0.8300 - val_accuracy: 0.8601\n",
      "Epoch 1463/2500\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.1106 - accuracy: 0.9525 - val_loss: 0.8229 - val_accuracy: 0.8717\n",
      "Epoch 1464/2500\n",
      "18/18 [==============================] - 1s 28ms/step - loss: 0.1265 - accuracy: 0.9438 - val_loss: 0.8353 - val_accuracy: 0.8776\n",
      "Epoch 1465/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1125 - accuracy: 0.9459 - val_loss: 0.8197 - val_accuracy: 0.8863\n",
      "Epoch 1466/2500\n",
      "18/18 [==============================] - 1s 28ms/step - loss: 0.0997 - accuracy: 0.9569 - val_loss: 0.8246 - val_accuracy: 0.8805\n",
      "Epoch 1467/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1116 - accuracy: 0.9518 - val_loss: 0.8012 - val_accuracy: 0.8863\n",
      "Epoch 1468/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1083 - accuracy: 0.9496 - val_loss: 0.8012 - val_accuracy: 0.8688\n",
      "Epoch 1469/2500\n",
      "18/18 [==============================] - 1s 28ms/step - loss: 0.1079 - accuracy: 0.9489 - val_loss: 0.7785 - val_accuracy: 0.8717\n",
      "Epoch 1470/2500\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.0990 - accuracy: 0.9547 - val_loss: 0.8051 - val_accuracy: 0.8717\n",
      "Epoch 1471/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1003 - accuracy: 0.9533 - val_loss: 0.7850 - val_accuracy: 0.8805\n",
      "Epoch 1472/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1000 - accuracy: 0.9540 - val_loss: 0.7997 - val_accuracy: 0.8630\n",
      "Epoch 1473/2500\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.1009 - accuracy: 0.9562 - val_loss: 0.8404 - val_accuracy: 0.8630\n",
      "Epoch 1474/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1049 - accuracy: 0.9540 - val_loss: 0.8391 - val_accuracy: 0.8688\n",
      "Epoch 1475/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1079 - accuracy: 0.9518 - val_loss: 0.8421 - val_accuracy: 0.8659\n",
      "Epoch 1476/2500\n",
      "18/18 [==============================] - 0s 28ms/step - loss: 0.1064 - accuracy: 0.9533 - val_loss: 0.8375 - val_accuracy: 0.8717\n",
      "Epoch 1477/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1026 - accuracy: 0.9562 - val_loss: 0.8246 - val_accuracy: 0.8688\n",
      "Epoch 1478/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1008 - accuracy: 0.9467 - val_loss: 0.8212 - val_accuracy: 0.8834\n",
      "Epoch 1479/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1068 - accuracy: 0.9511 - val_loss: 0.7967 - val_accuracy: 0.8834\n",
      "Epoch 1480/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1151 - accuracy: 0.9540 - val_loss: 0.8439 - val_accuracy: 0.8601\n",
      "Epoch 1481/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.1044 - accuracy: 0.9554 - val_loss: 0.8297 - val_accuracy: 0.8717\n",
      "Epoch 1482/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1074 - accuracy: 0.9518 - val_loss: 0.8479 - val_accuracy: 0.8630\n",
      "Epoch 1483/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0998 - accuracy: 0.9533 - val_loss: 0.8823 - val_accuracy: 0.8571\n",
      "Epoch 1484/2500\n",
      "18/18 [==============================] - 0s 28ms/step - loss: 0.1026 - accuracy: 0.9540 - val_loss: 0.8775 - val_accuracy: 0.8601\n",
      "Epoch 1485/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1031 - accuracy: 0.9503 - val_loss: 0.8872 - val_accuracy: 0.8688\n",
      "Epoch 1486/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1123 - accuracy: 0.9467 - val_loss: 0.8765 - val_accuracy: 0.8688\n",
      "Epoch 1487/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1022 - accuracy: 0.9554 - val_loss: 0.9070 - val_accuracy: 0.8805\n",
      "Epoch 1488/2500\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.1121 - accuracy: 0.9525 - val_loss: 0.8632 - val_accuracy: 0.8688\n",
      "Epoch 1489/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1100 - accuracy: 0.9525 - val_loss: 0.8594 - val_accuracy: 0.8659\n",
      "Epoch 1490/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1015 - accuracy: 0.9576 - val_loss: 0.8852 - val_accuracy: 0.8601\n",
      "Epoch 1491/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.1052 - accuracy: 0.9518 - val_loss: 0.8588 - val_accuracy: 0.8746\n",
      "Epoch 1492/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1002 - accuracy: 0.9525 - val_loss: 0.8646 - val_accuracy: 0.8601\n",
      "Epoch 1493/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0964 - accuracy: 0.9547 - val_loss: 0.8528 - val_accuracy: 0.8805\n",
      "Epoch 1494/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0957 - accuracy: 0.9562 - val_loss: 0.8484 - val_accuracy: 0.8746\n",
      "Epoch 1495/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1114 - accuracy: 0.9511 - val_loss: 0.8551 - val_accuracy: 0.8805\n",
      "Epoch 1496/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.0970 - accuracy: 0.9547 - val_loss: 0.8484 - val_accuracy: 0.8776\n",
      "Epoch 1497/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.0913 - accuracy: 0.9591 - val_loss: 0.8594 - val_accuracy: 0.8659\n",
      "Epoch 1498/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.1185 - accuracy: 0.9511 - val_loss: 0.8348 - val_accuracy: 0.8863\n",
      "Epoch 1499/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1022 - accuracy: 0.9525 - val_loss: 0.8651 - val_accuracy: 0.8571\n",
      "Epoch 1500/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0980 - accuracy: 0.9576 - val_loss: 0.8600 - val_accuracy: 0.8746\n",
      "Epoch 1501/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1158 - accuracy: 0.9489 - val_loss: 0.8644 - val_accuracy: 0.8776\n",
      "Epoch 1502/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.1060 - accuracy: 0.9540 - val_loss: 0.8469 - val_accuracy: 0.8571\n",
      "Epoch 1503/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1153 - accuracy: 0.9489 - val_loss: 0.8503 - val_accuracy: 0.8746\n",
      "Epoch 1504/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1016 - accuracy: 0.9547 - val_loss: 0.8692 - val_accuracy: 0.8455\n",
      "Epoch 1505/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1042 - accuracy: 0.9540 - val_loss: 0.8577 - val_accuracy: 0.8863\n",
      "Epoch 1506/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1165 - accuracy: 0.9474 - val_loss: 0.8773 - val_accuracy: 0.8630\n",
      "Epoch 1507/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1107 - accuracy: 0.9467 - val_loss: 0.8485 - val_accuracy: 0.8688\n",
      "Epoch 1508/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.1082 - accuracy: 0.9533 - val_loss: 0.8243 - val_accuracy: 0.8630\n",
      "Epoch 1509/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1126 - accuracy: 0.9540 - val_loss: 0.8200 - val_accuracy: 0.8717\n",
      "Epoch 1510/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1084 - accuracy: 0.9540 - val_loss: 0.8266 - val_accuracy: 0.8834\n",
      "Epoch 1511/2500\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.0992 - accuracy: 0.9569 - val_loss: 0.8383 - val_accuracy: 0.8717\n",
      "Epoch 1512/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.1149 - accuracy: 0.9496 - val_loss: 0.8459 - val_accuracy: 0.8601\n",
      "Epoch 1513/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1116 - accuracy: 0.9547 - val_loss: 0.8457 - val_accuracy: 0.8688\n",
      "Epoch 1514/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1062 - accuracy: 0.9525 - val_loss: 0.8488 - val_accuracy: 0.8688\n",
      "Epoch 1515/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1082 - accuracy: 0.9511 - val_loss: 0.8438 - val_accuracy: 0.8746\n",
      "Epoch 1516/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1025 - accuracy: 0.9554 - val_loss: 0.8632 - val_accuracy: 0.8659\n",
      "Epoch 1517/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1036 - accuracy: 0.9525 - val_loss: 0.8392 - val_accuracy: 0.8717\n",
      "Epoch 1518/2500\n",
      "18/18 [==============================] - 1s 28ms/step - loss: 0.0975 - accuracy: 0.9591 - val_loss: 0.8486 - val_accuracy: 0.8805\n",
      "Epoch 1519/2500\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.1033 - accuracy: 0.9525 - val_loss: 0.8417 - val_accuracy: 0.8776\n",
      "Epoch 1520/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0974 - accuracy: 0.9576 - val_loss: 0.8656 - val_accuracy: 0.8776\n",
      "Epoch 1521/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1136 - accuracy: 0.9503 - val_loss: 0.8887 - val_accuracy: 0.8630\n",
      "Epoch 1522/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1076 - accuracy: 0.9489 - val_loss: 0.8494 - val_accuracy: 0.8863\n",
      "Epoch 1523/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1029 - accuracy: 0.9547 - val_loss: 0.8567 - val_accuracy: 0.8717\n",
      "Epoch 1524/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.0966 - accuracy: 0.9547 - val_loss: 0.8324 - val_accuracy: 0.8863\n",
      "Epoch 1525/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1054 - accuracy: 0.9525 - val_loss: 0.8468 - val_accuracy: 0.8863\n",
      "Epoch 1526/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1037 - accuracy: 0.9518 - val_loss: 0.8711 - val_accuracy: 0.8630\n",
      "Epoch 1527/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1040 - accuracy: 0.9474 - val_loss: 0.8618 - val_accuracy: 0.8688\n",
      "Epoch 1528/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1081 - accuracy: 0.9481 - val_loss: 0.8705 - val_accuracy: 0.8776\n",
      "Epoch 1529/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1040 - accuracy: 0.9467 - val_loss: 0.8667 - val_accuracy: 0.8805\n",
      "Epoch 1530/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0945 - accuracy: 0.9518 - val_loss: 0.8725 - val_accuracy: 0.8717\n",
      "Epoch 1531/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1010 - accuracy: 0.9525 - val_loss: 0.8495 - val_accuracy: 0.8776\n",
      "Epoch 1532/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1003 - accuracy: 0.9518 - val_loss: 0.8511 - val_accuracy: 0.8746\n",
      "Epoch 1533/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.0956 - accuracy: 0.9540 - val_loss: 0.8713 - val_accuracy: 0.8805\n",
      "Epoch 1534/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.0951 - accuracy: 0.9576 - val_loss: 0.8690 - val_accuracy: 0.8688\n",
      "Epoch 1535/2500\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.0970 - accuracy: 0.9540 - val_loss: 0.8581 - val_accuracy: 0.8834\n",
      "Epoch 1536/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.0977 - accuracy: 0.9518 - val_loss: 0.8583 - val_accuracy: 0.8746\n",
      "Epoch 1537/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1059 - accuracy: 0.9518 - val_loss: 0.8850 - val_accuracy: 0.8659\n",
      "Epoch 1538/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.0965 - accuracy: 0.9562 - val_loss: 0.8382 - val_accuracy: 0.8717\n",
      "Epoch 1539/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.0973 - accuracy: 0.9569 - val_loss: 0.8453 - val_accuracy: 0.8776\n",
      "Epoch 1540/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1010 - accuracy: 0.9547 - val_loss: 0.8620 - val_accuracy: 0.8659\n",
      "Epoch 1541/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1280 - accuracy: 0.9416 - val_loss: 0.8535 - val_accuracy: 0.8571\n",
      "Epoch 1542/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1084 - accuracy: 0.9518 - val_loss: 0.8543 - val_accuracy: 0.8688\n",
      "Epoch 1543/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1008 - accuracy: 0.9533 - val_loss: 0.8392 - val_accuracy: 0.8834\n",
      "Epoch 1544/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1018 - accuracy: 0.9503 - val_loss: 0.8544 - val_accuracy: 0.8805\n",
      "Epoch 1545/2500\n",
      "18/18 [==============================] - 0s 28ms/step - loss: 0.1052 - accuracy: 0.9533 - val_loss: 0.8649 - val_accuracy: 0.8717\n",
      "Epoch 1546/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1019 - accuracy: 0.9584 - val_loss: 0.8497 - val_accuracy: 0.8688\n",
      "Epoch 1547/2500\n",
      "18/18 [==============================] - 0s 28ms/step - loss: 0.1036 - accuracy: 0.9591 - val_loss: 0.8435 - val_accuracy: 0.8834\n",
      "Epoch 1548/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1100 - accuracy: 0.9481 - val_loss: 0.8380 - val_accuracy: 0.8776\n",
      "Epoch 1549/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0985 - accuracy: 0.9562 - val_loss: 0.8547 - val_accuracy: 0.8717\n",
      "Epoch 1550/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.1015 - accuracy: 0.9584 - val_loss: 0.8388 - val_accuracy: 0.8834\n",
      "Epoch 1551/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1015 - accuracy: 0.9562 - val_loss: 0.8329 - val_accuracy: 0.8776\n",
      "Epoch 1552/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1089 - accuracy: 0.9496 - val_loss: 0.8525 - val_accuracy: 0.8746\n",
      "Epoch 1553/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1007 - accuracy: 0.9547 - val_loss: 0.8501 - val_accuracy: 0.8717\n",
      "Epoch 1554/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1028 - accuracy: 0.9562 - val_loss: 0.8534 - val_accuracy: 0.8688\n",
      "Epoch 1555/2500\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.0967 - accuracy: 0.9518 - val_loss: 0.8952 - val_accuracy: 0.8776\n",
      "Epoch 1556/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.0983 - accuracy: 0.9576 - val_loss: 0.8865 - val_accuracy: 0.8746\n",
      "Epoch 1557/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1096 - accuracy: 0.9525 - val_loss: 0.8401 - val_accuracy: 0.8746\n",
      "Epoch 1558/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1066 - accuracy: 0.9554 - val_loss: 0.8411 - val_accuracy: 0.8863\n",
      "Epoch 1559/2500\n",
      "18/18 [==============================] - 1s 28ms/step - loss: 0.0964 - accuracy: 0.9584 - val_loss: 0.8561 - val_accuracy: 0.8834\n",
      "Epoch 1560/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1040 - accuracy: 0.9554 - val_loss: 0.8522 - val_accuracy: 0.8805\n",
      "Epoch 1561/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0934 - accuracy: 0.9554 - val_loss: 0.8432 - val_accuracy: 0.8746\n",
      "Epoch 1562/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1004 - accuracy: 0.9554 - val_loss: 0.8474 - val_accuracy: 0.8892\n",
      "Epoch 1563/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1277 - accuracy: 0.9459 - val_loss: 0.9046 - val_accuracy: 0.8601\n",
      "Epoch 1564/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1191 - accuracy: 0.9481 - val_loss: 0.8105 - val_accuracy: 0.8805\n",
      "Epoch 1565/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1183 - accuracy: 0.9452 - val_loss: 0.8340 - val_accuracy: 0.8717\n",
      "Epoch 1566/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1088 - accuracy: 0.9518 - val_loss: 0.8200 - val_accuracy: 0.8717\n",
      "Epoch 1567/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1015 - accuracy: 0.9540 - val_loss: 0.8198 - val_accuracy: 0.8776\n",
      "Epoch 1568/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1125 - accuracy: 0.9562 - val_loss: 0.8211 - val_accuracy: 0.8776\n",
      "Epoch 1569/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1056 - accuracy: 0.9489 - val_loss: 0.8479 - val_accuracy: 0.8746\n",
      "Epoch 1570/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1246 - accuracy: 0.9511 - val_loss: 0.8634 - val_accuracy: 0.8746\n",
      "Epoch 1571/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1138 - accuracy: 0.9467 - val_loss: 0.8379 - val_accuracy: 0.8688\n",
      "Epoch 1572/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.1000 - accuracy: 0.9554 - val_loss: 0.8297 - val_accuracy: 0.8805\n",
      "Epoch 1573/2500\n",
      "18/18 [==============================] - 1s 28ms/step - loss: 0.1155 - accuracy: 0.9438 - val_loss: 0.8393 - val_accuracy: 0.8834\n",
      "Epoch 1574/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1053 - accuracy: 0.9496 - val_loss: 0.8225 - val_accuracy: 0.8688\n",
      "Epoch 1575/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1045 - accuracy: 0.9525 - val_loss: 0.8473 - val_accuracy: 0.8776\n",
      "Epoch 1576/2500\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.0981 - accuracy: 0.9511 - val_loss: 0.8653 - val_accuracy: 0.8688\n",
      "Epoch 1577/2500\n",
      "18/18 [==============================] - 1s 25ms/step - loss: 0.0934 - accuracy: 0.9562 - val_loss: 0.8469 - val_accuracy: 0.8717\n",
      "Epoch 1578/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1049 - accuracy: 0.9533 - val_loss: 0.8290 - val_accuracy: 0.8863\n",
      "Epoch 1579/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1001 - accuracy: 0.9540 - val_loss: 0.8080 - val_accuracy: 0.8834\n",
      "Epoch 1580/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0955 - accuracy: 0.9540 - val_loss: 0.8375 - val_accuracy: 0.8776\n",
      "Epoch 1581/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.0961 - accuracy: 0.9533 - val_loss: 0.8536 - val_accuracy: 0.8659\n",
      "Epoch 1582/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1008 - accuracy: 0.9547 - val_loss: 0.8753 - val_accuracy: 0.8688\n",
      "Epoch 1583/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1092 - accuracy: 0.9496 - val_loss: 0.8652 - val_accuracy: 0.8834\n",
      "Epoch 1584/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.0984 - accuracy: 0.9554 - val_loss: 0.8477 - val_accuracy: 0.8717\n",
      "Epoch 1585/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0986 - accuracy: 0.9576 - val_loss: 0.8423 - val_accuracy: 0.8776\n",
      "Epoch 1586/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.0986 - accuracy: 0.9598 - val_loss: 0.8651 - val_accuracy: 0.8746\n",
      "Epoch 1587/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.1013 - accuracy: 0.9554 - val_loss: 0.8353 - val_accuracy: 0.8834\n",
      "Epoch 1588/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0986 - accuracy: 0.9511 - val_loss: 0.8599 - val_accuracy: 0.8746\n",
      "Epoch 1589/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1040 - accuracy: 0.9540 - val_loss: 0.8682 - val_accuracy: 0.8805\n",
      "Epoch 1590/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1075 - accuracy: 0.9481 - val_loss: 0.8815 - val_accuracy: 0.8659\n",
      "Epoch 1591/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1027 - accuracy: 0.9503 - val_loss: 0.8796 - val_accuracy: 0.8688\n",
      "Epoch 1592/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0966 - accuracy: 0.9554 - val_loss: 0.8615 - val_accuracy: 0.8776\n",
      "Epoch 1593/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0994 - accuracy: 0.9562 - val_loss: 0.8494 - val_accuracy: 0.8834\n",
      "Epoch 1594/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1007 - accuracy: 0.9562 - val_loss: 0.8549 - val_accuracy: 0.8834\n",
      "Epoch 1595/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1035 - accuracy: 0.9562 - val_loss: 0.8551 - val_accuracy: 0.8834\n",
      "Epoch 1596/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1063 - accuracy: 0.9518 - val_loss: 0.8716 - val_accuracy: 0.8717\n",
      "Epoch 1597/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.1010 - accuracy: 0.9554 - val_loss: 0.8359 - val_accuracy: 0.8892\n",
      "Epoch 1598/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.1113 - accuracy: 0.9518 - val_loss: 0.8350 - val_accuracy: 0.8805\n",
      "Epoch 1599/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1036 - accuracy: 0.9503 - val_loss: 0.8495 - val_accuracy: 0.8542\n",
      "Epoch 1600/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.0992 - accuracy: 0.9562 - val_loss: 0.8649 - val_accuracy: 0.8542\n",
      "Epoch 1601/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1006 - accuracy: 0.9547 - val_loss: 0.8395 - val_accuracy: 0.8688\n",
      "Epoch 1602/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1029 - accuracy: 0.9569 - val_loss: 0.8533 - val_accuracy: 0.8571\n",
      "Epoch 1603/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1188 - accuracy: 0.9489 - val_loss: 0.8527 - val_accuracy: 0.8630\n",
      "Epoch 1604/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.0989 - accuracy: 0.9503 - val_loss: 0.8476 - val_accuracy: 0.8601\n",
      "Epoch 1605/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1026 - accuracy: 0.9540 - val_loss: 0.8481 - val_accuracy: 0.8630\n",
      "Epoch 1606/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1058 - accuracy: 0.9481 - val_loss: 0.8354 - val_accuracy: 0.8688\n",
      "Epoch 1607/2500\n",
      "18/18 [==============================] - 1s 28ms/step - loss: 0.0962 - accuracy: 0.9584 - val_loss: 0.8381 - val_accuracy: 0.8717\n",
      "Epoch 1608/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1105 - accuracy: 0.9445 - val_loss: 0.8638 - val_accuracy: 0.8746\n",
      "Epoch 1609/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.1190 - accuracy: 0.9503 - val_loss: 0.8310 - val_accuracy: 0.8601\n",
      "Epoch 1610/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.0995 - accuracy: 0.9496 - val_loss: 0.8682 - val_accuracy: 0.8601\n",
      "Epoch 1611/2500\n",
      "18/18 [==============================] - 1s 25ms/step - loss: 0.1057 - accuracy: 0.9511 - val_loss: 0.8619 - val_accuracy: 0.8717\n",
      "Epoch 1612/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1082 - accuracy: 0.9511 - val_loss: 0.8422 - val_accuracy: 0.8688\n",
      "Epoch 1613/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0976 - accuracy: 0.9547 - val_loss: 0.8514 - val_accuracy: 0.8571\n",
      "Epoch 1614/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.0981 - accuracy: 0.9503 - val_loss: 0.8477 - val_accuracy: 0.8746\n",
      "Epoch 1615/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1069 - accuracy: 0.9518 - val_loss: 0.8532 - val_accuracy: 0.8717\n",
      "Epoch 1616/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1047 - accuracy: 0.9547 - val_loss: 0.8478 - val_accuracy: 0.8717\n",
      "Epoch 1617/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1012 - accuracy: 0.9569 - val_loss: 0.8558 - val_accuracy: 0.8746\n",
      "Epoch 1618/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0966 - accuracy: 0.9554 - val_loss: 0.8672 - val_accuracy: 0.8688\n",
      "Epoch 1619/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0910 - accuracy: 0.9584 - val_loss: 0.8899 - val_accuracy: 0.8659\n",
      "Epoch 1620/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0968 - accuracy: 0.9569 - val_loss: 0.8970 - val_accuracy: 0.8601\n",
      "Epoch 1621/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1119 - accuracy: 0.9525 - val_loss: 0.8931 - val_accuracy: 0.8630\n",
      "Epoch 1622/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1173 - accuracy: 0.9474 - val_loss: 0.8949 - val_accuracy: 0.8746\n",
      "Epoch 1623/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1067 - accuracy: 0.9496 - val_loss: 0.8795 - val_accuracy: 0.8863\n",
      "Epoch 1624/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0949 - accuracy: 0.9554 - val_loss: 0.8609 - val_accuracy: 0.8776\n",
      "Epoch 1625/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1076 - accuracy: 0.9489 - val_loss: 0.8564 - val_accuracy: 0.8834\n",
      "Epoch 1626/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1180 - accuracy: 0.9503 - val_loss: 0.8704 - val_accuracy: 0.8746\n",
      "Epoch 1627/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1165 - accuracy: 0.9533 - val_loss: 0.8837 - val_accuracy: 0.8542\n",
      "Epoch 1628/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1013 - accuracy: 0.9533 - val_loss: 0.8641 - val_accuracy: 0.8834\n",
      "Epoch 1629/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.1010 - accuracy: 0.9540 - val_loss: 0.8850 - val_accuracy: 0.8776\n",
      "Epoch 1630/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.0990 - accuracy: 0.9584 - val_loss: 0.9364 - val_accuracy: 0.8717\n",
      "Epoch 1631/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.0979 - accuracy: 0.9562 - val_loss: 0.9384 - val_accuracy: 0.8805\n",
      "Epoch 1632/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1004 - accuracy: 0.9576 - val_loss: 0.9156 - val_accuracy: 0.8630\n",
      "Epoch 1633/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.0964 - accuracy: 0.9540 - val_loss: 0.9267 - val_accuracy: 0.8601\n",
      "Epoch 1634/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1075 - accuracy: 0.9554 - val_loss: 0.9132 - val_accuracy: 0.8659\n",
      "Epoch 1635/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0939 - accuracy: 0.9584 - val_loss: 0.8993 - val_accuracy: 0.8659\n",
      "Epoch 1636/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0962 - accuracy: 0.9576 - val_loss: 0.9082 - val_accuracy: 0.8746\n",
      "Epoch 1637/2500\n",
      "18/18 [==============================] - 1s 28ms/step - loss: 0.0941 - accuracy: 0.9569 - val_loss: 0.9164 - val_accuracy: 0.8746\n",
      "Epoch 1638/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1051 - accuracy: 0.9503 - val_loss: 0.8992 - val_accuracy: 0.8863\n",
      "Epoch 1639/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.0976 - accuracy: 0.9569 - val_loss: 0.8966 - val_accuracy: 0.8776\n",
      "Epoch 1640/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.1024 - accuracy: 0.9525 - val_loss: 0.9023 - val_accuracy: 0.8688\n",
      "Epoch 1641/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1024 - accuracy: 0.9525 - val_loss: 0.9010 - val_accuracy: 0.8834\n",
      "Epoch 1642/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.0949 - accuracy: 0.9562 - val_loss: 0.8814 - val_accuracy: 0.8688\n",
      "Epoch 1643/2500\n",
      "18/18 [==============================] - 0s 28ms/step - loss: 0.0956 - accuracy: 0.9525 - val_loss: 0.8739 - val_accuracy: 0.8805\n",
      "Epoch 1644/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0961 - accuracy: 0.9584 - val_loss: 0.8706 - val_accuracy: 0.8921\n",
      "Epoch 1645/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1055 - accuracy: 0.9489 - val_loss: 0.8942 - val_accuracy: 0.8863\n",
      "Epoch 1646/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1130 - accuracy: 0.9511 - val_loss: 0.8963 - val_accuracy: 0.8630\n",
      "Epoch 1647/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0997 - accuracy: 0.9569 - val_loss: 0.8737 - val_accuracy: 0.8717\n",
      "Epoch 1648/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.0953 - accuracy: 0.9591 - val_loss: 0.8790 - val_accuracy: 0.8805\n",
      "Epoch 1649/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0899 - accuracy: 0.9562 - val_loss: 0.8987 - val_accuracy: 0.8805\n",
      "Epoch 1650/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.0969 - accuracy: 0.9525 - val_loss: 0.9010 - val_accuracy: 0.8776\n",
      "Epoch 1651/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.1092 - accuracy: 0.9474 - val_loss: 0.9130 - val_accuracy: 0.8659\n",
      "Epoch 1652/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1061 - accuracy: 0.9547 - val_loss: 0.8569 - val_accuracy: 0.8805\n",
      "Epoch 1653/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.0923 - accuracy: 0.9562 - val_loss: 0.8728 - val_accuracy: 0.8601\n",
      "Epoch 1654/2500\n",
      "18/18 [==============================] - 1s 28ms/step - loss: 0.1001 - accuracy: 0.9496 - val_loss: 0.8738 - val_accuracy: 0.8659\n",
      "Epoch 1655/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1019 - accuracy: 0.9569 - val_loss: 0.8816 - val_accuracy: 0.8659\n",
      "Epoch 1656/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1094 - accuracy: 0.9511 - val_loss: 0.8937 - val_accuracy: 0.8571\n",
      "Epoch 1657/2500\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.1187 - accuracy: 0.9518 - val_loss: 0.8757 - val_accuracy: 0.8601\n",
      "Epoch 1658/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1055 - accuracy: 0.9518 - val_loss: 0.8623 - val_accuracy: 0.8717\n",
      "Epoch 1659/2500\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.1004 - accuracy: 0.9606 - val_loss: 0.8579 - val_accuracy: 0.8717\n",
      "Epoch 1660/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1063 - accuracy: 0.9503 - val_loss: 0.8961 - val_accuracy: 0.8746\n",
      "Epoch 1661/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.0975 - accuracy: 0.9547 - val_loss: 0.9137 - val_accuracy: 0.8717\n",
      "Epoch 1662/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1025 - accuracy: 0.9554 - val_loss: 0.9125 - val_accuracy: 0.8659\n",
      "Epoch 1663/2500\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.0990 - accuracy: 0.9562 - val_loss: 0.8994 - val_accuracy: 0.8717\n",
      "Epoch 1664/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.1103 - accuracy: 0.9533 - val_loss: 0.8880 - val_accuracy: 0.8805\n",
      "Epoch 1665/2500\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.0942 - accuracy: 0.9576 - val_loss: 0.9027 - val_accuracy: 0.8659\n",
      "Epoch 1666/2500\n",
      "18/18 [==============================] - 0s 28ms/step - loss: 0.0908 - accuracy: 0.9591 - val_loss: 0.8920 - val_accuracy: 0.8805\n",
      "Epoch 1667/2500\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 0.0911 - accuracy: 0.9598 - val_loss: 0.8944 - val_accuracy: 0.8746\n",
      "Epoch 1668/2500\n",
      "18/18 [==============================] - 1s 33ms/step - loss: 0.0920 - accuracy: 0.9554 - val_loss: 0.9080 - val_accuracy: 0.8601\n",
      "Epoch 1669/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0914 - accuracy: 0.9620 - val_loss: 0.8918 - val_accuracy: 0.8805\n",
      "Epoch 1670/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.0930 - accuracy: 0.9598 - val_loss: 0.9123 - val_accuracy: 0.8746\n",
      "Epoch 1671/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.0917 - accuracy: 0.9562 - val_loss: 0.8986 - val_accuracy: 0.8776\n",
      "Epoch 1672/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0960 - accuracy: 0.9554 - val_loss: 0.8795 - val_accuracy: 0.8805\n",
      "Epoch 1673/2500\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.1092 - accuracy: 0.9540 - val_loss: 0.8987 - val_accuracy: 0.8776\n",
      "Epoch 1674/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.0994 - accuracy: 0.9540 - val_loss: 0.9134 - val_accuracy: 0.8805\n",
      "Epoch 1675/2500\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 0.0923 - accuracy: 0.9540 - val_loss: 0.9144 - val_accuracy: 0.8863\n",
      "Epoch 1676/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.0951 - accuracy: 0.9547 - val_loss: 0.9175 - val_accuracy: 0.8630\n",
      "Epoch 1677/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0987 - accuracy: 0.9591 - val_loss: 0.8984 - val_accuracy: 0.8571\n",
      "Epoch 1678/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1033 - accuracy: 0.9525 - val_loss: 0.9072 - val_accuracy: 0.8659\n",
      "Epoch 1679/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.1085 - accuracy: 0.9474 - val_loss: 0.9166 - val_accuracy: 0.8746\n",
      "Epoch 1680/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0950 - accuracy: 0.9547 - val_loss: 0.9142 - val_accuracy: 0.8688\n",
      "Epoch 1681/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1008 - accuracy: 0.9511 - val_loss: 0.9082 - val_accuracy: 0.8717\n",
      "Epoch 1682/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1107 - accuracy: 0.9540 - val_loss: 0.9385 - val_accuracy: 0.8630\n",
      "Epoch 1683/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0998 - accuracy: 0.9554 - val_loss: 0.8831 - val_accuracy: 0.8630\n",
      "Epoch 1684/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.0955 - accuracy: 0.9584 - val_loss: 0.8819 - val_accuracy: 0.8571\n",
      "Epoch 1685/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0966 - accuracy: 0.9598 - val_loss: 0.9184 - val_accuracy: 0.8776\n",
      "Epoch 1686/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1036 - accuracy: 0.9525 - val_loss: 0.9335 - val_accuracy: 0.8746\n",
      "Epoch 1687/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.1103 - accuracy: 0.9503 - val_loss: 0.8881 - val_accuracy: 0.8571\n",
      "Epoch 1688/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0941 - accuracy: 0.9540 - val_loss: 0.8870 - val_accuracy: 0.8630\n",
      "Epoch 1689/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.0928 - accuracy: 0.9525 - val_loss: 0.9020 - val_accuracy: 0.8746\n",
      "Epoch 1690/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.1036 - accuracy: 0.9547 - val_loss: 0.9203 - val_accuracy: 0.8542\n",
      "Epoch 1691/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.1133 - accuracy: 0.9540 - val_loss: 0.9019 - val_accuracy: 0.8776\n",
      "Epoch 1692/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1026 - accuracy: 0.9518 - val_loss: 0.9078 - val_accuracy: 0.8805\n",
      "Epoch 1693/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.0972 - accuracy: 0.9554 - val_loss: 0.9184 - val_accuracy: 0.8805\n",
      "Epoch 1694/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.0925 - accuracy: 0.9569 - val_loss: 0.9010 - val_accuracy: 0.8601\n",
      "Epoch 1695/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0982 - accuracy: 0.9547 - val_loss: 0.8949 - val_accuracy: 0.8776\n",
      "Epoch 1696/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0949 - accuracy: 0.9576 - val_loss: 0.8913 - val_accuracy: 0.8863\n",
      "Epoch 1697/2500\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.1030 - accuracy: 0.9533 - val_loss: 0.8857 - val_accuracy: 0.8746\n",
      "Epoch 1698/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1021 - accuracy: 0.9525 - val_loss: 0.8714 - val_accuracy: 0.8834\n",
      "Epoch 1699/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.0923 - accuracy: 0.9569 - val_loss: 0.8850 - val_accuracy: 0.8776\n",
      "Epoch 1700/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1007 - accuracy: 0.9598 - val_loss: 0.8911 - val_accuracy: 0.8863\n",
      "Epoch 1701/2500\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 0.0929 - accuracy: 0.9554 - val_loss: 0.9000 - val_accuracy: 0.8892\n",
      "Epoch 1702/2500\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.0996 - accuracy: 0.9511 - val_loss: 0.8967 - val_accuracy: 0.8717\n",
      "Epoch 1703/2500\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.1044 - accuracy: 0.9503 - val_loss: 0.8846 - val_accuracy: 0.8746\n",
      "Epoch 1704/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1184 - accuracy: 0.9525 - val_loss: 0.9286 - val_accuracy: 0.8630\n",
      "Epoch 1705/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1388 - accuracy: 0.9452 - val_loss: 0.8992 - val_accuracy: 0.8630\n",
      "Epoch 1706/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1153 - accuracy: 0.9489 - val_loss: 0.8660 - val_accuracy: 0.8834\n",
      "Epoch 1707/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1077 - accuracy: 0.9511 - val_loss: 0.8623 - val_accuracy: 0.8717\n",
      "Epoch 1708/2500\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.1080 - accuracy: 0.9533 - val_loss: 0.8524 - val_accuracy: 0.8776\n",
      "Epoch 1709/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.1165 - accuracy: 0.9489 - val_loss: 0.8145 - val_accuracy: 0.8834\n",
      "Epoch 1710/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.0960 - accuracy: 0.9598 - val_loss: 0.8384 - val_accuracy: 0.8834\n",
      "Epoch 1711/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1044 - accuracy: 0.9533 - val_loss: 0.8705 - val_accuracy: 0.8688\n",
      "Epoch 1712/2500\n",
      "18/18 [==============================] - 1s 33ms/step - loss: 0.1033 - accuracy: 0.9511 - val_loss: 0.8626 - val_accuracy: 0.8863\n",
      "Epoch 1713/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.1027 - accuracy: 0.9496 - val_loss: 0.8715 - val_accuracy: 0.8630\n",
      "Epoch 1714/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1064 - accuracy: 0.9474 - val_loss: 0.8687 - val_accuracy: 0.8688\n",
      "Epoch 1715/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.1104 - accuracy: 0.9518 - val_loss: 0.8652 - val_accuracy: 0.8630\n",
      "Epoch 1716/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1067 - accuracy: 0.9540 - val_loss: 0.8669 - val_accuracy: 0.8805\n",
      "Epoch 1717/2500\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.1075 - accuracy: 0.9540 - val_loss: 0.8575 - val_accuracy: 0.8805\n",
      "Epoch 1718/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0894 - accuracy: 0.9554 - val_loss: 0.8497 - val_accuracy: 0.8746\n",
      "Epoch 1719/2500\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.0948 - accuracy: 0.9591 - val_loss: 0.8521 - val_accuracy: 0.8717\n",
      "Epoch 1720/2500\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.1307 - accuracy: 0.9503 - val_loss: 0.8418 - val_accuracy: 0.8717\n",
      "Epoch 1721/2500\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.1130 - accuracy: 0.9489 - val_loss: 0.8671 - val_accuracy: 0.8688\n",
      "Epoch 1722/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1031 - accuracy: 0.9518 - val_loss: 0.8831 - val_accuracy: 0.8746\n",
      "Epoch 1723/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1051 - accuracy: 0.9503 - val_loss: 0.8714 - val_accuracy: 0.8717\n",
      "Epoch 1724/2500\n",
      "18/18 [==============================] - 1s 28ms/step - loss: 0.0975 - accuracy: 0.9562 - val_loss: 0.8782 - val_accuracy: 0.8746\n",
      "Epoch 1725/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1036 - accuracy: 0.9554 - val_loss: 0.8699 - val_accuracy: 0.8746\n",
      "Epoch 1726/2500\n",
      "18/18 [==============================] - 1s 33ms/step - loss: 0.1020 - accuracy: 0.9511 - val_loss: 0.8535 - val_accuracy: 0.8863\n",
      "Epoch 1727/2500\n",
      "18/18 [==============================] - 1s 28ms/step - loss: 0.0974 - accuracy: 0.9562 - val_loss: 0.8813 - val_accuracy: 0.8630\n",
      "Epoch 1728/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0964 - accuracy: 0.9547 - val_loss: 0.8827 - val_accuracy: 0.8659\n",
      "Epoch 1729/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0959 - accuracy: 0.9613 - val_loss: 0.8942 - val_accuracy: 0.8601\n",
      "Epoch 1730/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0876 - accuracy: 0.9598 - val_loss: 0.8923 - val_accuracy: 0.8776\n",
      "Epoch 1731/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0969 - accuracy: 0.9554 - val_loss: 0.9031 - val_accuracy: 0.8688\n",
      "Epoch 1732/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0984 - accuracy: 0.9547 - val_loss: 0.8752 - val_accuracy: 0.8776\n",
      "Epoch 1733/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.0944 - accuracy: 0.9569 - val_loss: 0.8755 - val_accuracy: 0.8688\n",
      "Epoch 1734/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.1019 - accuracy: 0.9496 - val_loss: 0.8572 - val_accuracy: 0.8805\n",
      "Epoch 1735/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.0962 - accuracy: 0.9554 - val_loss: 0.8631 - val_accuracy: 0.8805\n",
      "Epoch 1736/2500\n",
      "18/18 [==============================] - 1s 33ms/step - loss: 0.0954 - accuracy: 0.9576 - val_loss: 0.8984 - val_accuracy: 0.8542\n",
      "Epoch 1737/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1096 - accuracy: 0.9511 - val_loss: 0.9060 - val_accuracy: 0.8601\n",
      "Epoch 1738/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0901 - accuracy: 0.9584 - val_loss: 0.8839 - val_accuracy: 0.8834\n",
      "Epoch 1739/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.1019 - accuracy: 0.9511 - val_loss: 0.8900 - val_accuracy: 0.8717\n",
      "Epoch 1740/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1030 - accuracy: 0.9525 - val_loss: 0.8856 - val_accuracy: 0.8659\n",
      "Epoch 1741/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1003 - accuracy: 0.9562 - val_loss: 0.8960 - val_accuracy: 0.8571\n",
      "Epoch 1742/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1006 - accuracy: 0.9533 - val_loss: 0.8918 - val_accuracy: 0.8571\n",
      "Epoch 1743/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1063 - accuracy: 0.9525 - val_loss: 0.8886 - val_accuracy: 0.8571\n",
      "Epoch 1744/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.0898 - accuracy: 0.9591 - val_loss: 0.8836 - val_accuracy: 0.8659\n",
      "Epoch 1745/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0949 - accuracy: 0.9540 - val_loss: 0.8993 - val_accuracy: 0.8659\n",
      "Epoch 1746/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.1056 - accuracy: 0.9533 - val_loss: 0.9197 - val_accuracy: 0.8776\n",
      "Epoch 1747/2500\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.0910 - accuracy: 0.9598 - val_loss: 0.8923 - val_accuracy: 0.8717\n",
      "Epoch 1748/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0961 - accuracy: 0.9533 - val_loss: 0.8845 - val_accuracy: 0.8601\n",
      "Epoch 1749/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0963 - accuracy: 0.9562 - val_loss: 0.8872 - val_accuracy: 0.8863\n",
      "Epoch 1750/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1024 - accuracy: 0.9533 - val_loss: 0.9061 - val_accuracy: 0.8659\n",
      "Epoch 1751/2500\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.1028 - accuracy: 0.9540 - val_loss: 0.8910 - val_accuracy: 0.8776\n",
      "Epoch 1752/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1083 - accuracy: 0.9554 - val_loss: 0.8667 - val_accuracy: 0.8805\n",
      "Epoch 1753/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0894 - accuracy: 0.9547 - val_loss: 0.8756 - val_accuracy: 0.8805\n",
      "Epoch 1754/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0915 - accuracy: 0.9584 - val_loss: 0.8816 - val_accuracy: 0.8805\n",
      "Epoch 1755/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.0964 - accuracy: 0.9562 - val_loss: 0.8778 - val_accuracy: 0.8805\n",
      "Epoch 1756/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0942 - accuracy: 0.9569 - val_loss: 0.9057 - val_accuracy: 0.8776\n",
      "Epoch 1757/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1027 - accuracy: 0.9540 - val_loss: 0.8934 - val_accuracy: 0.8571\n",
      "Epoch 1758/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1007 - accuracy: 0.9503 - val_loss: 0.9075 - val_accuracy: 0.8571\n",
      "Epoch 1759/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1064 - accuracy: 0.9525 - val_loss: 0.9008 - val_accuracy: 0.8717\n",
      "Epoch 1760/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0914 - accuracy: 0.9554 - val_loss: 0.9118 - val_accuracy: 0.8659\n",
      "Epoch 1761/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.0944 - accuracy: 0.9533 - val_loss: 0.9211 - val_accuracy: 0.8717\n",
      "Epoch 1762/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.1036 - accuracy: 0.9540 - val_loss: 0.9041 - val_accuracy: 0.8659\n",
      "Epoch 1763/2500\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.1066 - accuracy: 0.9511 - val_loss: 0.8992 - val_accuracy: 0.8630\n",
      "Epoch 1764/2500\n",
      "18/18 [==============================] - 1s 33ms/step - loss: 0.0922 - accuracy: 0.9576 - val_loss: 0.8788 - val_accuracy: 0.8746\n",
      "Epoch 1765/2500\n",
      "18/18 [==============================] - 1s 33ms/step - loss: 0.0878 - accuracy: 0.9569 - val_loss: 0.8782 - val_accuracy: 0.8863\n",
      "Epoch 1766/2500\n",
      "18/18 [==============================] - 1s 28ms/step - loss: 0.0980 - accuracy: 0.9606 - val_loss: 0.8896 - val_accuracy: 0.8688\n",
      "Epoch 1767/2500\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.0930 - accuracy: 0.9598 - val_loss: 0.8836 - val_accuracy: 0.8688\n",
      "Epoch 1768/2500\n",
      "18/18 [==============================] - 1s 33ms/step - loss: 0.0916 - accuracy: 0.9547 - val_loss: 0.8985 - val_accuracy: 0.8776\n",
      "Epoch 1769/2500\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 0.1011 - accuracy: 0.9584 - val_loss: 0.9066 - val_accuracy: 0.8746\n",
      "Epoch 1770/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1034 - accuracy: 0.9562 - val_loss: 0.8880 - val_accuracy: 0.8688\n",
      "Epoch 1771/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1122 - accuracy: 0.9533 - val_loss: 0.8605 - val_accuracy: 0.8776\n",
      "Epoch 1772/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.0903 - accuracy: 0.9584 - val_loss: 0.8696 - val_accuracy: 0.8717\n",
      "Epoch 1773/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.0875 - accuracy: 0.9591 - val_loss: 0.8908 - val_accuracy: 0.8659\n",
      "Epoch 1774/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.0891 - accuracy: 0.9598 - val_loss: 0.8986 - val_accuracy: 0.8776\n",
      "Epoch 1775/2500\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.1031 - accuracy: 0.9503 - val_loss: 0.9067 - val_accuracy: 0.8630\n",
      "Epoch 1776/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.1105 - accuracy: 0.9525 - val_loss: 0.8661 - val_accuracy: 0.8746\n",
      "Epoch 1777/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0951 - accuracy: 0.9562 - val_loss: 0.8663 - val_accuracy: 0.8776\n",
      "Epoch 1778/2500\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 0.0922 - accuracy: 0.9606 - val_loss: 0.8740 - val_accuracy: 0.8601\n",
      "Epoch 1779/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0949 - accuracy: 0.9598 - val_loss: 0.8720 - val_accuracy: 0.8659\n",
      "Epoch 1780/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.0920 - accuracy: 0.9569 - val_loss: 0.8759 - val_accuracy: 0.8776\n",
      "Epoch 1781/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.0962 - accuracy: 0.9576 - val_loss: 0.8874 - val_accuracy: 0.8776\n",
      "Epoch 1782/2500\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.1041 - accuracy: 0.9562 - val_loss: 0.9099 - val_accuracy: 0.8659\n",
      "Epoch 1783/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0983 - accuracy: 0.9598 - val_loss: 0.9281 - val_accuracy: 0.8630\n",
      "Epoch 1784/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.0967 - accuracy: 0.9562 - val_loss: 0.9231 - val_accuracy: 0.8688\n",
      "Epoch 1785/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0984 - accuracy: 0.9525 - val_loss: 0.9110 - val_accuracy: 0.8717\n",
      "Epoch 1786/2500\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.0981 - accuracy: 0.9511 - val_loss: 0.9317 - val_accuracy: 0.8659\n",
      "Epoch 1787/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1067 - accuracy: 0.9533 - val_loss: 0.9284 - val_accuracy: 0.8688\n",
      "Epoch 1788/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1110 - accuracy: 0.9554 - val_loss: 0.8801 - val_accuracy: 0.8688\n",
      "Epoch 1789/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1142 - accuracy: 0.9547 - val_loss: 0.8728 - val_accuracy: 0.8542\n",
      "Epoch 1790/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1200 - accuracy: 0.9547 - val_loss: 0.8804 - val_accuracy: 0.8776\n",
      "Epoch 1791/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.1066 - accuracy: 0.9496 - val_loss: 0.9117 - val_accuracy: 0.8776\n",
      "Epoch 1792/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1217 - accuracy: 0.9445 - val_loss: 0.8865 - val_accuracy: 0.8601\n",
      "Epoch 1793/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.1108 - accuracy: 0.9481 - val_loss: 0.9158 - val_accuracy: 0.8542\n",
      "Epoch 1794/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1016 - accuracy: 0.9547 - val_loss: 0.9112 - val_accuracy: 0.8630\n",
      "Epoch 1795/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.0989 - accuracy: 0.9533 - val_loss: 0.9270 - val_accuracy: 0.8601\n",
      "Epoch 1796/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.0983 - accuracy: 0.9540 - val_loss: 0.9107 - val_accuracy: 0.8601\n",
      "Epoch 1797/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.0951 - accuracy: 0.9540 - val_loss: 0.9033 - val_accuracy: 0.8688\n",
      "Epoch 1798/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1001 - accuracy: 0.9511 - val_loss: 0.9204 - val_accuracy: 0.8601\n",
      "Epoch 1799/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1127 - accuracy: 0.9554 - val_loss: 0.9039 - val_accuracy: 0.8571\n",
      "Epoch 1800/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.1070 - accuracy: 0.9533 - val_loss: 0.8967 - val_accuracy: 0.8601\n",
      "Epoch 1801/2500\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.1039 - accuracy: 0.9518 - val_loss: 0.9004 - val_accuracy: 0.8659\n",
      "Epoch 1802/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1092 - accuracy: 0.9511 - val_loss: 0.8998 - val_accuracy: 0.8601\n",
      "Epoch 1803/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.1214 - accuracy: 0.9489 - val_loss: 0.9306 - val_accuracy: 0.8484\n",
      "Epoch 1804/2500\n",
      "18/18 [==============================] - 1s 33ms/step - loss: 0.1119 - accuracy: 0.9525 - val_loss: 0.9310 - val_accuracy: 0.8397\n",
      "Epoch 1805/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1018 - accuracy: 0.9554 - val_loss: 0.9064 - val_accuracy: 0.8601\n",
      "Epoch 1806/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0931 - accuracy: 0.9540 - val_loss: 0.9161 - val_accuracy: 0.8659\n",
      "Epoch 1807/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.0986 - accuracy: 0.9489 - val_loss: 0.9349 - val_accuracy: 0.8571\n",
      "Epoch 1808/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1051 - accuracy: 0.9525 - val_loss: 0.9393 - val_accuracy: 0.8630\n",
      "Epoch 1809/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.1128 - accuracy: 0.9452 - val_loss: 0.9314 - val_accuracy: 0.8601\n",
      "Epoch 1810/2500\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.1081 - accuracy: 0.9525 - val_loss: 0.9240 - val_accuracy: 0.8630\n",
      "Epoch 1811/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1068 - accuracy: 0.9547 - val_loss: 0.9253 - val_accuracy: 0.8630\n",
      "Epoch 1812/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.0936 - accuracy: 0.9591 - val_loss: 0.8927 - val_accuracy: 0.8601\n",
      "Epoch 1813/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0981 - accuracy: 0.9569 - val_loss: 0.9024 - val_accuracy: 0.8659\n",
      "Epoch 1814/2500\n",
      "18/18 [==============================] - 1s 33ms/step - loss: 0.0948 - accuracy: 0.9511 - val_loss: 0.9017 - val_accuracy: 0.8630\n",
      "Epoch 1815/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1052 - accuracy: 0.9569 - val_loss: 0.8976 - val_accuracy: 0.8688\n",
      "Epoch 1816/2500\n",
      "18/18 [==============================] - 1s 28ms/step - loss: 0.0941 - accuracy: 0.9511 - val_loss: 0.8915 - val_accuracy: 0.8601\n",
      "Epoch 1817/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0976 - accuracy: 0.9569 - val_loss: 0.9061 - val_accuracy: 0.8688\n",
      "Epoch 1818/2500\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.1014 - accuracy: 0.9496 - val_loss: 0.9207 - val_accuracy: 0.8571\n",
      "Epoch 1819/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0931 - accuracy: 0.9540 - val_loss: 0.9451 - val_accuracy: 0.8513\n",
      "Epoch 1820/2500\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 0.0964 - accuracy: 0.9584 - val_loss: 0.9659 - val_accuracy: 0.8601\n",
      "Epoch 1821/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1036 - accuracy: 0.9591 - val_loss: 0.9270 - val_accuracy: 0.8630\n",
      "Epoch 1822/2500\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.1019 - accuracy: 0.9569 - val_loss: 0.9114 - val_accuracy: 0.8659\n",
      "Epoch 1823/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.1101 - accuracy: 0.9533 - val_loss: 0.9136 - val_accuracy: 0.8601\n",
      "Epoch 1824/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1038 - accuracy: 0.9554 - val_loss: 0.9031 - val_accuracy: 0.8571\n",
      "Epoch 1825/2500\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.1056 - accuracy: 0.9562 - val_loss: 0.9233 - val_accuracy: 0.8659\n",
      "Epoch 1826/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.1056 - accuracy: 0.9533 - val_loss: 0.8447 - val_accuracy: 0.8776\n",
      "Epoch 1827/2500\n",
      "18/18 [==============================] - 0s 28ms/step - loss: 0.1045 - accuracy: 0.9547 - val_loss: 0.8590 - val_accuracy: 0.8601\n",
      "Epoch 1828/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0977 - accuracy: 0.9569 - val_loss: 0.8563 - val_accuracy: 0.8805\n",
      "Epoch 1829/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0997 - accuracy: 0.9554 - val_loss: 0.8912 - val_accuracy: 0.8630\n",
      "Epoch 1830/2500\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.0904 - accuracy: 0.9562 - val_loss: 0.8775 - val_accuracy: 0.8717\n",
      "Epoch 1831/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1119 - accuracy: 0.9474 - val_loss: 0.8798 - val_accuracy: 0.8746\n",
      "Epoch 1832/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1032 - accuracy: 0.9452 - val_loss: 0.8711 - val_accuracy: 0.8746\n",
      "Epoch 1833/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.0970 - accuracy: 0.9584 - val_loss: 0.8887 - val_accuracy: 0.8542\n",
      "Epoch 1834/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1110 - accuracy: 0.9540 - val_loss: 0.9093 - val_accuracy: 0.8688\n",
      "Epoch 1835/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1044 - accuracy: 0.9511 - val_loss: 0.9086 - val_accuracy: 0.8630\n",
      "Epoch 1836/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1030 - accuracy: 0.9511 - val_loss: 0.9095 - val_accuracy: 0.8630\n",
      "Epoch 1837/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.0908 - accuracy: 0.9591 - val_loss: 0.9095 - val_accuracy: 0.8513\n",
      "Epoch 1838/2500\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.0866 - accuracy: 0.9554 - val_loss: 0.9152 - val_accuracy: 0.8571\n",
      "Epoch 1839/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.1020 - accuracy: 0.9511 - val_loss: 0.9441 - val_accuracy: 0.8542\n",
      "Epoch 1840/2500\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 0.0885 - accuracy: 0.9569 - val_loss: 0.9277 - val_accuracy: 0.8746\n",
      "Epoch 1841/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0945 - accuracy: 0.9569 - val_loss: 0.9440 - val_accuracy: 0.8601\n",
      "Epoch 1842/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1020 - accuracy: 0.9525 - val_loss: 0.9619 - val_accuracy: 0.8601\n",
      "Epoch 1843/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0909 - accuracy: 0.9576 - val_loss: 0.9479 - val_accuracy: 0.8601\n",
      "Epoch 1844/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1006 - accuracy: 0.9518 - val_loss: 0.9222 - val_accuracy: 0.8659\n",
      "Epoch 1845/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0955 - accuracy: 0.9576 - val_loss: 0.9158 - val_accuracy: 0.8601\n",
      "Epoch 1846/2500\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.1020 - accuracy: 0.9554 - val_loss: 0.9185 - val_accuracy: 0.8717\n",
      "Epoch 1847/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.0970 - accuracy: 0.9547 - val_loss: 0.9351 - val_accuracy: 0.8659\n",
      "Epoch 1848/2500\n",
      "18/18 [==============================] - 0s 28ms/step - loss: 0.0886 - accuracy: 0.9584 - val_loss: 0.9273 - val_accuracy: 0.8659\n",
      "Epoch 1849/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.0875 - accuracy: 0.9569 - val_loss: 0.9229 - val_accuracy: 0.8834\n",
      "Epoch 1850/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0873 - accuracy: 0.9569 - val_loss: 0.9251 - val_accuracy: 0.8717\n",
      "Epoch 1851/2500\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.0997 - accuracy: 0.9489 - val_loss: 0.9449 - val_accuracy: 0.8571\n",
      "Epoch 1852/2500\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.0976 - accuracy: 0.9547 - val_loss: 0.9427 - val_accuracy: 0.8659\n",
      "Epoch 1853/2500\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.0987 - accuracy: 0.9511 - val_loss: 0.9488 - val_accuracy: 0.8688\n",
      "Epoch 1854/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.0962 - accuracy: 0.9547 - val_loss: 0.9242 - val_accuracy: 0.8688\n",
      "Epoch 1855/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0918 - accuracy: 0.9540 - val_loss: 0.9204 - val_accuracy: 0.8630\n",
      "Epoch 1856/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0955 - accuracy: 0.9576 - val_loss: 0.9087 - val_accuracy: 0.8834\n",
      "Epoch 1857/2500\n",
      "18/18 [==============================] - 1s 33ms/step - loss: 0.0884 - accuracy: 0.9547 - val_loss: 0.9218 - val_accuracy: 0.8776\n",
      "Epoch 1858/2500\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.0991 - accuracy: 0.9547 - val_loss: 0.9292 - val_accuracy: 0.8571\n",
      "Epoch 1859/2500\n",
      "18/18 [==============================] - 1s 33ms/step - loss: 0.0932 - accuracy: 0.9591 - val_loss: 0.9304 - val_accuracy: 0.8688\n",
      "Epoch 1860/2500\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.0881 - accuracy: 0.9591 - val_loss: 0.9357 - val_accuracy: 0.8746\n",
      "Epoch 1861/2500\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.0960 - accuracy: 0.9554 - val_loss: 0.8806 - val_accuracy: 0.8717\n",
      "Epoch 1862/2500\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.0955 - accuracy: 0.9562 - val_loss: 0.9051 - val_accuracy: 0.8776\n",
      "Epoch 1863/2500\n",
      "18/18 [==============================] - 1s 34ms/step - loss: 0.1068 - accuracy: 0.9569 - val_loss: 0.8886 - val_accuracy: 0.8717\n",
      "Epoch 1864/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.1091 - accuracy: 0.9576 - val_loss: 0.8905 - val_accuracy: 0.8776\n",
      "Epoch 1865/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0926 - accuracy: 0.9627 - val_loss: 0.8844 - val_accuracy: 0.8717\n",
      "Epoch 1866/2500\n",
      "18/18 [==============================] - 1s 26ms/step - loss: 0.0991 - accuracy: 0.9518 - val_loss: 0.8883 - val_accuracy: 0.8688\n",
      "Epoch 1867/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0959 - accuracy: 0.9598 - val_loss: 0.9166 - val_accuracy: 0.8601\n",
      "Epoch 1868/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.0967 - accuracy: 0.9569 - val_loss: 0.8851 - val_accuracy: 0.8863\n",
      "Epoch 1869/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1022 - accuracy: 0.9525 - val_loss: 0.8505 - val_accuracy: 0.8688\n",
      "Epoch 1870/2500\n",
      "18/18 [==============================] - 1s 33ms/step - loss: 0.0923 - accuracy: 0.9606 - val_loss: 0.8561 - val_accuracy: 0.8630\n",
      "Epoch 1871/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0972 - accuracy: 0.9569 - val_loss: 0.8511 - val_accuracy: 0.8746\n",
      "Epoch 1872/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0978 - accuracy: 0.9547 - val_loss: 0.8591 - val_accuracy: 0.8746\n",
      "Epoch 1873/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.0872 - accuracy: 0.9584 - val_loss: 0.8870 - val_accuracy: 0.8717\n",
      "Epoch 1874/2500\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.0929 - accuracy: 0.9591 - val_loss: 0.8890 - val_accuracy: 0.8717\n",
      "Epoch 1875/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0951 - accuracy: 0.9569 - val_loss: 0.8783 - val_accuracy: 0.8630\n",
      "Epoch 1876/2500\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.0950 - accuracy: 0.9562 - val_loss: 0.8827 - val_accuracy: 0.8892\n",
      "Epoch 1877/2500\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.0913 - accuracy: 0.9584 - val_loss: 0.8890 - val_accuracy: 0.8717\n",
      "Epoch 1878/2500\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.0930 - accuracy: 0.9569 - val_loss: 0.8780 - val_accuracy: 0.8776\n",
      "Epoch 1879/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.1007 - accuracy: 0.9511 - val_loss: 0.8821 - val_accuracy: 0.8688\n",
      "Epoch 1880/2500\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.1004 - accuracy: 0.9554 - val_loss: 0.8790 - val_accuracy: 0.8630\n",
      "Epoch 1881/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.0902 - accuracy: 0.9554 - val_loss: 0.9069 - val_accuracy: 0.8717\n",
      "Epoch 1882/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0899 - accuracy: 0.9569 - val_loss: 0.8852 - val_accuracy: 0.8746\n",
      "Epoch 1883/2500\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.0958 - accuracy: 0.9591 - val_loss: 0.8896 - val_accuracy: 0.8688\n",
      "Epoch 1884/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.1030 - accuracy: 0.9518 - val_loss: 0.8919 - val_accuracy: 0.8688\n",
      "Epoch 1885/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.1019 - accuracy: 0.9540 - val_loss: 0.9216 - val_accuracy: 0.8630\n",
      "Epoch 1886/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0983 - accuracy: 0.9569 - val_loss: 0.9001 - val_accuracy: 0.8776\n",
      "Epoch 1887/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0956 - accuracy: 0.9554 - val_loss: 0.8916 - val_accuracy: 0.8659\n",
      "Epoch 1888/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1030 - accuracy: 0.9503 - val_loss: 0.9015 - val_accuracy: 0.8601\n",
      "Epoch 1889/2500\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.0935 - accuracy: 0.9540 - val_loss: 0.9122 - val_accuracy: 0.8688\n",
      "Epoch 1890/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0958 - accuracy: 0.9562 - val_loss: 0.9091 - val_accuracy: 0.8746\n",
      "Epoch 1891/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.1065 - accuracy: 0.9503 - val_loss: 0.9043 - val_accuracy: 0.8776\n",
      "Epoch 1892/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0888 - accuracy: 0.9547 - val_loss: 0.9056 - val_accuracy: 0.8717\n",
      "Epoch 1893/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0944 - accuracy: 0.9584 - val_loss: 0.9219 - val_accuracy: 0.8746\n",
      "Epoch 1894/2500\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.0860 - accuracy: 0.9569 - val_loss: 0.9259 - val_accuracy: 0.8746\n",
      "Epoch 1895/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0974 - accuracy: 0.9584 - val_loss: 0.9349 - val_accuracy: 0.8630\n",
      "Epoch 1896/2500\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.1225 - accuracy: 0.9511 - val_loss: 0.9269 - val_accuracy: 0.8805\n",
      "Epoch 1897/2500\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.0928 - accuracy: 0.9576 - val_loss: 0.8810 - val_accuracy: 0.8746\n",
      "Epoch 1898/2500\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 0.0963 - accuracy: 0.9620 - val_loss: 0.8960 - val_accuracy: 0.8571\n",
      "Epoch 1899/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0931 - accuracy: 0.9540 - val_loss: 0.8797 - val_accuracy: 0.8776\n",
      "Epoch 1900/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0959 - accuracy: 0.9576 - val_loss: 0.8611 - val_accuracy: 0.8542\n",
      "Epoch 1901/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1000 - accuracy: 0.9511 - val_loss: 0.8710 - val_accuracy: 0.8571\n",
      "Epoch 1902/2500\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.1074 - accuracy: 0.9525 - val_loss: 0.8942 - val_accuracy: 0.8630\n",
      "Epoch 1903/2500\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.1005 - accuracy: 0.9562 - val_loss: 0.8958 - val_accuracy: 0.8688\n",
      "Epoch 1904/2500\n",
      "18/18 [==============================] - 1s 33ms/step - loss: 0.0929 - accuracy: 0.9562 - val_loss: 0.9038 - val_accuracy: 0.8746\n",
      "Epoch 1905/2500\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.0904 - accuracy: 0.9554 - val_loss: 0.9071 - val_accuracy: 0.8630\n",
      "Epoch 1906/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0988 - accuracy: 0.9569 - val_loss: 0.9333 - val_accuracy: 0.8688\n",
      "Epoch 1907/2500\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.0908 - accuracy: 0.9569 - val_loss: 0.9157 - val_accuracy: 0.8717\n",
      "Epoch 1908/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0840 - accuracy: 0.9606 - val_loss: 0.9175 - val_accuracy: 0.8659\n",
      "Epoch 1909/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0876 - accuracy: 0.9569 - val_loss: 0.9301 - val_accuracy: 0.8688\n",
      "Epoch 1910/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.1020 - accuracy: 0.9518 - val_loss: 0.9271 - val_accuracy: 0.8630\n",
      "Epoch 1911/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.0927 - accuracy: 0.9547 - val_loss: 0.9426 - val_accuracy: 0.8484\n",
      "Epoch 1912/2500\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.0934 - accuracy: 0.9562 - val_loss: 0.9480 - val_accuracy: 0.8542\n",
      "Epoch 1913/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.0999 - accuracy: 0.9569 - val_loss: 0.9603 - val_accuracy: 0.8630\n",
      "Epoch 1914/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.1050 - accuracy: 0.9540 - val_loss: 0.9703 - val_accuracy: 0.8426\n",
      "Epoch 1915/2500\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.1138 - accuracy: 0.9459 - val_loss: 0.9582 - val_accuracy: 0.8484\n",
      "Epoch 1916/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1104 - accuracy: 0.9496 - val_loss: 0.9496 - val_accuracy: 0.8630\n",
      "Epoch 1917/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.1013 - accuracy: 0.9533 - val_loss: 0.9326 - val_accuracy: 0.8601\n",
      "Epoch 1918/2500\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.0946 - accuracy: 0.9584 - val_loss: 0.9224 - val_accuracy: 0.8571\n",
      "Epoch 1919/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0984 - accuracy: 0.9540 - val_loss: 0.9355 - val_accuracy: 0.8542\n",
      "Epoch 1920/2500\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 0.0934 - accuracy: 0.9569 - val_loss: 0.9187 - val_accuracy: 0.8484\n",
      "Epoch 1921/2500\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.0929 - accuracy: 0.9533 - val_loss: 0.9055 - val_accuracy: 0.8630\n",
      "Epoch 1922/2500\n",
      "18/18 [==============================] - 1s 33ms/step - loss: 0.0924 - accuracy: 0.9569 - val_loss: 0.8896 - val_accuracy: 0.8659\n",
      "Epoch 1923/2500\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.1046 - accuracy: 0.9518 - val_loss: 0.9334 - val_accuracy: 0.8630\n",
      "Epoch 1924/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1080 - accuracy: 0.9518 - val_loss: 0.9282 - val_accuracy: 0.8601\n",
      "Epoch 1925/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.0928 - accuracy: 0.9584 - val_loss: 0.9068 - val_accuracy: 0.8630\n",
      "Epoch 1926/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0990 - accuracy: 0.9591 - val_loss: 0.9012 - val_accuracy: 0.8688\n",
      "Epoch 1927/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.0945 - accuracy: 0.9569 - val_loss: 0.8964 - val_accuracy: 0.8659\n",
      "Epoch 1928/2500\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.0912 - accuracy: 0.9584 - val_loss: 0.9261 - val_accuracy: 0.8630\n",
      "Epoch 1929/2500\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.0985 - accuracy: 0.9533 - val_loss: 0.9322 - val_accuracy: 0.8571\n",
      "Epoch 1930/2500\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.1021 - accuracy: 0.9540 - val_loss: 0.9359 - val_accuracy: 0.8601\n",
      "Epoch 1931/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.0909 - accuracy: 0.9547 - val_loss: 0.9209 - val_accuracy: 0.8601\n",
      "Epoch 1932/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0896 - accuracy: 0.9591 - val_loss: 0.9214 - val_accuracy: 0.8542\n",
      "Epoch 1933/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.1047 - accuracy: 0.9562 - val_loss: 0.9339 - val_accuracy: 0.8571\n",
      "Epoch 1934/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0873 - accuracy: 0.9613 - val_loss: 0.9116 - val_accuracy: 0.8601\n",
      "Epoch 1935/2500\n",
      "18/18 [==============================] - 1s 28ms/step - loss: 0.0882 - accuracy: 0.9584 - val_loss: 0.8956 - val_accuracy: 0.8717\n",
      "Epoch 1936/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.0964 - accuracy: 0.9547 - val_loss: 0.9252 - val_accuracy: 0.8659\n",
      "Epoch 1937/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1213 - accuracy: 0.9474 - val_loss: 0.9985 - val_accuracy: 0.8426\n",
      "Epoch 1938/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1122 - accuracy: 0.9474 - val_loss: 0.9091 - val_accuracy: 0.8659\n",
      "Epoch 1939/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1032 - accuracy: 0.9540 - val_loss: 0.9274 - val_accuracy: 0.8571\n",
      "Epoch 1940/2500\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.1076 - accuracy: 0.9503 - val_loss: 0.9301 - val_accuracy: 0.8688\n",
      "Epoch 1941/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.0890 - accuracy: 0.9606 - val_loss: 0.9385 - val_accuracy: 0.8659\n",
      "Epoch 1942/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1103 - accuracy: 0.9525 - val_loss: 0.9301 - val_accuracy: 0.8717\n",
      "Epoch 1943/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.1028 - accuracy: 0.9569 - val_loss: 0.9293 - val_accuracy: 0.8688\n",
      "Epoch 1944/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.1052 - accuracy: 0.9547 - val_loss: 0.9173 - val_accuracy: 0.8688\n",
      "Epoch 1945/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.0956 - accuracy: 0.9576 - val_loss: 0.9208 - val_accuracy: 0.8542\n",
      "Epoch 1946/2500\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.0986 - accuracy: 0.9518 - val_loss: 0.9069 - val_accuracy: 0.8659\n",
      "Epoch 1947/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.0931 - accuracy: 0.9576 - val_loss: 0.9154 - val_accuracy: 0.8571\n",
      "Epoch 1948/2500\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.0965 - accuracy: 0.9569 - val_loss: 0.9040 - val_accuracy: 0.8601\n",
      "Epoch 1949/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0902 - accuracy: 0.9547 - val_loss: 0.8927 - val_accuracy: 0.8601\n",
      "Epoch 1950/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.0951 - accuracy: 0.9584 - val_loss: 0.9128 - val_accuracy: 0.8659\n",
      "Epoch 1951/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0914 - accuracy: 0.9562 - val_loss: 0.9332 - val_accuracy: 0.8688\n",
      "Epoch 1952/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.0907 - accuracy: 0.9562 - val_loss: 0.9368 - val_accuracy: 0.8688\n",
      "Epoch 1953/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.0896 - accuracy: 0.9554 - val_loss: 0.9440 - val_accuracy: 0.8659\n",
      "Epoch 1954/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.0987 - accuracy: 0.9518 - val_loss: 0.9657 - val_accuracy: 0.8688\n",
      "Epoch 1955/2500\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.1250 - accuracy: 0.9489 - val_loss: 0.9410 - val_accuracy: 0.8542\n",
      "Epoch 1956/2500\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.1121 - accuracy: 0.9445 - val_loss: 0.9158 - val_accuracy: 0.8688\n",
      "Epoch 1957/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.1077 - accuracy: 0.9511 - val_loss: 0.9240 - val_accuracy: 0.8484\n",
      "Epoch 1958/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0987 - accuracy: 0.9540 - val_loss: 0.9338 - val_accuracy: 0.8659\n",
      "Epoch 1959/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1012 - accuracy: 0.9503 - val_loss: 0.9666 - val_accuracy: 0.8571\n",
      "Epoch 1960/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.0964 - accuracy: 0.9554 - val_loss: 0.9538 - val_accuracy: 0.8513\n",
      "Epoch 1961/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.0933 - accuracy: 0.9584 - val_loss: 0.9507 - val_accuracy: 0.8659\n",
      "Epoch 1962/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0946 - accuracy: 0.9562 - val_loss: 0.9606 - val_accuracy: 0.8659\n",
      "Epoch 1963/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1013 - accuracy: 0.9598 - val_loss: 0.9731 - val_accuracy: 0.8571\n",
      "Epoch 1964/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.0997 - accuracy: 0.9503 - val_loss: 0.9607 - val_accuracy: 0.8717\n",
      "Epoch 1965/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1063 - accuracy: 0.9540 - val_loss: 0.9251 - val_accuracy: 0.8805\n",
      "Epoch 1966/2500\n",
      "18/18 [==============================] - 1s 34ms/step - loss: 0.0904 - accuracy: 0.9591 - val_loss: 0.9288 - val_accuracy: 0.8659\n",
      "Epoch 1967/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1010 - accuracy: 0.9496 - val_loss: 0.9135 - val_accuracy: 0.8805\n",
      "Epoch 1968/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0957 - accuracy: 0.9613 - val_loss: 0.9390 - val_accuracy: 0.8805\n",
      "Epoch 1969/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.0916 - accuracy: 0.9584 - val_loss: 0.9586 - val_accuracy: 0.8746\n",
      "Epoch 1970/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0962 - accuracy: 0.9562 - val_loss: 0.9670 - val_accuracy: 0.8776\n",
      "Epoch 1971/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1107 - accuracy: 0.9511 - val_loss: 0.9763 - val_accuracy: 0.8688\n",
      "Epoch 1972/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0996 - accuracy: 0.9533 - val_loss: 0.9765 - val_accuracy: 0.8776\n",
      "Epoch 1973/2500\n",
      "18/18 [==============================] - 1s 25ms/step - loss: 0.1037 - accuracy: 0.9547 - val_loss: 0.9462 - val_accuracy: 0.8805\n",
      "Epoch 1974/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.0969 - accuracy: 0.9554 - val_loss: 0.9653 - val_accuracy: 0.8805\n",
      "Epoch 1975/2500\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.0988 - accuracy: 0.9540 - val_loss: 0.9408 - val_accuracy: 0.8717\n",
      "Epoch 1976/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0931 - accuracy: 0.9591 - val_loss: 0.9071 - val_accuracy: 0.8601\n",
      "Epoch 1977/2500\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 0.1134 - accuracy: 0.9525 - val_loss: 0.9006 - val_accuracy: 0.8601\n",
      "Epoch 1978/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.1078 - accuracy: 0.9569 - val_loss: 0.8669 - val_accuracy: 0.8746\n",
      "Epoch 1979/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0908 - accuracy: 0.9569 - val_loss: 0.8601 - val_accuracy: 0.8688\n",
      "Epoch 1980/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1170 - accuracy: 0.9459 - val_loss: 0.9192 - val_accuracy: 0.8717\n",
      "Epoch 1981/2500\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.0975 - accuracy: 0.9562 - val_loss: 0.9491 - val_accuracy: 0.8688\n",
      "Epoch 1982/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.1168 - accuracy: 0.9481 - val_loss: 0.9350 - val_accuracy: 0.8746\n",
      "Epoch 1983/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1075 - accuracy: 0.9481 - val_loss: 0.9503 - val_accuracy: 0.8630\n",
      "Epoch 1984/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1021 - accuracy: 0.9547 - val_loss: 0.9418 - val_accuracy: 0.8571\n",
      "Epoch 1985/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1059 - accuracy: 0.9467 - val_loss: 0.9500 - val_accuracy: 0.8717\n",
      "Epoch 1986/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.1209 - accuracy: 0.9503 - val_loss: 0.9762 - val_accuracy: 0.8630\n",
      "Epoch 1987/2500\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.0975 - accuracy: 0.9562 - val_loss: 0.9505 - val_accuracy: 0.8688\n",
      "Epoch 1988/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0973 - accuracy: 0.9576 - val_loss: 0.9510 - val_accuracy: 0.8717\n",
      "Epoch 1989/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.0934 - accuracy: 0.9554 - val_loss: 0.9439 - val_accuracy: 0.8717\n",
      "Epoch 1990/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0954 - accuracy: 0.9562 - val_loss: 0.9411 - val_accuracy: 0.8630\n",
      "Epoch 1991/2500\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.0926 - accuracy: 0.9591 - val_loss: 0.9426 - val_accuracy: 0.8746\n",
      "Epoch 1992/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0886 - accuracy: 0.9613 - val_loss: 0.9394 - val_accuracy: 0.8776\n",
      "Epoch 1993/2500\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.0910 - accuracy: 0.9569 - val_loss: 0.9725 - val_accuracy: 0.8717\n",
      "Epoch 1994/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.1021 - accuracy: 0.9540 - val_loss: 0.9750 - val_accuracy: 0.8659\n",
      "Epoch 1995/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.1035 - accuracy: 0.9547 - val_loss: 0.9765 - val_accuracy: 0.8688\n",
      "Epoch 1996/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.0905 - accuracy: 0.9584 - val_loss: 0.9651 - val_accuracy: 0.8805\n",
      "Epoch 1997/2500\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.0893 - accuracy: 0.9576 - val_loss: 0.9703 - val_accuracy: 0.8863\n",
      "Epoch 1998/2500\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.0946 - accuracy: 0.9576 - val_loss: 0.9547 - val_accuracy: 0.8746\n",
      "Epoch 1999/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.0964 - accuracy: 0.9576 - val_loss: 0.9532 - val_accuracy: 0.8717\n",
      "Epoch 2000/2500\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.1044 - accuracy: 0.9533 - val_loss: 0.9679 - val_accuracy: 0.8659\n",
      "Epoch 2001/2500\n",
      "18/18 [==============================] - 1s 34ms/step - loss: 0.1006 - accuracy: 0.9547 - val_loss: 0.9607 - val_accuracy: 0.8659\n",
      "Epoch 2002/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.0992 - accuracy: 0.9525 - val_loss: 1.0052 - val_accuracy: 0.8630\n",
      "Epoch 2003/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0907 - accuracy: 0.9562 - val_loss: 0.9534 - val_accuracy: 0.8659\n",
      "Epoch 2004/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1051 - accuracy: 0.9496 - val_loss: 0.9641 - val_accuracy: 0.8542\n",
      "Epoch 2005/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0970 - accuracy: 0.9562 - val_loss: 0.9620 - val_accuracy: 0.8746\n",
      "Epoch 2006/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.0885 - accuracy: 0.9591 - val_loss: 0.9701 - val_accuracy: 0.8630\n",
      "Epoch 2007/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.0904 - accuracy: 0.9576 - val_loss: 0.9577 - val_accuracy: 0.8717\n",
      "Epoch 2008/2500\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.0938 - accuracy: 0.9613 - val_loss: 0.9702 - val_accuracy: 0.8776\n",
      "Epoch 2009/2500\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.0879 - accuracy: 0.9591 - val_loss: 0.9856 - val_accuracy: 0.8776\n",
      "Epoch 2010/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0999 - accuracy: 0.9562 - val_loss: 0.9907 - val_accuracy: 0.8659\n",
      "Epoch 2011/2500\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.1008 - accuracy: 0.9525 - val_loss: 0.9877 - val_accuracy: 0.8746\n",
      "Epoch 2012/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.0973 - accuracy: 0.9569 - val_loss: 0.9937 - val_accuracy: 0.8746\n",
      "Epoch 2013/2500\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.1071 - accuracy: 0.9496 - val_loss: 0.9920 - val_accuracy: 0.8746\n",
      "Epoch 2014/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0933 - accuracy: 0.9569 - val_loss: 0.9667 - val_accuracy: 0.8805\n",
      "Epoch 2015/2500\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.0939 - accuracy: 0.9533 - val_loss: 0.9199 - val_accuracy: 0.8776\n",
      "Epoch 2016/2500\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.0957 - accuracy: 0.9547 - val_loss: 0.9152 - val_accuracy: 0.8834\n",
      "Epoch 2017/2500\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.0922 - accuracy: 0.9547 - val_loss: 0.9334 - val_accuracy: 0.8688\n",
      "Epoch 2018/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0939 - accuracy: 0.9569 - val_loss: 0.9282 - val_accuracy: 0.8746\n",
      "Epoch 2019/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1206 - accuracy: 0.9459 - val_loss: 0.9221 - val_accuracy: 0.8746\n",
      "Epoch 2020/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.1019 - accuracy: 0.9591 - val_loss: 0.9481 - val_accuracy: 0.8746\n",
      "Epoch 2021/2500\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.1074 - accuracy: 0.9525 - val_loss: 0.9598 - val_accuracy: 0.8746\n",
      "Epoch 2022/2500\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.0980 - accuracy: 0.9569 - val_loss: 0.9382 - val_accuracy: 0.8776\n",
      "Epoch 2023/2500\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.0927 - accuracy: 0.9613 - val_loss: 0.9224 - val_accuracy: 0.8746\n",
      "Epoch 2024/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1034 - accuracy: 0.9540 - val_loss: 0.9398 - val_accuracy: 0.8688\n",
      "Epoch 2025/2500\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.1023 - accuracy: 0.9562 - val_loss: 0.9723 - val_accuracy: 0.8746\n",
      "Epoch 2026/2500\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.0904 - accuracy: 0.9591 - val_loss: 0.9785 - val_accuracy: 0.8659\n",
      "Epoch 2027/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0897 - accuracy: 0.9576 - val_loss: 1.0021 - val_accuracy: 0.8776\n",
      "Epoch 2028/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.0958 - accuracy: 0.9569 - val_loss: 0.9812 - val_accuracy: 0.8746\n",
      "Epoch 2029/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0912 - accuracy: 0.9613 - val_loss: 0.9622 - val_accuracy: 0.8746\n",
      "Epoch 2030/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0936 - accuracy: 0.9525 - val_loss: 0.9557 - val_accuracy: 0.8776\n",
      "Epoch 2031/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.0870 - accuracy: 0.9576 - val_loss: 0.9693 - val_accuracy: 0.8688\n",
      "Epoch 2032/2500\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.0887 - accuracy: 0.9606 - val_loss: 0.9837 - val_accuracy: 0.8659\n",
      "Epoch 2033/2500\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.1089 - accuracy: 0.9511 - val_loss: 0.9775 - val_accuracy: 0.8776\n",
      "Epoch 2034/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1029 - accuracy: 0.9540 - val_loss: 0.9751 - val_accuracy: 0.8630\n",
      "Epoch 2035/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1017 - accuracy: 0.9503 - val_loss: 0.9951 - val_accuracy: 0.8776\n",
      "Epoch 2036/2500\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.1039 - accuracy: 0.9576 - val_loss: 1.0111 - val_accuracy: 0.8746\n",
      "Epoch 2037/2500\n",
      "18/18 [==============================] - 1s 33ms/step - loss: 0.0980 - accuracy: 0.9525 - val_loss: 1.0106 - val_accuracy: 0.8630\n",
      "Epoch 2038/2500\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.0981 - accuracy: 0.9606 - val_loss: 1.0416 - val_accuracy: 0.8746\n",
      "Epoch 2039/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1023 - accuracy: 0.9496 - val_loss: 1.0276 - val_accuracy: 0.8659\n",
      "Epoch 2040/2500\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 0.0927 - accuracy: 0.9584 - val_loss: 1.0013 - val_accuracy: 0.8776\n",
      "Epoch 2041/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0977 - accuracy: 0.9576 - val_loss: 0.9923 - val_accuracy: 0.8834\n",
      "Epoch 2042/2500\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.0958 - accuracy: 0.9554 - val_loss: 0.9773 - val_accuracy: 0.8688\n",
      "Epoch 2043/2500\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.0927 - accuracy: 0.9613 - val_loss: 0.9930 - val_accuracy: 0.8805\n",
      "Epoch 2044/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1002 - accuracy: 0.9540 - val_loss: 0.9922 - val_accuracy: 0.8717\n",
      "Epoch 2045/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0948 - accuracy: 0.9540 - val_loss: 1.0026 - val_accuracy: 0.8601\n",
      "Epoch 2046/2500\n",
      "18/18 [==============================] - 1s 33ms/step - loss: 0.0958 - accuracy: 0.9525 - val_loss: 0.9599 - val_accuracy: 0.8805\n",
      "Epoch 2047/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.0977 - accuracy: 0.9606 - val_loss: 0.9669 - val_accuracy: 0.8717\n",
      "Epoch 2048/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.0942 - accuracy: 0.9569 - val_loss: 1.0052 - val_accuracy: 0.8688\n",
      "Epoch 2049/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.0855 - accuracy: 0.9606 - val_loss: 1.0042 - val_accuracy: 0.8688\n",
      "Epoch 2050/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1026 - accuracy: 0.9547 - val_loss: 0.9922 - val_accuracy: 0.8630\n",
      "Epoch 2051/2500\n",
      "18/18 [==============================] - 1s 34ms/step - loss: 0.0973 - accuracy: 0.9576 - val_loss: 0.9701 - val_accuracy: 0.8659\n",
      "Epoch 2052/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1010 - accuracy: 0.9533 - val_loss: 0.9453 - val_accuracy: 0.8805\n",
      "Epoch 2053/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0886 - accuracy: 0.9598 - val_loss: 0.9536 - val_accuracy: 0.8863\n",
      "Epoch 2054/2500\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.0940 - accuracy: 0.9584 - val_loss: 0.9736 - val_accuracy: 0.8746\n",
      "Epoch 2055/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0962 - accuracy: 0.9576 - val_loss: 0.9932 - val_accuracy: 0.8717\n",
      "Epoch 2056/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1029 - accuracy: 0.9547 - val_loss: 0.9787 - val_accuracy: 0.8805\n",
      "Epoch 2057/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0984 - accuracy: 0.9554 - val_loss: 0.9955 - val_accuracy: 0.8630\n",
      "Epoch 2058/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.1096 - accuracy: 0.9562 - val_loss: 0.9899 - val_accuracy: 0.8571\n",
      "Epoch 2059/2500\n",
      "18/18 [==============================] - 1s 33ms/step - loss: 0.1038 - accuracy: 0.9576 - val_loss: 0.9830 - val_accuracy: 0.8717\n",
      "Epoch 2060/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.0942 - accuracy: 0.9547 - val_loss: 0.9557 - val_accuracy: 0.8776\n",
      "Epoch 2061/2500\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 0.1073 - accuracy: 0.9511 - val_loss: 0.9919 - val_accuracy: 0.8601\n",
      "Epoch 2062/2500\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.0948 - accuracy: 0.9525 - val_loss: 1.0079 - val_accuracy: 0.8601\n",
      "Epoch 2063/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1000 - accuracy: 0.9496 - val_loss: 0.9982 - val_accuracy: 0.8746\n",
      "Epoch 2064/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0845 - accuracy: 0.9569 - val_loss: 0.9941 - val_accuracy: 0.8805\n",
      "Epoch 2065/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0963 - accuracy: 0.9562 - val_loss: 0.9922 - val_accuracy: 0.8717\n",
      "Epoch 2066/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0964 - accuracy: 0.9554 - val_loss: 0.9984 - val_accuracy: 0.8659\n",
      "Epoch 2067/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1001 - accuracy: 0.9540 - val_loss: 1.0002 - val_accuracy: 0.8688\n",
      "Epoch 2068/2500\n",
      "18/18 [==============================] - 1s 33ms/step - loss: 0.0967 - accuracy: 0.9569 - val_loss: 0.9449 - val_accuracy: 0.8805\n",
      "Epoch 2069/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0925 - accuracy: 0.9620 - val_loss: 0.9520 - val_accuracy: 0.8746\n",
      "Epoch 2070/2500\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.0969 - accuracy: 0.9540 - val_loss: 0.9505 - val_accuracy: 0.8834\n",
      "Epoch 2071/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0957 - accuracy: 0.9554 - val_loss: 0.9853 - val_accuracy: 0.8776\n",
      "Epoch 2072/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0925 - accuracy: 0.9576 - val_loss: 0.9704 - val_accuracy: 0.8776\n",
      "Epoch 2073/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0862 - accuracy: 0.9635 - val_loss: 0.9743 - val_accuracy: 0.8834\n",
      "Epoch 2074/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0917 - accuracy: 0.9489 - val_loss: 0.9560 - val_accuracy: 0.8630\n",
      "Epoch 2075/2500\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.1000 - accuracy: 0.9569 - val_loss: 0.9236 - val_accuracy: 0.8717\n",
      "Epoch 2076/2500\n",
      "18/18 [==============================] - 1s 33ms/step - loss: 0.0982 - accuracy: 0.9562 - val_loss: 0.9461 - val_accuracy: 0.8746\n",
      "Epoch 2077/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0835 - accuracy: 0.9562 - val_loss: 0.9642 - val_accuracy: 0.8659\n",
      "Epoch 2078/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0891 - accuracy: 0.9569 - val_loss: 0.9838 - val_accuracy: 0.8659\n",
      "Epoch 2079/2500\n",
      "18/18 [==============================] - 1s 33ms/step - loss: 0.0934 - accuracy: 0.9569 - val_loss: 1.0002 - val_accuracy: 0.8659\n",
      "Epoch 2080/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0922 - accuracy: 0.9554 - val_loss: 0.9703 - val_accuracy: 0.8659\n",
      "Epoch 2081/2500\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.0928 - accuracy: 0.9576 - val_loss: 0.9828 - val_accuracy: 0.8688\n",
      "Epoch 2082/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.0834 - accuracy: 0.9613 - val_loss: 0.9798 - val_accuracy: 0.8776\n",
      "Epoch 2083/2500\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.0891 - accuracy: 0.9554 - val_loss: 0.9826 - val_accuracy: 0.8601\n",
      "Epoch 2084/2500\n",
      "18/18 [==============================] - 1s 33ms/step - loss: 0.0869 - accuracy: 0.9606 - val_loss: 0.9857 - val_accuracy: 0.8805\n",
      "Epoch 2085/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0955 - accuracy: 0.9562 - val_loss: 1.0130 - val_accuracy: 0.8688\n",
      "Epoch 2086/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0943 - accuracy: 0.9606 - val_loss: 1.0045 - val_accuracy: 0.8746\n",
      "Epoch 2087/2500\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.0883 - accuracy: 0.9576 - val_loss: 0.9882 - val_accuracy: 0.8717\n",
      "Epoch 2088/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0846 - accuracy: 0.9591 - val_loss: 0.9916 - val_accuracy: 0.8805\n",
      "Epoch 2089/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0892 - accuracy: 0.9584 - val_loss: 0.9817 - val_accuracy: 0.8834\n",
      "Epoch 2090/2500\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.0896 - accuracy: 0.9554 - val_loss: 0.9693 - val_accuracy: 0.8863\n",
      "Epoch 2091/2500\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.0882 - accuracy: 0.9598 - val_loss: 0.9585 - val_accuracy: 0.8776\n",
      "Epoch 2092/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.0939 - accuracy: 0.9598 - val_loss: 0.9885 - val_accuracy: 0.8746\n",
      "Epoch 2093/2500\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.0913 - accuracy: 0.9554 - val_loss: 0.9848 - val_accuracy: 0.8746\n",
      "Epoch 2094/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.1009 - accuracy: 0.9481 - val_loss: 0.9875 - val_accuracy: 0.8688\n",
      "Epoch 2095/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.0988 - accuracy: 0.9533 - val_loss: 0.9983 - val_accuracy: 0.8630\n",
      "Epoch 2096/2500\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.0958 - accuracy: 0.9569 - val_loss: 0.9832 - val_accuracy: 0.8630\n",
      "Epoch 2097/2500\n",
      "18/18 [==============================] - 1s 34ms/step - loss: 0.0991 - accuracy: 0.9584 - val_loss: 0.9715 - val_accuracy: 0.8776\n",
      "Epoch 2098/2500\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.0962 - accuracy: 0.9584 - val_loss: 0.9969 - val_accuracy: 0.8688\n",
      "Epoch 2099/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.0940 - accuracy: 0.9518 - val_loss: 0.9821 - val_accuracy: 0.8805\n",
      "Epoch 2100/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1038 - accuracy: 0.9533 - val_loss: 0.9986 - val_accuracy: 0.8601\n",
      "Epoch 2101/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0936 - accuracy: 0.9562 - val_loss: 0.9817 - val_accuracy: 0.8746\n",
      "Epoch 2102/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0934 - accuracy: 0.9576 - val_loss: 0.9520 - val_accuracy: 0.8717\n",
      "Epoch 2103/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0989 - accuracy: 0.9569 - val_loss: 0.9694 - val_accuracy: 0.8601\n",
      "Epoch 2104/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.0892 - accuracy: 0.9562 - val_loss: 0.9540 - val_accuracy: 0.8571\n",
      "Epoch 2105/2500\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.0933 - accuracy: 0.9554 - val_loss: 0.9481 - val_accuracy: 0.8717\n",
      "Epoch 2106/2500\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.0953 - accuracy: 0.9562 - val_loss: 0.9447 - val_accuracy: 0.8746\n",
      "Epoch 2107/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0977 - accuracy: 0.9518 - val_loss: 0.9482 - val_accuracy: 0.8746\n",
      "Epoch 2108/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0841 - accuracy: 0.9576 - val_loss: 0.9571 - val_accuracy: 0.8688\n",
      "Epoch 2109/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0931 - accuracy: 0.9547 - val_loss: 0.9760 - val_accuracy: 0.8746\n",
      "Epoch 2110/2500\n",
      "18/18 [==============================] - 1s 33ms/step - loss: 0.1050 - accuracy: 0.9511 - val_loss: 0.9532 - val_accuracy: 0.8630\n",
      "Epoch 2111/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0931 - accuracy: 0.9525 - val_loss: 0.9272 - val_accuracy: 0.8688\n",
      "Epoch 2112/2500\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.1172 - accuracy: 0.9503 - val_loss: 0.9065 - val_accuracy: 0.8659\n",
      "Epoch 2113/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0961 - accuracy: 0.9591 - val_loss: 0.9343 - val_accuracy: 0.8805\n",
      "Epoch 2114/2500\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 0.0989 - accuracy: 0.9591 - val_loss: 0.9695 - val_accuracy: 0.8571\n",
      "Epoch 2115/2500\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.0957 - accuracy: 0.9518 - val_loss: 1.0003 - val_accuracy: 0.8542\n",
      "Epoch 2116/2500\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.0903 - accuracy: 0.9591 - val_loss: 1.0135 - val_accuracy: 0.8717\n",
      "Epoch 2117/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.0853 - accuracy: 0.9606 - val_loss: 1.0094 - val_accuracy: 0.8717\n",
      "Epoch 2118/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.0961 - accuracy: 0.9540 - val_loss: 0.9864 - val_accuracy: 0.8659\n",
      "Epoch 2119/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0835 - accuracy: 0.9613 - val_loss: 1.0015 - val_accuracy: 0.8746\n",
      "Epoch 2120/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.0973 - accuracy: 0.9540 - val_loss: 0.9743 - val_accuracy: 0.8717\n",
      "Epoch 2121/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.0846 - accuracy: 0.9627 - val_loss: 0.9780 - val_accuracy: 0.8659\n",
      "Epoch 2122/2500\n",
      "18/18 [==============================] - 1s 28ms/step - loss: 0.0894 - accuracy: 0.9576 - val_loss: 0.9953 - val_accuracy: 0.8776\n",
      "Epoch 2123/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.0897 - accuracy: 0.9576 - val_loss: 0.9990 - val_accuracy: 0.8746\n",
      "Epoch 2124/2500\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.0942 - accuracy: 0.9562 - val_loss: 0.9940 - val_accuracy: 0.8688\n",
      "Epoch 2125/2500\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 0.0915 - accuracy: 0.9591 - val_loss: 0.9862 - val_accuracy: 0.8805\n",
      "Epoch 2126/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0878 - accuracy: 0.9598 - val_loss: 0.9822 - val_accuracy: 0.8805\n",
      "Epoch 2127/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0933 - accuracy: 0.9606 - val_loss: 0.9712 - val_accuracy: 0.8805\n",
      "Epoch 2128/2500\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.1090 - accuracy: 0.9554 - val_loss: 0.9596 - val_accuracy: 0.8834\n",
      "Epoch 2129/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0846 - accuracy: 0.9606 - val_loss: 0.9999 - val_accuracy: 0.8746\n",
      "Epoch 2130/2500\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 0.0943 - accuracy: 0.9540 - val_loss: 0.9785 - val_accuracy: 0.8746\n",
      "Epoch 2131/2500\n",
      "18/18 [==============================] - 1s 34ms/step - loss: 0.0893 - accuracy: 0.9562 - val_loss: 0.9809 - val_accuracy: 0.8776\n",
      "Epoch 2132/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0872 - accuracy: 0.9584 - val_loss: 0.9711 - val_accuracy: 0.8805\n",
      "Epoch 2133/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0953 - accuracy: 0.9518 - val_loss: 0.9902 - val_accuracy: 0.8630\n",
      "Epoch 2134/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0907 - accuracy: 0.9547 - val_loss: 0.9938 - val_accuracy: 0.8717\n",
      "Epoch 2135/2500\n",
      "18/18 [==============================] - 1s 27ms/step - loss: 0.0872 - accuracy: 0.9591 - val_loss: 0.9922 - val_accuracy: 0.8717\n",
      "Epoch 2136/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0819 - accuracy: 0.9620 - val_loss: 0.9930 - val_accuracy: 0.8746\n",
      "Epoch 2137/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1042 - accuracy: 0.9540 - val_loss: 1.0099 - val_accuracy: 0.8659\n",
      "Epoch 2138/2500\n",
      "18/18 [==============================] - 1s 33ms/step - loss: 0.0892 - accuracy: 0.9613 - val_loss: 1.0395 - val_accuracy: 0.8484\n",
      "Epoch 2139/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0823 - accuracy: 0.9620 - val_loss: 1.0446 - val_accuracy: 0.8688\n",
      "Epoch 2140/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0979 - accuracy: 0.9533 - val_loss: 1.0151 - val_accuracy: 0.8776\n",
      "Epoch 2141/2500\n",
      "18/18 [==============================] - 0s 28ms/step - loss: 0.1032 - accuracy: 0.9533 - val_loss: 1.0240 - val_accuracy: 0.8834\n",
      "Epoch 2142/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0985 - accuracy: 0.9591 - val_loss: 1.0260 - val_accuracy: 0.8805\n",
      "Epoch 2143/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0947 - accuracy: 0.9525 - val_loss: 1.0019 - val_accuracy: 0.8746\n",
      "Epoch 2144/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0933 - accuracy: 0.9540 - val_loss: 0.9597 - val_accuracy: 0.8688\n",
      "Epoch 2145/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.0976 - accuracy: 0.9584 - val_loss: 1.0265 - val_accuracy: 0.8746\n",
      "Epoch 2146/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0911 - accuracy: 0.9569 - val_loss: 1.0199 - val_accuracy: 0.8863\n",
      "Epoch 2147/2500\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.0931 - accuracy: 0.9518 - val_loss: 1.0043 - val_accuracy: 0.8805\n",
      "Epoch 2148/2500\n",
      "18/18 [==============================] - 0s 28ms/step - loss: 0.0915 - accuracy: 0.9562 - val_loss: 1.0303 - val_accuracy: 0.8834\n",
      "Epoch 2149/2500\n",
      "18/18 [==============================] - 1s 33ms/step - loss: 0.0966 - accuracy: 0.9562 - val_loss: 1.0322 - val_accuracy: 0.8776\n",
      "Epoch 2150/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0953 - accuracy: 0.9518 - val_loss: 1.0429 - val_accuracy: 0.8688\n",
      "Epoch 2151/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.1011 - accuracy: 0.9547 - val_loss: 1.0081 - val_accuracy: 0.8776\n",
      "Epoch 2152/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1049 - accuracy: 0.9525 - val_loss: 1.0008 - val_accuracy: 0.8630\n",
      "Epoch 2153/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0989 - accuracy: 0.9562 - val_loss: 0.9838 - val_accuracy: 0.8834\n",
      "Epoch 2154/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.0901 - accuracy: 0.9606 - val_loss: 0.9933 - val_accuracy: 0.8717\n",
      "Epoch 2155/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0890 - accuracy: 0.9606 - val_loss: 0.9981 - val_accuracy: 0.8805\n",
      "Epoch 2156/2500\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 0.0867 - accuracy: 0.9606 - val_loss: 1.0028 - val_accuracy: 0.8746\n",
      "Epoch 2157/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0834 - accuracy: 0.9591 - val_loss: 1.0136 - val_accuracy: 0.8776\n",
      "Epoch 2158/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0913 - accuracy: 0.9554 - val_loss: 0.9849 - val_accuracy: 0.8630\n",
      "Epoch 2159/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.0815 - accuracy: 0.9620 - val_loss: 0.9960 - val_accuracy: 0.8659\n",
      "Epoch 2160/2500\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 0.0958 - accuracy: 0.9576 - val_loss: 0.9865 - val_accuracy: 0.8776\n",
      "Epoch 2161/2500\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.0860 - accuracy: 0.9584 - val_loss: 0.9607 - val_accuracy: 0.8863\n",
      "Epoch 2162/2500\n",
      "18/18 [==============================] - 1s 33ms/step - loss: 0.0974 - accuracy: 0.9547 - val_loss: 0.9638 - val_accuracy: 0.8717\n",
      "Epoch 2163/2500\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.1005 - accuracy: 0.9569 - val_loss: 0.9867 - val_accuracy: 0.8601\n",
      "Epoch 2164/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.0861 - accuracy: 0.9598 - val_loss: 0.9774 - val_accuracy: 0.8746\n",
      "Epoch 2165/2500\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.1024 - accuracy: 0.9525 - val_loss: 0.9734 - val_accuracy: 0.8746\n",
      "Epoch 2166/2500\n",
      "18/18 [==============================] - 1s 33ms/step - loss: 0.0864 - accuracy: 0.9591 - val_loss: 0.9763 - val_accuracy: 0.8834\n",
      "Epoch 2167/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0881 - accuracy: 0.9606 - val_loss: 0.9493 - val_accuracy: 0.8717\n",
      "Epoch 2168/2500\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.0981 - accuracy: 0.9533 - val_loss: 0.9628 - val_accuracy: 0.8717\n",
      "Epoch 2169/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.0892 - accuracy: 0.9554 - val_loss: 0.9871 - val_accuracy: 0.8776\n",
      "Epoch 2170/2500\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.0896 - accuracy: 0.9562 - val_loss: 0.9939 - val_accuracy: 0.8630\n",
      "Epoch 2171/2500\n",
      "18/18 [==============================] - 0s 28ms/step - loss: 0.0905 - accuracy: 0.9613 - val_loss: 1.0037 - val_accuracy: 0.8717\n",
      "Epoch 2172/2500\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.0906 - accuracy: 0.9547 - val_loss: 1.0030 - val_accuracy: 0.8805\n",
      "Epoch 2173/2500\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.0967 - accuracy: 0.9576 - val_loss: 0.9939 - val_accuracy: 0.8863\n",
      "Epoch 2174/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.0986 - accuracy: 0.9584 - val_loss: 0.9947 - val_accuracy: 0.8746\n",
      "Epoch 2175/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1000 - accuracy: 0.9547 - val_loss: 0.9955 - val_accuracy: 0.8805\n",
      "Epoch 2176/2500\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.0942 - accuracy: 0.9540 - val_loss: 0.9980 - val_accuracy: 0.8776\n",
      "Epoch 2177/2500\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.0936 - accuracy: 0.9540 - val_loss: 0.9798 - val_accuracy: 0.8805\n",
      "Epoch 2178/2500\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.0894 - accuracy: 0.9569 - val_loss: 1.0026 - val_accuracy: 0.8776\n",
      "Epoch 2179/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1013 - accuracy: 0.9584 - val_loss: 1.0341 - val_accuracy: 0.8659\n",
      "Epoch 2180/2500\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.0990 - accuracy: 0.9554 - val_loss: 1.0111 - val_accuracy: 0.8834\n",
      "Epoch 2181/2500\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.0996 - accuracy: 0.9569 - val_loss: 1.0281 - val_accuracy: 0.8426\n",
      "Epoch 2182/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.1067 - accuracy: 0.9576 - val_loss: 0.9691 - val_accuracy: 0.8601\n",
      "Epoch 2183/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.1084 - accuracy: 0.9562 - val_loss: 0.9645 - val_accuracy: 0.8717\n",
      "Epoch 2184/2500\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.0927 - accuracy: 0.9562 - val_loss: 0.9569 - val_accuracy: 0.8776\n",
      "Epoch 2185/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.1014 - accuracy: 0.9547 - val_loss: 0.9433 - val_accuracy: 0.8542\n",
      "Epoch 2186/2500\n",
      "18/18 [==============================] - 1s 33ms/step - loss: 0.0972 - accuracy: 0.9576 - val_loss: 0.9437 - val_accuracy: 0.8746\n",
      "Epoch 2187/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.0968 - accuracy: 0.9606 - val_loss: 0.9337 - val_accuracy: 0.8863\n",
      "Epoch 2188/2500\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 0.0881 - accuracy: 0.9584 - val_loss: 0.9281 - val_accuracy: 0.8746\n",
      "Epoch 2189/2500\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.0938 - accuracy: 0.9576 - val_loss: 0.9488 - val_accuracy: 0.8805\n",
      "Epoch 2190/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0940 - accuracy: 0.9569 - val_loss: 0.9446 - val_accuracy: 0.8805\n",
      "Epoch 2191/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.1066 - accuracy: 0.9540 - val_loss: 0.9053 - val_accuracy: 0.8834\n",
      "Epoch 2192/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0832 - accuracy: 0.9613 - val_loss: 0.9036 - val_accuracy: 0.8805\n",
      "Epoch 2193/2500\n",
      "18/18 [==============================] - 1s 25ms/step - loss: 0.0969 - accuracy: 0.9562 - val_loss: 0.9201 - val_accuracy: 0.8863\n",
      "Epoch 2194/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1002 - accuracy: 0.9533 - val_loss: 0.8981 - val_accuracy: 0.8834\n",
      "Epoch 2195/2500\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.0961 - accuracy: 0.9591 - val_loss: 0.8840 - val_accuracy: 0.8717\n",
      "Epoch 2196/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0914 - accuracy: 0.9569 - val_loss: 0.8599 - val_accuracy: 0.8805\n",
      "Epoch 2197/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0946 - accuracy: 0.9540 - val_loss: 0.8589 - val_accuracy: 0.8776\n",
      "Epoch 2198/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0917 - accuracy: 0.9576 - val_loss: 0.8748 - val_accuracy: 0.8834\n",
      "Epoch 2199/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0925 - accuracy: 0.9569 - val_loss: 0.8887 - val_accuracy: 0.8805\n",
      "Epoch 2200/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0894 - accuracy: 0.9584 - val_loss: 0.9048 - val_accuracy: 0.8776\n",
      "Epoch 2201/2500\n",
      "18/18 [==============================] - 1s 34ms/step - loss: 0.1050 - accuracy: 0.9562 - val_loss: 0.9107 - val_accuracy: 0.8746\n",
      "Epoch 2202/2500\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.0897 - accuracy: 0.9576 - val_loss: 0.9126 - val_accuracy: 0.8805\n",
      "Epoch 2203/2500\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.0979 - accuracy: 0.9613 - val_loss: 0.9637 - val_accuracy: 0.8746\n",
      "Epoch 2204/2500\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.0984 - accuracy: 0.9562 - val_loss: 0.9220 - val_accuracy: 0.8805\n",
      "Epoch 2205/2500\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.0889 - accuracy: 0.9613 - val_loss: 0.9253 - val_accuracy: 0.8717\n",
      "Epoch 2206/2500\n",
      "18/18 [==============================] - 1s 33ms/step - loss: 0.0876 - accuracy: 0.9620 - val_loss: 0.9204 - val_accuracy: 0.8776\n",
      "Epoch 2207/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0839 - accuracy: 0.9591 - val_loss: 0.9460 - val_accuracy: 0.8688\n",
      "Epoch 2208/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0891 - accuracy: 0.9598 - val_loss: 0.9593 - val_accuracy: 0.8717\n",
      "Epoch 2209/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0853 - accuracy: 0.9598 - val_loss: 0.9691 - val_accuracy: 0.8717\n",
      "Epoch 2210/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.0852 - accuracy: 0.9627 - val_loss: 0.9667 - val_accuracy: 0.8863\n",
      "Epoch 2211/2500\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.0900 - accuracy: 0.9606 - val_loss: 0.9705 - val_accuracy: 0.8746\n",
      "Epoch 2212/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1002 - accuracy: 0.9569 - val_loss: 0.9493 - val_accuracy: 0.8834\n",
      "Epoch 2213/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0942 - accuracy: 0.9562 - val_loss: 0.9616 - val_accuracy: 0.8776\n",
      "Epoch 2214/2500\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.1030 - accuracy: 0.9533 - val_loss: 0.9958 - val_accuracy: 0.8630\n",
      "Epoch 2215/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0986 - accuracy: 0.9525 - val_loss: 0.9915 - val_accuracy: 0.8717\n",
      "Epoch 2216/2500\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.0948 - accuracy: 0.9606 - val_loss: 0.9613 - val_accuracy: 0.8834\n",
      "Epoch 2217/2500\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.0990 - accuracy: 0.9525 - val_loss: 0.9564 - val_accuracy: 0.8892\n",
      "Epoch 2218/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.0989 - accuracy: 0.9569 - val_loss: 0.9726 - val_accuracy: 0.8834\n",
      "Epoch 2219/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1034 - accuracy: 0.9576 - val_loss: 0.9963 - val_accuracy: 0.8717\n",
      "Epoch 2220/2500\n",
      "18/18 [==============================] - 1s 33ms/step - loss: 0.1035 - accuracy: 0.9554 - val_loss: 0.9688 - val_accuracy: 0.8659\n",
      "Epoch 2221/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.0948 - accuracy: 0.9569 - val_loss: 0.9749 - val_accuracy: 0.8688\n",
      "Epoch 2222/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0961 - accuracy: 0.9562 - val_loss: 0.9613 - val_accuracy: 0.8805\n",
      "Epoch 2223/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0911 - accuracy: 0.9576 - val_loss: 0.9432 - val_accuracy: 0.8776\n",
      "Epoch 2224/2500\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 0.1022 - accuracy: 0.9525 - val_loss: 0.9572 - val_accuracy: 0.8776\n",
      "Epoch 2225/2500\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.0934 - accuracy: 0.9598 - val_loss: 0.9523 - val_accuracy: 0.8717\n",
      "Epoch 2226/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0975 - accuracy: 0.9525 - val_loss: 0.9405 - val_accuracy: 0.8805\n",
      "Epoch 2227/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0927 - accuracy: 0.9547 - val_loss: 0.9302 - val_accuracy: 0.8746\n",
      "Epoch 2228/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.0870 - accuracy: 0.9591 - val_loss: 0.9243 - val_accuracy: 0.8776\n",
      "Epoch 2229/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0921 - accuracy: 0.9576 - val_loss: 0.9417 - val_accuracy: 0.8776\n",
      "Epoch 2230/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0887 - accuracy: 0.9591 - val_loss: 0.9356 - val_accuracy: 0.8776\n",
      "Epoch 2231/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.0913 - accuracy: 0.9591 - val_loss: 0.9264 - val_accuracy: 0.8688\n",
      "Epoch 2232/2500\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.0930 - accuracy: 0.9518 - val_loss: 0.9379 - val_accuracy: 0.8834\n",
      "Epoch 2233/2500\n",
      "18/18 [==============================] - 1s 33ms/step - loss: 0.0866 - accuracy: 0.9569 - val_loss: 0.9454 - val_accuracy: 0.8746\n",
      "Epoch 2234/2500\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.0961 - accuracy: 0.9562 - val_loss: 0.9388 - val_accuracy: 0.8834\n",
      "Epoch 2235/2500\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.0899 - accuracy: 0.9540 - val_loss: 0.9371 - val_accuracy: 0.8805\n",
      "Epoch 2236/2500\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.0898 - accuracy: 0.9562 - val_loss: 0.9730 - val_accuracy: 0.8484\n",
      "Epoch 2237/2500\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.0901 - accuracy: 0.9576 - val_loss: 0.9700 - val_accuracy: 0.8776\n",
      "Epoch 2238/2500\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.0897 - accuracy: 0.9562 - val_loss: 0.9689 - val_accuracy: 0.8805\n",
      "Epoch 2239/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0927 - accuracy: 0.9635 - val_loss: 0.9802 - val_accuracy: 0.8717\n",
      "Epoch 2240/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.0950 - accuracy: 0.9554 - val_loss: 0.9412 - val_accuracy: 0.8863\n",
      "Epoch 2241/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.0938 - accuracy: 0.9576 - val_loss: 0.9455 - val_accuracy: 0.8834\n",
      "Epoch 2242/2500\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.0797 - accuracy: 0.9642 - val_loss: 0.9426 - val_accuracy: 0.8776\n",
      "Epoch 2243/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.0842 - accuracy: 0.9635 - val_loss: 0.9586 - val_accuracy: 0.8834\n",
      "Epoch 2244/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0912 - accuracy: 0.9620 - val_loss: 0.9655 - val_accuracy: 0.8717\n",
      "Epoch 2245/2500\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.0861 - accuracy: 0.9598 - val_loss: 0.9794 - val_accuracy: 0.8746\n",
      "Epoch 2246/2500\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.1005 - accuracy: 0.9533 - val_loss: 0.9757 - val_accuracy: 0.8834\n",
      "Epoch 2247/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0870 - accuracy: 0.9569 - val_loss: 0.9789 - val_accuracy: 0.8746\n",
      "Epoch 2248/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0858 - accuracy: 0.9562 - val_loss: 0.9864 - val_accuracy: 0.8805\n",
      "Epoch 2249/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.0815 - accuracy: 0.9598 - val_loss: 0.9650 - val_accuracy: 0.8834\n",
      "Epoch 2250/2500\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.0937 - accuracy: 0.9584 - val_loss: 0.9726 - val_accuracy: 0.8746\n",
      "Epoch 2251/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0890 - accuracy: 0.9569 - val_loss: 0.9671 - val_accuracy: 0.8805\n",
      "Epoch 2252/2500\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.0963 - accuracy: 0.9511 - val_loss: 0.9543 - val_accuracy: 0.8688\n",
      "Epoch 2253/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.0867 - accuracy: 0.9547 - val_loss: 0.9510 - val_accuracy: 0.8863\n",
      "Epoch 2254/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0985 - accuracy: 0.9584 - val_loss: 0.9745 - val_accuracy: 0.8630\n",
      "Epoch 2255/2500\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.0907 - accuracy: 0.9540 - val_loss: 0.9632 - val_accuracy: 0.8776\n",
      "Epoch 2256/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0852 - accuracy: 0.9613 - val_loss: 0.9846 - val_accuracy: 0.8746\n",
      "Epoch 2257/2500\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.0857 - accuracy: 0.9642 - val_loss: 0.9597 - val_accuracy: 0.8805\n",
      "Epoch 2258/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0841 - accuracy: 0.9598 - val_loss: 0.9543 - val_accuracy: 0.8834\n",
      "Epoch 2259/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.0903 - accuracy: 0.9518 - val_loss: 0.9922 - val_accuracy: 0.8834\n",
      "Epoch 2260/2500\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.0877 - accuracy: 0.9584 - val_loss: 1.0138 - val_accuracy: 0.8601\n",
      "Epoch 2261/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0816 - accuracy: 0.9576 - val_loss: 0.9894 - val_accuracy: 0.8746\n",
      "Epoch 2262/2500\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.0867 - accuracy: 0.9591 - val_loss: 1.0018 - val_accuracy: 0.8805\n",
      "Epoch 2263/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0850 - accuracy: 0.9627 - val_loss: 0.9989 - val_accuracy: 0.8630\n",
      "Epoch 2264/2500\n",
      "18/18 [==============================] - 1s 27ms/step - loss: 0.0977 - accuracy: 0.9554 - val_loss: 0.9798 - val_accuracy: 0.8717\n",
      "Epoch 2265/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0908 - accuracy: 0.9525 - val_loss: 0.9844 - val_accuracy: 0.8776\n",
      "Epoch 2266/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0810 - accuracy: 0.9606 - val_loss: 0.9686 - val_accuracy: 0.8834\n",
      "Epoch 2267/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0871 - accuracy: 0.9591 - val_loss: 0.9766 - val_accuracy: 0.8863\n",
      "Epoch 2268/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0858 - accuracy: 0.9584 - val_loss: 0.9841 - val_accuracy: 0.8834\n",
      "Epoch 2269/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0864 - accuracy: 0.9554 - val_loss: 0.9699 - val_accuracy: 0.8746\n",
      "Epoch 2270/2500\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.0924 - accuracy: 0.9591 - val_loss: 0.9798 - val_accuracy: 0.8776\n",
      "Epoch 2271/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0855 - accuracy: 0.9606 - val_loss: 0.9737 - val_accuracy: 0.8746\n",
      "Epoch 2272/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.0896 - accuracy: 0.9547 - val_loss: 0.9859 - val_accuracy: 0.8776\n",
      "Epoch 2273/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1004 - accuracy: 0.9576 - val_loss: 0.9666 - val_accuracy: 0.8659\n",
      "Epoch 2274/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.0897 - accuracy: 0.9584 - val_loss: 0.9346 - val_accuracy: 0.8776\n",
      "Epoch 2275/2500\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 0.0968 - accuracy: 0.9598 - val_loss: 0.9527 - val_accuracy: 0.8776\n",
      "Epoch 2276/2500\n",
      "18/18 [==============================] - 0s 28ms/step - loss: 0.0907 - accuracy: 0.9569 - val_loss: 0.9719 - val_accuracy: 0.8746\n",
      "Epoch 2277/2500\n",
      "18/18 [==============================] - 1s 33ms/step - loss: 0.0956 - accuracy: 0.9562 - val_loss: 0.9872 - val_accuracy: 0.8717\n",
      "Epoch 2278/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0857 - accuracy: 0.9569 - val_loss: 0.9876 - val_accuracy: 0.8688\n",
      "Epoch 2279/2500\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.0916 - accuracy: 0.9569 - val_loss: 0.9836 - val_accuracy: 0.8659\n",
      "Epoch 2280/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.0881 - accuracy: 0.9613 - val_loss: 0.9948 - val_accuracy: 0.8717\n",
      "Epoch 2281/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0873 - accuracy: 0.9584 - val_loss: 1.0379 - val_accuracy: 0.8659\n",
      "Epoch 2282/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0818 - accuracy: 0.9591 - val_loss: 1.0242 - val_accuracy: 0.8776\n",
      "Epoch 2283/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.0928 - accuracy: 0.9569 - val_loss: 1.0757 - val_accuracy: 0.8688\n",
      "Epoch 2284/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1002 - accuracy: 0.9562 - val_loss: 1.0191 - val_accuracy: 0.8601\n",
      "Epoch 2285/2500\n",
      "18/18 [==============================] - 1s 25ms/step - loss: 0.1045 - accuracy: 0.9576 - val_loss: 1.0006 - val_accuracy: 0.8455\n",
      "Epoch 2286/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1014 - accuracy: 0.9554 - val_loss: 0.9916 - val_accuracy: 0.8688\n",
      "Epoch 2287/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.0967 - accuracy: 0.9525 - val_loss: 1.0084 - val_accuracy: 0.8601\n",
      "Epoch 2288/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1001 - accuracy: 0.9554 - val_loss: 1.0115 - val_accuracy: 0.8717\n",
      "Epoch 2289/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0955 - accuracy: 0.9547 - val_loss: 0.9947 - val_accuracy: 0.8717\n",
      "Epoch 2290/2500\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.0847 - accuracy: 0.9576 - val_loss: 1.0077 - val_accuracy: 0.8571\n",
      "Epoch 2291/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0836 - accuracy: 0.9569 - val_loss: 1.0082 - val_accuracy: 0.8659\n",
      "Epoch 2292/2500\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.0914 - accuracy: 0.9569 - val_loss: 0.9918 - val_accuracy: 0.8805\n",
      "Epoch 2293/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.0885 - accuracy: 0.9591 - val_loss: 0.9978 - val_accuracy: 0.8921\n",
      "Epoch 2294/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0966 - accuracy: 0.9525 - val_loss: 1.0015 - val_accuracy: 0.8863\n",
      "Epoch 2295/2500\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.1028 - accuracy: 0.9503 - val_loss: 0.9961 - val_accuracy: 0.8776\n",
      "Epoch 2296/2500\n",
      "18/18 [==============================] - 1s 33ms/step - loss: 0.0973 - accuracy: 0.9554 - val_loss: 0.9686 - val_accuracy: 0.8717\n",
      "Epoch 2297/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1020 - accuracy: 0.9525 - val_loss: 0.9491 - val_accuracy: 0.8746\n",
      "Epoch 2298/2500\n",
      "18/18 [==============================] - 0s 28ms/step - loss: 0.0938 - accuracy: 0.9562 - val_loss: 0.9254 - val_accuracy: 0.8659\n",
      "Epoch 2299/2500\n",
      "18/18 [==============================] - 1s 33ms/step - loss: 0.0903 - accuracy: 0.9562 - val_loss: 0.9443 - val_accuracy: 0.8834\n",
      "Epoch 2300/2500\n",
      "18/18 [==============================] - 1s 33ms/step - loss: 0.1124 - accuracy: 0.9503 - val_loss: 0.9279 - val_accuracy: 0.8746\n",
      "Epoch 2301/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.1030 - accuracy: 0.9503 - val_loss: 0.9012 - val_accuracy: 0.8630\n",
      "Epoch 2302/2500\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 0.0892 - accuracy: 0.9562 - val_loss: 0.9004 - val_accuracy: 0.8717\n",
      "Epoch 2303/2500\n",
      "18/18 [==============================] - 1s 33ms/step - loss: 0.0902 - accuracy: 0.9584 - val_loss: 0.9141 - val_accuracy: 0.8746\n",
      "Epoch 2304/2500\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.0874 - accuracy: 0.9576 - val_loss: 0.9352 - val_accuracy: 0.8805\n",
      "Epoch 2305/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0925 - accuracy: 0.9562 - val_loss: 0.9364 - val_accuracy: 0.8834\n",
      "Epoch 2306/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0882 - accuracy: 0.9540 - val_loss: 0.9328 - val_accuracy: 0.8746\n",
      "Epoch 2307/2500\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.0834 - accuracy: 0.9606 - val_loss: 0.9368 - val_accuracy: 0.8776\n",
      "Epoch 2308/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.0867 - accuracy: 0.9584 - val_loss: 0.9489 - val_accuracy: 0.8776\n",
      "Epoch 2309/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0871 - accuracy: 0.9584 - val_loss: 0.9510 - val_accuracy: 0.8805\n",
      "Epoch 2310/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.0922 - accuracy: 0.9533 - val_loss: 0.9640 - val_accuracy: 0.8776\n",
      "Epoch 2311/2500\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.0859 - accuracy: 0.9613 - val_loss: 0.9613 - val_accuracy: 0.8688\n",
      "Epoch 2312/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0854 - accuracy: 0.9584 - val_loss: 0.9805 - val_accuracy: 0.8601\n",
      "Epoch 2313/2500\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.0949 - accuracy: 0.9511 - val_loss: 0.9646 - val_accuracy: 0.8688\n",
      "Epoch 2314/2500\n",
      "18/18 [==============================] - 1s 33ms/step - loss: 0.0894 - accuracy: 0.9562 - val_loss: 0.9510 - val_accuracy: 0.8630\n",
      "Epoch 2315/2500\n",
      "18/18 [==============================] - 1s 34ms/step - loss: 0.0883 - accuracy: 0.9584 - val_loss: 0.9746 - val_accuracy: 0.8659\n",
      "Epoch 2316/2500\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.0952 - accuracy: 0.9613 - val_loss: 0.9780 - val_accuracy: 0.8630\n",
      "Epoch 2317/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0912 - accuracy: 0.9635 - val_loss: 0.9172 - val_accuracy: 0.8630\n",
      "Epoch 2318/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.0918 - accuracy: 0.9547 - val_loss: 0.9388 - val_accuracy: 0.8688\n",
      "Epoch 2319/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0862 - accuracy: 0.9598 - val_loss: 0.9454 - val_accuracy: 0.8776\n",
      "Epoch 2320/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0841 - accuracy: 0.9591 - val_loss: 0.9309 - val_accuracy: 0.8746\n",
      "Epoch 2321/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0828 - accuracy: 0.9576 - val_loss: 0.9179 - val_accuracy: 0.8863\n",
      "Epoch 2322/2500\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.0898 - accuracy: 0.9540 - val_loss: 0.9486 - val_accuracy: 0.8659\n",
      "Epoch 2323/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0842 - accuracy: 0.9598 - val_loss: 0.9339 - val_accuracy: 0.8717\n",
      "Epoch 2324/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.0939 - accuracy: 0.9584 - val_loss: 0.9396 - val_accuracy: 0.8834\n",
      "Epoch 2325/2500\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.0869 - accuracy: 0.9554 - val_loss: 0.9793 - val_accuracy: 0.8717\n",
      "Epoch 2326/2500\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.0978 - accuracy: 0.9613 - val_loss: 0.9710 - val_accuracy: 0.8746\n",
      "Epoch 2327/2500\n",
      "18/18 [==============================] - 1s 33ms/step - loss: 0.0884 - accuracy: 0.9554 - val_loss: 0.9753 - val_accuracy: 0.8717\n",
      "Epoch 2328/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0993 - accuracy: 0.9576 - val_loss: 0.9931 - val_accuracy: 0.8746\n",
      "Epoch 2329/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0980 - accuracy: 0.9606 - val_loss: 0.9716 - val_accuracy: 0.8863\n",
      "Epoch 2330/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.1034 - accuracy: 0.9511 - val_loss: 1.0020 - val_accuracy: 0.8630\n",
      "Epoch 2331/2500\n",
      "18/18 [==============================] - 1s 28ms/step - loss: 0.0933 - accuracy: 0.9518 - val_loss: 1.0231 - val_accuracy: 0.8630\n",
      "Epoch 2332/2500\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 0.0923 - accuracy: 0.9525 - val_loss: 1.0163 - val_accuracy: 0.8805\n",
      "Epoch 2333/2500\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.0944 - accuracy: 0.9547 - val_loss: 1.0323 - val_accuracy: 0.8746\n",
      "Epoch 2334/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.0914 - accuracy: 0.9591 - val_loss: 0.9969 - val_accuracy: 0.8659\n",
      "Epoch 2335/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.0978 - accuracy: 0.9569 - val_loss: 0.9927 - val_accuracy: 0.8630\n",
      "Epoch 2336/2500\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.0846 - accuracy: 0.9606 - val_loss: 1.0146 - val_accuracy: 0.8659\n",
      "Epoch 2337/2500\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.0862 - accuracy: 0.9584 - val_loss: 1.0098 - val_accuracy: 0.8717\n",
      "Epoch 2338/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0945 - accuracy: 0.9525 - val_loss: 1.0220 - val_accuracy: 0.8659\n",
      "Epoch 2339/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.0948 - accuracy: 0.9547 - val_loss: 1.0223 - val_accuracy: 0.8688\n",
      "Epoch 2340/2500\n",
      "18/18 [==============================] - 1s 33ms/step - loss: 0.0921 - accuracy: 0.9562 - val_loss: 1.0059 - val_accuracy: 0.8776\n",
      "Epoch 2341/2500\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.0929 - accuracy: 0.9598 - val_loss: 1.0076 - val_accuracy: 0.8717\n",
      "Epoch 2342/2500\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.0887 - accuracy: 0.9591 - val_loss: 0.9834 - val_accuracy: 0.8746\n",
      "Epoch 2343/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.0931 - accuracy: 0.9540 - val_loss: 0.9754 - val_accuracy: 0.8834\n",
      "Epoch 2344/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.0993 - accuracy: 0.9584 - val_loss: 0.9806 - val_accuracy: 0.8834\n",
      "Epoch 2345/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.0836 - accuracy: 0.9679 - val_loss: 0.9818 - val_accuracy: 0.8834\n",
      "Epoch 2346/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.0836 - accuracy: 0.9642 - val_loss: 0.9581 - val_accuracy: 0.8805\n",
      "Epoch 2347/2500\n",
      "18/18 [==============================] - 1s 33ms/step - loss: 0.0856 - accuracy: 0.9584 - val_loss: 0.9537 - val_accuracy: 0.8688\n",
      "Epoch 2348/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0923 - accuracy: 0.9606 - val_loss: 0.9517 - val_accuracy: 0.8776\n",
      "Epoch 2349/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0981 - accuracy: 0.9503 - val_loss: 0.9648 - val_accuracy: 0.8746\n",
      "Epoch 2350/2500\n",
      "18/18 [==============================] - 1s 33ms/step - loss: 0.0971 - accuracy: 0.9547 - val_loss: 0.9777 - val_accuracy: 0.8746\n",
      "Epoch 2351/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0963 - accuracy: 0.9481 - val_loss: 1.0002 - val_accuracy: 0.8746\n",
      "Epoch 2352/2500\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 0.0903 - accuracy: 0.9584 - val_loss: 1.0063 - val_accuracy: 0.8746\n",
      "Epoch 2353/2500\n",
      "18/18 [==============================] - 1s 33ms/step - loss: 0.0955 - accuracy: 0.9562 - val_loss: 1.0096 - val_accuracy: 0.8688\n",
      "Epoch 2354/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0936 - accuracy: 0.9591 - val_loss: 0.9931 - val_accuracy: 0.8834\n",
      "Epoch 2355/2500\n",
      "18/18 [==============================] - 1s 28ms/step - loss: 0.0814 - accuracy: 0.9613 - val_loss: 1.0091 - val_accuracy: 0.8805\n",
      "Epoch 2356/2500\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.0970 - accuracy: 0.9525 - val_loss: 1.0090 - val_accuracy: 0.8717\n",
      "Epoch 2357/2500\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.0929 - accuracy: 0.9591 - val_loss: 1.0278 - val_accuracy: 0.8746\n",
      "Epoch 2358/2500\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.0809 - accuracy: 0.9635 - val_loss: 1.0167 - val_accuracy: 0.8776\n",
      "Epoch 2359/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.0892 - accuracy: 0.9562 - val_loss: 1.0130 - val_accuracy: 0.8805\n",
      "Epoch 2360/2500\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.0858 - accuracy: 0.9569 - val_loss: 1.0117 - val_accuracy: 0.8776\n",
      "Epoch 2361/2500\n",
      "18/18 [==============================] - 1s 33ms/step - loss: 0.0897 - accuracy: 0.9569 - val_loss: 0.9993 - val_accuracy: 0.8746\n",
      "Epoch 2362/2500\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.0905 - accuracy: 0.9554 - val_loss: 0.9936 - val_accuracy: 0.8746\n",
      "Epoch 2363/2500\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 0.0807 - accuracy: 0.9606 - val_loss: 1.0081 - val_accuracy: 0.8688\n",
      "Epoch 2364/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.0839 - accuracy: 0.9620 - val_loss: 1.0062 - val_accuracy: 0.8717\n",
      "Epoch 2365/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.0853 - accuracy: 0.9598 - val_loss: 1.0278 - val_accuracy: 0.8601\n",
      "Epoch 2366/2500\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.0802 - accuracy: 0.9598 - val_loss: 1.0429 - val_accuracy: 0.8688\n",
      "Epoch 2367/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.0884 - accuracy: 0.9591 - val_loss: 1.0323 - val_accuracy: 0.8688\n",
      "Epoch 2368/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0874 - accuracy: 0.9518 - val_loss: 1.0268 - val_accuracy: 0.8776\n",
      "Epoch 2369/2500\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.0907 - accuracy: 0.9576 - val_loss: 1.0037 - val_accuracy: 0.8688\n",
      "Epoch 2370/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.0920 - accuracy: 0.9569 - val_loss: 0.9754 - val_accuracy: 0.8746\n",
      "Epoch 2371/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.0913 - accuracy: 0.9533 - val_loss: 0.9870 - val_accuracy: 0.8805\n",
      "Epoch 2372/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0823 - accuracy: 0.9591 - val_loss: 0.9726 - val_accuracy: 0.8688\n",
      "Epoch 2373/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.0860 - accuracy: 0.9620 - val_loss: 0.9636 - val_accuracy: 0.8776\n",
      "Epoch 2374/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.1012 - accuracy: 0.9547 - val_loss: 0.9739 - val_accuracy: 0.8717\n",
      "Epoch 2375/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0920 - accuracy: 0.9569 - val_loss: 0.9708 - val_accuracy: 0.8717\n",
      "Epoch 2376/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0865 - accuracy: 0.9598 - val_loss: 0.9969 - val_accuracy: 0.8630\n",
      "Epoch 2377/2500\n",
      "18/18 [==============================] - 1s 33ms/step - loss: 0.0844 - accuracy: 0.9627 - val_loss: 1.0149 - val_accuracy: 0.8659\n",
      "Epoch 2378/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0918 - accuracy: 0.9613 - val_loss: 0.9904 - val_accuracy: 0.8717\n",
      "Epoch 2379/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0897 - accuracy: 0.9606 - val_loss: 0.9823 - val_accuracy: 0.8630\n",
      "Epoch 2380/2500\n",
      "18/18 [==============================] - 1s 33ms/step - loss: 0.0922 - accuracy: 0.9569 - val_loss: 0.9843 - val_accuracy: 0.8630\n",
      "Epoch 2381/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0963 - accuracy: 0.9606 - val_loss: 0.9855 - val_accuracy: 0.8746\n",
      "Epoch 2382/2500\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 0.0968 - accuracy: 0.9547 - val_loss: 0.9622 - val_accuracy: 0.8717\n",
      "Epoch 2383/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0927 - accuracy: 0.9562 - val_loss: 0.9495 - val_accuracy: 0.8776\n",
      "Epoch 2384/2500\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.0931 - accuracy: 0.9540 - val_loss: 0.9483 - val_accuracy: 0.8805\n",
      "Epoch 2385/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.0893 - accuracy: 0.9584 - val_loss: 0.9733 - val_accuracy: 0.8746\n",
      "Epoch 2386/2500\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.0847 - accuracy: 0.9533 - val_loss: 0.9897 - val_accuracy: 0.8746\n",
      "Epoch 2387/2500\n",
      "18/18 [==============================] - 1s 33ms/step - loss: 0.1007 - accuracy: 0.9547 - val_loss: 0.9749 - val_accuracy: 0.8805\n",
      "Epoch 2388/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.0938 - accuracy: 0.9598 - val_loss: 0.9537 - val_accuracy: 0.8746\n",
      "Epoch 2389/2500\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.0916 - accuracy: 0.9569 - val_loss: 0.9540 - val_accuracy: 0.8746\n",
      "Epoch 2390/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0911 - accuracy: 0.9569 - val_loss: 0.9679 - val_accuracy: 0.8688\n",
      "Epoch 2391/2500\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.0830 - accuracy: 0.9591 - val_loss: 0.9751 - val_accuracy: 0.8776\n",
      "Epoch 2392/2500\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.0850 - accuracy: 0.9562 - val_loss: 1.0030 - val_accuracy: 0.8746\n",
      "Epoch 2393/2500\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.0960 - accuracy: 0.9598 - val_loss: 0.9782 - val_accuracy: 0.8688\n",
      "Epoch 2394/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0844 - accuracy: 0.9576 - val_loss: 0.9738 - val_accuracy: 0.8659\n",
      "Epoch 2395/2500\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.0906 - accuracy: 0.9576 - val_loss: 0.9633 - val_accuracy: 0.8659\n",
      "Epoch 2396/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0863 - accuracy: 0.9613 - val_loss: 0.9747 - val_accuracy: 0.8717\n",
      "Epoch 2397/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0928 - accuracy: 0.9584 - val_loss: 0.9876 - val_accuracy: 0.8776\n",
      "Epoch 2398/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0923 - accuracy: 0.9598 - val_loss: 0.9846 - val_accuracy: 0.8746\n",
      "Epoch 2399/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0901 - accuracy: 0.9569 - val_loss: 0.9426 - val_accuracy: 0.8688\n",
      "Epoch 2400/2500\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.0856 - accuracy: 0.9606 - val_loss: 0.9633 - val_accuracy: 0.8717\n",
      "Epoch 2401/2500\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.0826 - accuracy: 0.9606 - val_loss: 0.9647 - val_accuracy: 0.8717\n",
      "Epoch 2402/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0867 - accuracy: 0.9533 - val_loss: 0.9808 - val_accuracy: 0.8659\n",
      "Epoch 2403/2500\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.0854 - accuracy: 0.9642 - val_loss: 0.9872 - val_accuracy: 0.8659\n",
      "Epoch 2404/2500\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.0975 - accuracy: 0.9554 - val_loss: 0.9794 - val_accuracy: 0.8688\n",
      "Epoch 2405/2500\n",
      "18/18 [==============================] - 1s 28ms/step - loss: 0.0875 - accuracy: 0.9620 - val_loss: 0.9845 - val_accuracy: 0.8659\n",
      "Epoch 2406/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0952 - accuracy: 0.9533 - val_loss: 0.9744 - val_accuracy: 0.8601\n",
      "Epoch 2407/2500\n",
      "18/18 [==============================] - 1s 33ms/step - loss: 0.0945 - accuracy: 0.9584 - val_loss: 0.9799 - val_accuracy: 0.8746\n",
      "Epoch 2408/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0852 - accuracy: 0.9598 - val_loss: 0.9659 - val_accuracy: 0.8805\n",
      "Epoch 2409/2500\n",
      "18/18 [==============================] - 1s 33ms/step - loss: 0.0870 - accuracy: 0.9620 - val_loss: 0.9613 - val_accuracy: 0.8805\n",
      "Epoch 2410/2500\n",
      "18/18 [==============================] - 0s 28ms/step - loss: 0.0902 - accuracy: 0.9591 - val_loss: 0.9612 - val_accuracy: 0.8776\n",
      "Epoch 2411/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0832 - accuracy: 0.9620 - val_loss: 0.9658 - val_accuracy: 0.8863\n",
      "Epoch 2412/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0830 - accuracy: 0.9584 - val_loss: 0.9603 - val_accuracy: 0.8805\n",
      "Epoch 2413/2500\n",
      "18/18 [==============================] - 1s 33ms/step - loss: 0.0896 - accuracy: 0.9576 - val_loss: 1.0004 - val_accuracy: 0.8805\n",
      "Epoch 2414/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.0918 - accuracy: 0.9525 - val_loss: 1.0125 - val_accuracy: 0.8805\n",
      "Epoch 2415/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1079 - accuracy: 0.9584 - val_loss: 0.9919 - val_accuracy: 0.8659\n",
      "Epoch 2416/2500\n",
      "18/18 [==============================] - 1s 33ms/step - loss: 0.0918 - accuracy: 0.9591 - val_loss: 0.9731 - val_accuracy: 0.8659\n",
      "Epoch 2417/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0882 - accuracy: 0.9562 - val_loss: 0.9901 - val_accuracy: 0.8717\n",
      "Epoch 2418/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0918 - accuracy: 0.9525 - val_loss: 1.0009 - val_accuracy: 0.8630\n",
      "Epoch 2419/2500\n",
      "18/18 [==============================] - 1s 33ms/step - loss: 0.0918 - accuracy: 0.9533 - val_loss: 1.0304 - val_accuracy: 0.8659\n",
      "Epoch 2420/2500\n",
      "18/18 [==============================] - 1s 33ms/step - loss: 0.0868 - accuracy: 0.9562 - val_loss: 1.0254 - val_accuracy: 0.8659\n",
      "Epoch 2421/2500\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.0938 - accuracy: 0.9576 - val_loss: 1.0320 - val_accuracy: 0.8659\n",
      "Epoch 2422/2500\n",
      "18/18 [==============================] - 1s 33ms/step - loss: 0.0888 - accuracy: 0.9576 - val_loss: 1.0369 - val_accuracy: 0.8688\n",
      "Epoch 2423/2500\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.0931 - accuracy: 0.9598 - val_loss: 1.0365 - val_accuracy: 0.8717\n",
      "Epoch 2424/2500\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.0891 - accuracy: 0.9620 - val_loss: 1.0251 - val_accuracy: 0.8805\n",
      "Epoch 2425/2500\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.0876 - accuracy: 0.9606 - val_loss: 1.0247 - val_accuracy: 0.8805\n",
      "Epoch 2426/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0906 - accuracy: 0.9554 - val_loss: 1.0211 - val_accuracy: 0.8805\n",
      "Epoch 2427/2500\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.0902 - accuracy: 0.9598 - val_loss: 1.0227 - val_accuracy: 0.8688\n",
      "Epoch 2428/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0866 - accuracy: 0.9627 - val_loss: 1.0226 - val_accuracy: 0.8805\n",
      "Epoch 2429/2500\n",
      "18/18 [==============================] - 0s 28ms/step - loss: 0.0878 - accuracy: 0.9584 - val_loss: 1.0356 - val_accuracy: 0.8776\n",
      "Epoch 2430/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0892 - accuracy: 0.9554 - val_loss: 1.0516 - val_accuracy: 0.8834\n",
      "Epoch 2431/2500\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.0876 - accuracy: 0.9591 - val_loss: 1.0400 - val_accuracy: 0.8805\n",
      "Epoch 2432/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.0960 - accuracy: 0.9540 - val_loss: 1.0087 - val_accuracy: 0.8776\n",
      "Epoch 2433/2500\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.0856 - accuracy: 0.9606 - val_loss: 1.0040 - val_accuracy: 0.8746\n",
      "Epoch 2434/2500\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.0893 - accuracy: 0.9576 - val_loss: 1.0102 - val_accuracy: 0.8776\n",
      "Epoch 2435/2500\n",
      "18/18 [==============================] - 1s 33ms/step - loss: 0.0935 - accuracy: 0.9554 - val_loss: 1.0126 - val_accuracy: 0.8805\n",
      "Epoch 2436/2500\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.0923 - accuracy: 0.9584 - val_loss: 1.0169 - val_accuracy: 0.8834\n",
      "Epoch 2437/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0878 - accuracy: 0.9562 - val_loss: 0.9935 - val_accuracy: 0.8863\n",
      "Epoch 2438/2500\n",
      "18/18 [==============================] - 1s 34ms/step - loss: 0.0951 - accuracy: 0.9576 - val_loss: 1.0096 - val_accuracy: 0.8542\n",
      "Epoch 2439/2500\n",
      "18/18 [==============================] - 1s 34ms/step - loss: 0.0811 - accuracy: 0.9642 - val_loss: 1.0054 - val_accuracy: 0.8717\n",
      "Epoch 2440/2500\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.0833 - accuracy: 0.9606 - val_loss: 1.0127 - val_accuracy: 0.8776\n",
      "Epoch 2441/2500\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.0866 - accuracy: 0.9606 - val_loss: 1.0297 - val_accuracy: 0.8805\n",
      "Epoch 2442/2500\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.0851 - accuracy: 0.9627 - val_loss: 1.0272 - val_accuracy: 0.8805\n",
      "Epoch 2443/2500\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.0872 - accuracy: 0.9613 - val_loss: 1.0440 - val_accuracy: 0.8688\n",
      "Epoch 2444/2500\n",
      "18/18 [==============================] - 1s 33ms/step - loss: 0.0885 - accuracy: 0.9620 - val_loss: 1.0161 - val_accuracy: 0.8659\n",
      "Epoch 2445/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.0940 - accuracy: 0.9584 - val_loss: 1.0241 - val_accuracy: 0.8746\n",
      "Epoch 2446/2500\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.0911 - accuracy: 0.9584 - val_loss: 1.0338 - val_accuracy: 0.8776\n",
      "Epoch 2447/2500\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.1032 - accuracy: 0.9547 - val_loss: 1.0020 - val_accuracy: 0.8688\n",
      "Epoch 2448/2500\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.0891 - accuracy: 0.9554 - val_loss: 0.9964 - val_accuracy: 0.8717\n",
      "Epoch 2449/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0984 - accuracy: 0.9554 - val_loss: 0.9681 - val_accuracy: 0.8717\n",
      "Epoch 2450/2500\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.0887 - accuracy: 0.9606 - val_loss: 0.9852 - val_accuracy: 0.8776\n",
      "Epoch 2451/2500\n",
      "18/18 [==============================] - 1s 35ms/step - loss: 0.0922 - accuracy: 0.9613 - val_loss: 1.0014 - val_accuracy: 0.8717\n",
      "Epoch 2452/2500\n",
      "18/18 [==============================] - 1s 33ms/step - loss: 0.0852 - accuracy: 0.9569 - val_loss: 1.0379 - val_accuracy: 0.8746\n",
      "Epoch 2453/2500\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.0917 - accuracy: 0.9540 - val_loss: 1.0494 - val_accuracy: 0.8805\n",
      "Epoch 2454/2500\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.0875 - accuracy: 0.9554 - val_loss: 1.0567 - val_accuracy: 0.8805\n",
      "Epoch 2455/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0856 - accuracy: 0.9584 - val_loss: 1.0640 - val_accuracy: 0.8805\n",
      "Epoch 2456/2500\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.0906 - accuracy: 0.9576 - val_loss: 1.0497 - val_accuracy: 0.8834\n",
      "Epoch 2457/2500\n",
      "18/18 [==============================] - 1s 34ms/step - loss: 0.1059 - accuracy: 0.9576 - val_loss: 1.0253 - val_accuracy: 0.8834\n",
      "Epoch 2458/2500\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1056 - accuracy: 0.9511 - val_loss: 1.0220 - val_accuracy: 0.8717\n",
      "Epoch 2459/2500\n",
      "18/18 [==============================] - 1s 25ms/step - loss: 0.0895 - accuracy: 0.9591 - val_loss: 1.0413 - val_accuracy: 0.8834\n",
      "Epoch 2460/2500\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.0904 - accuracy: 0.9554 - val_loss: 1.0498 - val_accuracy: 0.8659\n",
      "Epoch 2461/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0797 - accuracy: 0.9627 - val_loss: 1.0425 - val_accuracy: 0.8688\n",
      "Epoch 2462/2500\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.0879 - accuracy: 0.9598 - val_loss: 1.0434 - val_accuracy: 0.8717\n",
      "Epoch 2463/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0827 - accuracy: 0.9620 - val_loss: 1.0735 - val_accuracy: 0.8746\n",
      "Epoch 2464/2500\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.0888 - accuracy: 0.9576 - val_loss: 1.0853 - val_accuracy: 0.8776\n",
      "Epoch 2465/2500\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.0936 - accuracy: 0.9584 - val_loss: 1.0643 - val_accuracy: 0.8834\n",
      "Epoch 2466/2500\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.0918 - accuracy: 0.9606 - val_loss: 1.0758 - val_accuracy: 0.8746\n",
      "Epoch 2467/2500\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.0886 - accuracy: 0.9606 - val_loss: 1.0843 - val_accuracy: 0.8746\n",
      "Epoch 2468/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0912 - accuracy: 0.9591 - val_loss: 1.0853 - val_accuracy: 0.8717\n",
      "Epoch 2469/2500\n",
      "18/18 [==============================] - 0s 28ms/step - loss: 0.0932 - accuracy: 0.9554 - val_loss: 1.1084 - val_accuracy: 0.8571\n",
      "Epoch 2470/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.0847 - accuracy: 0.9584 - val_loss: 1.1181 - val_accuracy: 0.8776\n",
      "Epoch 2471/2500\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.0882 - accuracy: 0.9562 - val_loss: 1.1385 - val_accuracy: 0.8746\n",
      "Epoch 2472/2500\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.0901 - accuracy: 0.9562 - val_loss: 1.0677 - val_accuracy: 0.8630\n",
      "Epoch 2473/2500\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 0.0925 - accuracy: 0.9533 - val_loss: 1.0418 - val_accuracy: 0.8717\n",
      "Epoch 2474/2500\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.0878 - accuracy: 0.9598 - val_loss: 1.0803 - val_accuracy: 0.8776\n",
      "Epoch 2475/2500\n",
      "18/18 [==============================] - 1s 33ms/step - loss: 0.1011 - accuracy: 0.9547 - val_loss: 1.0649 - val_accuracy: 0.8717\n",
      "Epoch 2476/2500\n",
      "18/18 [==============================] - 1s 33ms/step - loss: 0.1086 - accuracy: 0.9540 - val_loss: 1.0446 - val_accuracy: 0.8776\n",
      "Epoch 2477/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0870 - accuracy: 0.9635 - val_loss: 1.0776 - val_accuracy: 0.8834\n",
      "Epoch 2478/2500\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.0949 - accuracy: 0.9584 - val_loss: 1.0702 - val_accuracy: 0.8776\n",
      "Epoch 2479/2500\n",
      "18/18 [==============================] - 1s 33ms/step - loss: 0.0929 - accuracy: 0.9547 - val_loss: 1.0167 - val_accuracy: 0.8834\n",
      "Epoch 2480/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0841 - accuracy: 0.9613 - val_loss: 1.0211 - val_accuracy: 0.8805\n",
      "Epoch 2481/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0893 - accuracy: 0.9569 - val_loss: 1.0542 - val_accuracy: 0.8688\n",
      "Epoch 2482/2500\n",
      "18/18 [==============================] - 1s 33ms/step - loss: 0.0988 - accuracy: 0.9591 - val_loss: 1.0701 - val_accuracy: 0.8717\n",
      "Epoch 2483/2500\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.0922 - accuracy: 0.9554 - val_loss: 1.0233 - val_accuracy: 0.8688\n",
      "Epoch 2484/2500\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.0928 - accuracy: 0.9562 - val_loss: 1.0144 - val_accuracy: 0.8513\n",
      "Epoch 2485/2500\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.0907 - accuracy: 0.9627 - val_loss: 1.0343 - val_accuracy: 0.8688\n",
      "Epoch 2486/2500\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.0920 - accuracy: 0.9569 - val_loss: 1.0196 - val_accuracy: 0.8776\n",
      "Epoch 2487/2500\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.0847 - accuracy: 0.9591 - val_loss: 1.0280 - val_accuracy: 0.8805\n",
      "Epoch 2488/2500\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.1029 - accuracy: 0.9591 - val_loss: 1.0731 - val_accuracy: 0.8688\n",
      "Epoch 2489/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0945 - accuracy: 0.9591 - val_loss: 1.0391 - val_accuracy: 0.8834\n",
      "Epoch 2490/2500\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.0869 - accuracy: 0.9620 - val_loss: 1.0473 - val_accuracy: 0.8776\n",
      "Epoch 2491/2500\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.0826 - accuracy: 0.9591 - val_loss: 1.0225 - val_accuracy: 0.8776\n",
      "Epoch 2492/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0896 - accuracy: 0.9554 - val_loss: 1.0216 - val_accuracy: 0.8746\n",
      "Epoch 2493/2500\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.0804 - accuracy: 0.9627 - val_loss: 1.0176 - val_accuracy: 0.8717\n",
      "Epoch 2494/2500\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.0825 - accuracy: 0.9598 - val_loss: 1.0174 - val_accuracy: 0.8717\n",
      "Epoch 2495/2500\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0927 - accuracy: 0.9533 - val_loss: 0.9962 - val_accuracy: 0.8688\n",
      "Epoch 2496/2500\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.0933 - accuracy: 0.9620 - val_loss: 0.9801 - val_accuracy: 0.8688\n",
      "Epoch 2497/2500\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.0821 - accuracy: 0.9649 - val_loss: 1.0019 - val_accuracy: 0.8659\n",
      "Epoch 2498/2500\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.0846 - accuracy: 0.9569 - val_loss: 0.9929 - val_accuracy: 0.8776\n",
      "Epoch 2499/2500\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.0849 - accuracy: 0.9584 - val_loss: 1.0135 - val_accuracy: 0.8776\n",
      "Epoch 2500/2500\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.0883 - accuracy: 0.9569 - val_loss: 1.0424 - val_accuracy: 0.8776\n"
     ]
    }
   ],
   "source": [
    "# BUILD MODEL USING BEST PARAMETERS AND EVALUATE\n",
    "set_random_seed(42)\n",
    "best_model = model_builder(**best_model_params['build_params'])\n",
    "hist = best_model.fit(X_train, y_train, \n",
    "                      validation_data=(X_test, y_test), \n",
    "                      **best_model_params['fit_params'], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report on Training Data\n",
      "--------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         BCC       0.96      0.97      0.96       352\n",
      "         FCC       0.96      0.98      0.97       337\n",
      "     FCC_BCC       0.96      0.98      0.97       341\n",
      "         MIP       0.98      0.94      0.96       339\n",
      "\n",
      "    accuracy                           0.97      1369\n",
      "   macro avg       0.97      0.97      0.97      1369\n",
      "weighted avg       0.97      0.97      0.97      1369\n",
      "\n",
      "Classification Report on Test Data\n",
      "--------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         BCC       0.84      0.91      0.87        76\n",
      "         FCC       0.90      0.89      0.90        91\n",
      "     FCC_BCC       0.90      0.91      0.90        87\n",
      "         MIP       0.87      0.81      0.84        89\n",
      "\n",
      "    accuracy                           0.88       343\n",
      "   macro avg       0.88      0.88      0.88       343\n",
      "weighted avg       0.88      0.88      0.88       343\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "ROC-AUC SCORE:  95.444 %\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# CLASSIFICATION REPORTS\n",
    "y_train_argmax = np.argmax(y_train, axis=1)\n",
    "y_test_argmax = np.argmax(y_test, axis=1)\n",
    "y_pred_train = np.argmax(best_model.predict(X_train, verbose=0), axis=1)\n",
    "y_pred_test = np.argmax(best_model.predict(X_test, verbose=0), axis=1)\n",
    "\n",
    "\n",
    "print(\"Classification Report on Training Data\")\n",
    "print(\"-\"*80)\n",
    "print(classification_report(y_train_argmax, y_pred_train, target_names=labels))\n",
    "\n",
    "print(\"Classification Report on Test Data\")\n",
    "print(\"-\"*80)\n",
    "print(classification_report(y_test_argmax, y_pred_test, target_names=labels))\n",
    "\n",
    "# EVALUATE ROC-AUC SCORE \n",
    "pred_proba = best_model.predict(X_test, verbose=0)\n",
    "roc_auc = roc_auc_score(y_test, pred_proba, multi_class='ovr')\n",
    "print(\"-\"*80)\n",
    "print(f\"ROC-AUC SCORE: {roc_auc*100: .3f} %\")\n",
    "print(\"-\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# PLOT ROC CURVE\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "colors = cycle([\"red\", \"green\", \"blue\", \"orange\"])\n",
    "for class_id, color in zip(range(4), colors):\n",
    "    RocCurveDisplay.from_predictions(\n",
    "        y_test[:, class_id],\n",
    "        pred_proba[:, class_id],\n",
    "        name=f\"ROC curve for {labels[class_id]}\",\n",
    "        color=color,\n",
    "        ax=ax,\n",
    "    )\n",
    "ax.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "ax.legend(loc='lower right', fontsize='10')\n",
    "plt.title(\"ROC for each classes\")\n",
    "plt.savefig(pwd+\"/figures/nn_new_roc_curve.png\", dpi=600, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# CONFUSION MATRIX\n",
    "cm_train = confusion_matrix(y_train_argmax, y_pred_train)\n",
    "cm_test = confusion_matrix(y_test_argmax, y_pred_test)\n",
    "f,(ax1, ax2) = plt.subplots(1,2, figsize = (15,5))\n",
    "disp_train = ConfusionMatrixDisplay(confusion_matrix=cm_train, display_labels=labels)\n",
    "disp_test = ConfusionMatrixDisplay(confusion_matrix=cm_test, display_labels=labels)\n",
    "disp_train.plot(ax = ax1)\n",
    "disp_test.plot(ax = ax2)\n",
    "ax1.set_title('Training Set')\n",
    "ax2.set_title('Testing Set')\n",
    "ax1.grid(False)\n",
    "ax2.grid(False)\n",
    "plt.suptitle('Train and Test Confusion Matrix')\n",
    "plt.savefig(pwd+\"/figures/nn_new_cf.png\", dpi=600, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score\n",
      "--------------------------------------------------\n",
      "Mean Accuracy:  86.448 % \n",
      "Standard Deviation: (+/-) 2.586 %\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 10 FOLD CROSS VALIDATION\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "cv_scores = []\n",
    "\n",
    "for train_idx, test_idx in kfold.split(X, y):\n",
    "    X_train_cv, y_train_cv = X.iloc[train_idx], to_categorical(y[train_idx])\n",
    "    X_test_cv, y_test_cv = X.iloc[test_idx], to_categorical(y[test_idx])\n",
    "    best_model = model_builder(**best_model_params['build_params'])\n",
    "    best_model.fit(X_train_cv, y_train_cv, \n",
    "                   **best_model_params['fit_params'], \n",
    "                   verbose=0)\n",
    "    scores = best_model.evaluate(X_test_cv, y_test_cv, verbose=0)\n",
    "    cv_scores.append(scores[1]*100)\n",
    "\n",
    "print(\"Cross Validation Score\")\n",
    "print(\"-\"*50)\n",
    "print(f\"Mean Accuracy: {np.mean(cv_scores): .3f} % \\nStandard Deviation: (+/-){np.std(cv_scores): .3f} %\")\n",
    "print(\"-\"*50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
